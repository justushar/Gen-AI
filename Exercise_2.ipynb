{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJ0ZKrDxffoG"
   },
   "source": [
    "#**Importing Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtJbPacm3nfY",
    "outputId": "8c0881a1-a5a8-4591-9b07-81703dbb85af"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92epT7aZgF74"
   },
   "source": [
    "#**Loading the Birds Dataset**\n",
    "\n",
    "There are many kinds of birds: pigeons, ducks, ostriches, penguins… Some are good at flying, others can't fly but run fast. Some swim under water, others wading in shallow pool.\n",
    "\n",
    "According to their living environments and living habits, birds are classified into different ecological groups. There are 6 ecological groups of birds:\n",
    "\n",
    "* Swimming Birds (SW)\n",
    "* Wading Birds (W)\n",
    "* Terrestrial Birds (T)\n",
    "* Raptors (R)\n",
    "* Scansorial Birds (P)\n",
    "* Singing Birds (SO)\n",
    "\n",
    "Apparently, birds belong to different ecological groups have different appearances: **flying birds have strong wings and wading birds have long legs**. Their living habits are somewhat reflected in their bones' shapes. As data scientists we may think of examining the underlying relationship between sizes of bones and ecological groups, and recognising birds' ecological groups by their bones' shapes.\n",
    "\n",
    "![An image](https://animalcorner.org/wp-content/uploads/2015/04/bird_skeleton1.jpg)\n",
    "\n",
    "**Content**\n",
    "\n",
    "There are 420 birds contained in this dataset. Each bird is represented by 10 measurements (features):\n",
    "\n",
    "* Length and Diameter of Humerus\n",
    "* Length and Diameter of Ulna\n",
    "* Length and Diameter of Femur\n",
    "* Length and Diameter of Tibiotarsus\n",
    "* Length and Diameter of Tarsometatarsus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "mslwX-u6eqdi",
    "outputId": "a2ecec77-3d0a-473f-f045-bafd4ddf0be5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>huml</th>\n",
       "      <th>humw</th>\n",
       "      <th>ulnal</th>\n",
       "      <th>ulnaw</th>\n",
       "      <th>feml</th>\n",
       "      <th>femw</th>\n",
       "      <th>tibl</th>\n",
       "      <th>tibw</th>\n",
       "      <th>tarl</th>\n",
       "      <th>tarw</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>80.78</td>\n",
       "      <td>6.68</td>\n",
       "      <td>72.01</td>\n",
       "      <td>4.88</td>\n",
       "      <td>41.81</td>\n",
       "      <td>3.70</td>\n",
       "      <td>5.50</td>\n",
       "      <td>4.03</td>\n",
       "      <td>38.70</td>\n",
       "      <td>3.84</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>88.91</td>\n",
       "      <td>6.63</td>\n",
       "      <td>80.53</td>\n",
       "      <td>5.59</td>\n",
       "      <td>47.04</td>\n",
       "      <td>4.30</td>\n",
       "      <td>80.22</td>\n",
       "      <td>4.51</td>\n",
       "      <td>41.50</td>\n",
       "      <td>4.01</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>79.97</td>\n",
       "      <td>6.37</td>\n",
       "      <td>69.26</td>\n",
       "      <td>5.28</td>\n",
       "      <td>43.07</td>\n",
       "      <td>3.90</td>\n",
       "      <td>75.35</td>\n",
       "      <td>4.04</td>\n",
       "      <td>38.31</td>\n",
       "      <td>3.34</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>77.65</td>\n",
       "      <td>5.70</td>\n",
       "      <td>65.76</td>\n",
       "      <td>4.77</td>\n",
       "      <td>40.04</td>\n",
       "      <td>3.52</td>\n",
       "      <td>69.17</td>\n",
       "      <td>3.40</td>\n",
       "      <td>35.78</td>\n",
       "      <td>3.41</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>62.80</td>\n",
       "      <td>4.84</td>\n",
       "      <td>52.09</td>\n",
       "      <td>3.73</td>\n",
       "      <td>33.95</td>\n",
       "      <td>2.72</td>\n",
       "      <td>56.27</td>\n",
       "      <td>2.96</td>\n",
       "      <td>31.88</td>\n",
       "      <td>3.13</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   huml  humw  ulnal  ulnaw   feml  femw   tibl  tibw   tarl  tarw type\n",
       "0   0  80.78  6.68  72.01   4.88  41.81  3.70   5.50  4.03  38.70  3.84   SW\n",
       "1   1  88.91  6.63  80.53   5.59  47.04  4.30  80.22  4.51  41.50  4.01   SW\n",
       "2   2  79.97  6.37  69.26   5.28  43.07  3.90  75.35  4.04  38.31  3.34   SW\n",
       "3   3  77.65  5.70  65.76   4.77  40.04  3.52  69.17  3.40  35.78  3.41   SW\n",
       "4   4  62.80  4.84  52.09   3.73  33.95  2.72  56.27  2.96  31.88  3.13   SW"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_data = pd.read_csv('bird.csv',delimiter = ',') #('/content/drive/MyDrive/AMITY/STUDENT_BOOTCAMP/Data/bird.csv', delimiter = ',')\n",
    "bird_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgacS0JggQgr"
   },
   "source": [
    "#**Accessing the Column Names in the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hqRcQ0jffWS6",
    "outputId": "5eef02c3-64e2-43c5-c6cb-1614fa8f02ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'huml', 'humw', 'ulnal', 'ulnaw', 'feml', 'femw', 'tibl', 'tibw',\n",
       "       'tarl', 'tarw', 'type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "uHyanSIie5Xx",
    "outputId": "5bed861e-5b02-4d2d-bed9-c22a6e9487f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>huml</th>\n",
       "      <th>humw</th>\n",
       "      <th>ulnal</th>\n",
       "      <th>ulnaw</th>\n",
       "      <th>feml</th>\n",
       "      <th>femw</th>\n",
       "      <th>tibl</th>\n",
       "      <th>tibw</th>\n",
       "      <th>tarl</th>\n",
       "      <th>tarw</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.78</td>\n",
       "      <td>6.68</td>\n",
       "      <td>72.01</td>\n",
       "      <td>4.88</td>\n",
       "      <td>41.81</td>\n",
       "      <td>3.70</td>\n",
       "      <td>5.50</td>\n",
       "      <td>4.03</td>\n",
       "      <td>38.70</td>\n",
       "      <td>3.84</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.91</td>\n",
       "      <td>6.63</td>\n",
       "      <td>80.53</td>\n",
       "      <td>5.59</td>\n",
       "      <td>47.04</td>\n",
       "      <td>4.30</td>\n",
       "      <td>80.22</td>\n",
       "      <td>4.51</td>\n",
       "      <td>41.50</td>\n",
       "      <td>4.01</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.97</td>\n",
       "      <td>6.37</td>\n",
       "      <td>69.26</td>\n",
       "      <td>5.28</td>\n",
       "      <td>43.07</td>\n",
       "      <td>3.90</td>\n",
       "      <td>75.35</td>\n",
       "      <td>4.04</td>\n",
       "      <td>38.31</td>\n",
       "      <td>3.34</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77.65</td>\n",
       "      <td>5.70</td>\n",
       "      <td>65.76</td>\n",
       "      <td>4.77</td>\n",
       "      <td>40.04</td>\n",
       "      <td>3.52</td>\n",
       "      <td>69.17</td>\n",
       "      <td>3.40</td>\n",
       "      <td>35.78</td>\n",
       "      <td>3.41</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.80</td>\n",
       "      <td>4.84</td>\n",
       "      <td>52.09</td>\n",
       "      <td>3.73</td>\n",
       "      <td>33.95</td>\n",
       "      <td>2.72</td>\n",
       "      <td>56.27</td>\n",
       "      <td>2.96</td>\n",
       "      <td>31.88</td>\n",
       "      <td>3.13</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     huml  humw  ulnal  ulnaw   feml  femw   tibl  tibw   tarl  tarw type\n",
       "id                                                                       \n",
       "0   80.78  6.68  72.01   4.88  41.81  3.70   5.50  4.03  38.70  3.84   SW\n",
       "1   88.91  6.63  80.53   5.59  47.04  4.30  80.22  4.51  41.50  4.01   SW\n",
       "2   79.97  6.37  69.26   5.28  43.07  3.90  75.35  4.04  38.31  3.34   SW\n",
       "3   77.65  5.70  65.76   4.77  40.04  3.52  69.17  3.40  35.78  3.41   SW\n",
       "4   62.80  4.84  52.09   3.73  33.95  2.72  56.27  2.96  31.88  3.13   SW"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_data = bird_data.set_index('id')\n",
    "bird_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbWc384ZgkNk"
   },
   "source": [
    "#**Finding the Shape of the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v3r-6BsCfO6O",
    "outputId": "b668af20-eec9-4fb1-b5f2-c79bc4981ff6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420, 11)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DR5iJOoggqVl",
    "outputId": "c2a6be79-cc78-4569-a7a6-470dc3f734d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 420 entries, 0 to 419\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   huml    419 non-null    float64\n",
      " 1   humw    419 non-null    float64\n",
      " 2   ulnal   417 non-null    float64\n",
      " 3   ulnaw   418 non-null    float64\n",
      " 4   feml    418 non-null    float64\n",
      " 5   femw    419 non-null    float64\n",
      " 6   tibl    418 non-null    float64\n",
      " 7   tibw    419 non-null    float64\n",
      " 8   tarl    419 non-null    float64\n",
      " 9   tarw    419 non-null    float64\n",
      " 10  type    420 non-null    object \n",
      "dtypes: float64(10), object(1)\n",
      "memory usage: 39.4+ KB\n"
     ]
    }
   ],
   "source": [
    "bird_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOi7okQ_tQrB"
   },
   "source": [
    "#**Checking Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3XbsLJg0tN-L",
    "outputId": "f3c48337-d5ef-467a-a129-2976289bcd1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "huml     1\n",
       "humw     1\n",
       "ulnal    3\n",
       "ulnaw    2\n",
       "feml     2\n",
       "femw     1\n",
       "tibl     2\n",
       "tibw     1\n",
       "tarl     1\n",
       "tarw     1\n",
       "type     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "lN0LogSwGCLy"
   },
   "outputs": [],
   "source": [
    "bird_data.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lhfQVtHAGPk1",
    "outputId": "683d3023-b7a5-48ce-a7da-e7c15c3b47d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "huml     0\n",
       "humw     0\n",
       "ulnal    0\n",
       "ulnaw    0\n",
       "feml     0\n",
       "femw     0\n",
       "tibl     0\n",
       "tibw     0\n",
       "tarl     0\n",
       "tarw     0\n",
       "type     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qiui1vOsGidM",
    "outputId": "061ccd74-3093-4009-86e8-d2b4928cdc89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413, 11)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gL5klaMFg4U0"
   },
   "source": [
    "# **Unique Values in the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yNjlTn9yhJtA",
    "outputId": "bbae01b8-e8da-49a3-eed7-355559021f6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "huml     403\n",
       "humw     319\n",
       "ulnal    394\n",
       "ulnaw    305\n",
       "feml     397\n",
       "femw     287\n",
       "tibl     401\n",
       "tibw     283\n",
       "tarl     403\n",
       "tarw     277\n",
       "type       6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccm8FqHuM2CQ",
    "outputId": "cd253012-169f-435d-b9d8-2aedcdc0493c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SW', 'W', 'T', 'R', 'P', 'SO'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_data['type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohHEfCNNMDNU"
   },
   "source": [
    "# **Label Encoding of Categorical Variables**\n",
    "\n",
    "Label Encoding means converting categorical features into numerical values. So that they can be fitted by machine learning models which only take numerical data.\n",
    "\n",
    "**Example:**\n",
    "Suppose we have a column Height in some dataset that has elements as Tall, Medium, and short. To convert this categorical column into a numerical column we will apply label encoding to this column. After applying label encoding, the Height column is converted into a numerical column having elements 0,1, and 2 where 0 is the label for tall, 1 is the label for medium, and 2 is the label for short height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "-d9-2bXeMFg_"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "bird_data[['type']] = bird_data[['type']].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "Y_MpErPUMrLx",
    "outputId": "b645c50c-fada-4c09-a3f6-d8f24bc3a8ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>huml</th>\n",
       "      <th>humw</th>\n",
       "      <th>ulnal</th>\n",
       "      <th>ulnaw</th>\n",
       "      <th>feml</th>\n",
       "      <th>femw</th>\n",
       "      <th>tibl</th>\n",
       "      <th>tibw</th>\n",
       "      <th>tarl</th>\n",
       "      <th>tarw</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.78</td>\n",
       "      <td>6.68</td>\n",
       "      <td>72.01</td>\n",
       "      <td>4.88</td>\n",
       "      <td>41.81</td>\n",
       "      <td>3.70</td>\n",
       "      <td>5.50</td>\n",
       "      <td>4.03</td>\n",
       "      <td>38.70</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.91</td>\n",
       "      <td>6.63</td>\n",
       "      <td>80.53</td>\n",
       "      <td>5.59</td>\n",
       "      <td>47.04</td>\n",
       "      <td>4.30</td>\n",
       "      <td>80.22</td>\n",
       "      <td>4.51</td>\n",
       "      <td>41.50</td>\n",
       "      <td>4.01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.97</td>\n",
       "      <td>6.37</td>\n",
       "      <td>69.26</td>\n",
       "      <td>5.28</td>\n",
       "      <td>43.07</td>\n",
       "      <td>3.90</td>\n",
       "      <td>75.35</td>\n",
       "      <td>4.04</td>\n",
       "      <td>38.31</td>\n",
       "      <td>3.34</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77.65</td>\n",
       "      <td>5.70</td>\n",
       "      <td>65.76</td>\n",
       "      <td>4.77</td>\n",
       "      <td>40.04</td>\n",
       "      <td>3.52</td>\n",
       "      <td>69.17</td>\n",
       "      <td>3.40</td>\n",
       "      <td>35.78</td>\n",
       "      <td>3.41</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.80</td>\n",
       "      <td>4.84</td>\n",
       "      <td>52.09</td>\n",
       "      <td>3.73</td>\n",
       "      <td>33.95</td>\n",
       "      <td>2.72</td>\n",
       "      <td>56.27</td>\n",
       "      <td>2.96</td>\n",
       "      <td>31.88</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     huml  humw  ulnal  ulnaw   feml  femw   tibl  tibw   tarl  tarw  type\n",
       "id                                                                        \n",
       "0   80.78  6.68  72.01   4.88  41.81  3.70   5.50  4.03  38.70  3.84     3\n",
       "1   88.91  6.63  80.53   5.59  47.04  4.30  80.22  4.51  41.50  4.01     3\n",
       "2   79.97  6.37  69.26   5.28  43.07  3.90  75.35  4.04  38.31  3.34     3\n",
       "3   77.65  5.70  65.76   4.77  40.04  3.52  69.17  3.40  35.78  3.41     3\n",
       "4   62.80  4.84  52.09   3.73  33.95  2.72  56.27  2.96  31.88  3.13     3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBhC2pV6kG-m"
   },
   "source": [
    "#**Seperating Label from Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "CU-h5H-vilid"
   },
   "outputs": [],
   "source": [
    "y = bird_data['type']\n",
    "X = bird_data.drop(['type'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "doNxQbxXkrXv",
    "outputId": "0dfb6683-27b0-4f0b-b819-279afa9afa05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['huml', 'humw', 'ulnal', 'ulnaw', 'feml', 'femw', 'tibl', 'tibw',\n",
       "       'tarl', 'tarw'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "BEi9ZZ11_pIq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JxmY3LYgksbe",
    "outputId": "5076fff5-6e9a-44fc-eb26-a6d3763fb864"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0      3\n",
       "1      3\n",
       "2      3\n",
       "3      3\n",
       "4      3\n",
       "      ..\n",
       "415    2\n",
       "416    2\n",
       "417    2\n",
       "418    2\n",
       "419    2\n",
       "Name: type, Length: 413, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y3L_7AdDLqrR",
    "outputId": "f0a9f567-92a6-442e-e1ac-043c97b8e99d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKjRtpJ0JWJf"
   },
   "source": [
    "#**One-Hot-Encoding**\n",
    "\n",
    "* It allows the use of categorical variables in models that require numerical input.\n",
    "* It can improve model performance by providing more information to the model about the categorical variable.\n",
    "* It can help to avoid the problem of ordinality, which can occur when a categorical variable has a natural ordering (e.g. “small”, “medium”, “large”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L5twQod-KyJY",
    "outputId": "7b1ae331-8f3e-418c-d5b9-693160d8c47a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "num_classes = 6\n",
    "y = to_categorical(y, num_classes)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OB8cY_fNk2KG"
   },
   "source": [
    "#**Splitting the Data into Training and Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "ONhh9fw5kunZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n7QUNsrflJyd",
    "outputId": "3cbe87e2-b6d9-474b-fa85-98115247cffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the X_train (289, 10)\n",
      "Shape of the X_test (124, 10)\n",
      "Shape of the y_train (289, 6)\n",
      "Shape of the y_test (124, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the X_train\", X_train.shape)\n",
    "print(\"Shape of the X_test\", X_test.shape)\n",
    "print(\"Shape of the y_train\", y_train.shape)\n",
    "print(\"Shape of the y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRe4F-ZllGU0"
   },
   "source": [
    "# **Feature Scaling:**\n",
    "The result of **standardization** (or **Z-Score normalization**) is that the features will be re scaled so that they'll have the properties of a standard normal distribution with:\n",
    "$$\\mu = 0$$\n",
    "And\n",
    "$$\\sigma = 1$$\n",
    "\n",
    "Where $\\mu$ is the mean(average) and $\\sigma$ is the standard deviation from the mean; standard scores (also called **Z** scores) of the sampels are calculated as follows:\n",
    "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "***\n",
    "\n",
    "# **About Min-Max Scaling**\n",
    "\n",
    "An alternative approach to **Z-Score** normalization (or called standardization) is the so-called **Min-Max Scaling** (often also simply called **Normalization** - a common cause for ambiguities)\n",
    "\n",
    "In this approach, the data is scaled to a fixed range - usually `[0, 1]`.\n",
    "The cost of having this bounded range - in contrast to standrdization - is that we will end up with smaaller standard deviations, which can suppress the effect of outliers.\n",
    "\n",
    "**Note**:\n",
    "\n",
    "If the dataset have lot's of outliers, and the algorithms are sensitive to outliers, please use `Min-Max Scaler`\n",
    "\n",
    "A `Min-Max Scaling` is typically done via the foloowing equation:\n",
    "\n",
    "$$X_{norm} = \\frac{X_{i} - X_{min}}{X_{max} - X_{min}}$$\n",
    "\n",
    "$X_i$ is the $i^{th}$ sample of dataset.\n",
    "\n",
    "\n",
    "# **Z-Score Standardization or Min-Max Scaling**\n",
    "\n",
    "\"Standardization or Min-Max scaling\"? - There is no obvious answer to this question: it really depends on the application.\n",
    "\n",
    "However this doesn't mean that `Min-Max Scaling` is not useful at all, A popular application is `image processing`, where pixel intensities have to be normalized to fit withint a certain range (i.e., `[0, 255]` for the RGB colour range). Also, typical _Neural Network_ Algorithm require data that on a `0 - 1` scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "0tJwn52Wk9ty"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-18bjO3rOHB"
   },
   "source": [
    "#**Building the ANN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "lYWxtWt4lwsa"
   },
   "outputs": [],
   "source": [
    "# sequential model to initialise our ann and dense module to build the layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "5SHVdj9Xl6se"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 10:34:00.776907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = 10))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDjrKcLnrSw0"
   },
   "source": [
    "# **Compiling and Fitting the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RRtVuxFumFcS",
    "outputId": "7f2b1693-1cf9-4eba-cec0-44371970d0f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3acefc04c0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 16, epochs = 100, verbose = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55PgRgP0rZ8A"
   },
   "source": [
    "#**Testing the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VPqoEf0VmVx0",
    "outputId": "0938a857-902b-4285-dc37-06e46e6c4bf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 656us/step - loss: 0.2465 - accuracy: 0.8997\n",
      "Train score: 0.24649691581726074\n",
      "Train accuracy: 0.899653971195221\n",
      "********************\n",
      "13/13 [==============================] - 0s 755us/step - loss: 0.8509 - accuracy: 0.8548\n",
      "Test score: 0.8508892059326172\n",
      "Test accuracy: 0.8548387289047241\n"
     ]
    }
   ],
   "source": [
    "score, acc = classifier.evaluate(X_train, y_train,\n",
    "                            batch_size=10)\n",
    "print('Train score:', score)\n",
    "print('Train accuracy:', acc)\n",
    "\n",
    "print('*'*20)\n",
    "score, acc = classifier.evaluate(X_test, y_test,\n",
    "                            batch_size=10)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLS1Qv2Yrfj4"
   },
   "source": [
    "#**Confusion Matrix**\n",
    "\n",
    "### * **Accuracy**\n",
    "number of examples correctly predicted / total number of examples  \n",
    "![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/c72ec21ef2505c2d376e96197637fc64f75e5891)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tv7u8KsKNyrk",
    "outputId": "7625e796-2533-482a-f4e4-90a7aefc7073"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "Y_pred: [[0.16666801 0.1666678  0.16666539 0.16666618 0.16666596 0.16666667]\n",
      " [0.16667575 0.16666801 0.16665715 0.16665317 0.16667552 0.16667038]\n",
      " [0.16666912 0.16666865 0.16666278 0.16666687 0.16666564 0.16666692]\n",
      " [0.16667117 0.16667023 0.16666281 0.16666345 0.1666641  0.16666819]\n",
      " [0.16666918 0.16666919 0.16666394 0.16666509 0.16666505 0.16666757]\n",
      " [0.16667344 0.16667019 0.16665769 0.16666299 0.16667053 0.16666515]\n",
      " [0.16666763 0.16667171 0.1666627  0.16665827 0.16667172 0.16666797]\n",
      " [0.16667041 0.16667001 0.1666633  0.16666403 0.16666421 0.16666806]\n",
      " [0.16667345 0.16667931 0.16665538 0.16666085 0.1666702  0.16666086]\n",
      " [0.16667509 0.16667329 0.16665383 0.16666223 0.16667183 0.1666637 ]\n",
      " [0.16667047 0.1666699  0.16666327 0.16666396 0.16666439 0.16666798]\n",
      " [0.16666861 0.16666861 0.16666372 0.16666596 0.16666572 0.16666739]\n",
      " [0.16666965 0.16666855 0.16666217 0.16666597 0.16666801 0.16666563]\n",
      " [0.1666687  0.16666865 0.16666485 0.16666533 0.16666529 0.1666672 ]\n",
      " [0.16667038 0.16666971 0.1666624  0.16666439 0.16666442 0.16666874]\n",
      " [0.16666853 0.16666897 0.16666244 0.16666731 0.16666554 0.16666721]\n",
      " [0.1666704  0.16666979 0.16666381 0.16666384 0.16666447 0.16666763]\n",
      " [0.16666754 0.16666941 0.16666403 0.16666155 0.16666992 0.1666676 ]\n",
      " [0.16667093 0.1666702  0.16666351 0.1666635  0.16666418 0.1666677 ]\n",
      " [0.1666705  0.16666937 0.16666469 0.16666384 0.1666646  0.16666701]\n",
      " [0.16667046 0.16667002 0.16666277 0.16666412 0.16666423 0.16666844]\n",
      " [0.16666855 0.16666844 0.16666439 0.16666557 0.16666552 0.1666675 ]\n",
      " [0.16667101 0.16667017 0.16666359 0.16666341 0.16666415 0.16666764]\n",
      " [0.16666695 0.16666768 0.16666532 0.16666728 0.16666627 0.16666648]\n",
      " [       nan        nan        nan        nan        nan        nan]\n",
      " [0.1666699  0.16666874 0.16666193 0.16666465 0.16666903 0.16666578]\n",
      " [0.16666675 0.16666847 0.16666575 0.16666418 0.16666791 0.16666698]\n",
      " [0.16666801 0.16666746 0.16666569 0.16666579 0.1666665  0.16666651]\n",
      " [0.1666709  0.1666701  0.16666353 0.16666348 0.16666418 0.16666779]\n",
      " [0.1666697  0.16666959 0.16666347 0.1666647  0.16666475 0.16666782]\n",
      " [0.16667096 0.16666879 0.16666116 0.1666601  0.16667156 0.1666674 ]\n",
      " [0.1666742  0.16666785 0.16665788 0.16666445 0.16666983 0.16666582]\n",
      " [0.16666996 0.16666938 0.1666634  0.16666447 0.16666476 0.16666806]\n",
      " [0.1666793  0.1666811  0.16664763 0.16665529 0.16667576 0.16666093]\n",
      " [0.16666974 0.16666952 0.16666415 0.16666442 0.16666459 0.16666763]\n",
      " [0.16666706 0.16666707 0.16666485 0.16666764 0.16666621 0.16666713]\n",
      " [0.16667068 0.16667001 0.1666631  0.16666383 0.16666432 0.16666807]\n",
      " [0.16667877 0.16666579 0.16665487 0.16666012 0.1666734  0.16666704]\n",
      " [0.16666692 0.1666676  0.16666546 0.16666722 0.16666633 0.16666648]\n",
      " [0.16666712 0.16666874 0.16666478 0.16666448 0.16666868 0.16666621]\n",
      " [0.16666734 0.16666807 0.166667   0.16666538 0.16666603 0.16666621]\n",
      " [0.1666695  0.16666898 0.16666293 0.16666539 0.16666493 0.16666824]\n",
      " [0.1666717  0.16667075 0.16666272 0.16666298 0.16666372 0.16666815]\n",
      " [0.16667049 0.16667004 0.1666628  0.16666408 0.1666642  0.16666843]\n",
      " [0.16666722 0.16666728 0.16666566 0.16666639 0.1666668  0.1666666 ]\n",
      " [0.16667002 0.16666952 0.16666381 0.16666421 0.16666469 0.16666773]\n",
      " [0.16666806 0.16666892 0.16666637 0.16666435 0.16666605 0.1666663 ]\n",
      " [0.1666756  0.16666737 0.16665784 0.16665879 0.16667339 0.16666701]\n",
      " [0.16667157 0.16667074 0.16666266 0.16666311 0.16666372 0.16666818]\n",
      " [0.16666715 0.1666682  0.16666518 0.16666383 0.1666685  0.16666713]\n",
      " [0.16667087 0.16667034 0.16666348 0.16666366 0.16666408 0.16666761]\n",
      " [0.16666897 0.16666871 0.16666444 0.16666527 0.16666496 0.16666763]\n",
      " [0.16667046 0.16666983 0.16666266 0.1666642  0.1666643  0.16666855]\n",
      " [0.16667424 0.16666953 0.16665769 0.16665237 0.166676   0.16667022]\n",
      " [0.16667987 0.16666755 0.16665347 0.16665442 0.16667649 0.1666682 ]\n",
      " [0.16666925 0.16666885 0.16666365 0.1666656  0.16666476 0.16666791]\n",
      " [0.16667026 0.16666943 0.16666311 0.16666429 0.16666466 0.16666822]\n",
      " [0.16667072 0.16667013 0.16666336 0.16666365 0.16666426 0.16666783]\n",
      " [0.16666919 0.16666886 0.16666396 0.16666532 0.16666493 0.16666777]\n",
      " [0.16667053 0.16667002 0.16666307 0.166664   0.16666432 0.16666813]\n",
      " [0.16666688 0.16667342 0.16666329 0.16665746 0.16667117 0.16666782]\n",
      " [0.16667067 0.16667011 0.16666281 0.16666394 0.16666417 0.16666825]\n",
      " [0.1666736  0.1666725  0.1666562  0.16664647 0.16667935 0.16667192]\n",
      " [0.16667245 0.16667004 0.16665903 0.16665547 0.16667442 0.16666864]\n",
      " [0.16667002 0.1666696  0.1666633  0.16666445 0.16666435 0.16666827]\n",
      " [0.16666818 0.16666844 0.1666646  0.16666621 0.1666656  0.16666697]\n",
      " [0.16666995 0.16666922 0.16666457 0.16666424 0.16666481 0.16666722]\n",
      " [0.16666931 0.16666856 0.16666538 0.16666494 0.16666517 0.1666666 ]\n",
      " [0.16667078 0.16667001 0.16666381 0.16666354 0.16666429 0.1666676 ]\n",
      " [0.16668262 0.16666509 0.16665268 0.16665392 0.16667685 0.16666886]\n",
      " [0.16666853 0.16666844 0.1666644  0.1666661  0.16666575 0.16666673]\n",
      " [0.166669   0.16666849 0.16666381 0.16666555 0.1666652  0.16666795]\n",
      " [0.1666698  0.16666847 0.1666621  0.16666524 0.16666932 0.16666503]\n",
      " [0.16667144 0.16667059 0.1666631  0.16666305 0.1666639  0.16666786]\n",
      " [0.16666879 0.16666852 0.16666399 0.1666659  0.16666508 0.1666677 ]\n",
      " [0.16667077 0.16666955 0.1666645  0.16666356 0.16666448 0.16666715]\n",
      " [0.16666786 0.16667229 0.16666207 0.16665706 0.16667253 0.16666818]\n",
      " [0.16667697 0.16666788 0.16665618 0.16665724 0.16667469 0.16666707]\n",
      " [0.16669996 0.16666952 0.16663119 0.1666514  0.16668321 0.16666469]\n",
      " [0.16667026 0.1666699  0.16666336 0.16666411 0.16666436 0.16666794]\n",
      " [0.166671   0.16667905 0.16665478 0.16664192 0.16668245 0.16667078]\n",
      " [0.16666943 0.16666898 0.16666028 0.16666883 0.1666665  0.16666596]\n",
      " [0.16667001 0.16666904 0.16666512 0.16666429 0.16666485 0.16666672]\n",
      " [       nan        nan        nan        nan        nan        nan]\n",
      " [0.16666943 0.16666883 0.16666397 0.16666485 0.16666514 0.16666785]\n",
      " [0.16667031 0.16666953 0.16666333 0.16666412 0.16666462 0.16666804]\n",
      " [0.16666652 0.166668   0.1666663  0.16666599 0.16666679 0.16666639]\n",
      " [0.16667388 0.16667755 0.16665582 0.16666064 0.16667043 0.1666617 ]\n",
      " [0.16666907 0.16666877 0.16666473 0.16666515 0.16666503 0.16666728]\n",
      " [0.16666727 0.16666777 0.16666438 0.16666792 0.16666657 0.16666609]\n",
      " [0.16666687 0.1666677  0.16666558 0.16666704 0.16666652 0.16666625]\n",
      " [0.16666767 0.16666755 0.16666514 0.16666642 0.16666642 0.16666678]\n",
      " [0.16667128 0.16667052 0.16666327 0.16666323 0.16666394 0.16666771]\n",
      " [0.16666862 0.16666852 0.16666529 0.16666497 0.16666526 0.16666737]\n",
      " [0.16667098 0.16667014 0.16666321 0.16666356 0.16666414 0.166668  ]\n",
      " [0.1666664  0.16666837 0.16666637 0.1666652  0.16666715 0.16666648]\n",
      " [0.16667044 0.16666968 0.166664   0.1666638  0.16666451 0.16666754]\n",
      " [0.16667187 0.166679   0.16665348 0.16664106 0.16668303 0.16667159]\n",
      " [0.16667016 0.1666696  0.16666318 0.16666432 0.1666645  0.16666819]\n",
      " [0.16666883 0.16666895 0.16666484 0.16666555 0.16666515 0.16666673]\n",
      " [0.16667031 0.1666699  0.16666275 0.16666433 0.16666435 0.16666836]\n",
      " [0.16667008 0.16666964 0.16666363 0.16666423 0.16666465 0.16666782]\n",
      " [0.16666771 0.16666849 0.16666402 0.1666666  0.16666727 0.16666588]\n",
      " [       nan        nan        nan        nan        nan        nan]\n",
      " [0.16666721 0.16666763 0.166665   0.16666742 0.16666637 0.16666637]\n",
      " [0.16666687 0.16666767 0.16666561 0.16666709 0.16666648 0.1666663 ]\n",
      " [0.16666691 0.16666752 0.16666555 0.16666713 0.16666636 0.16666652]\n",
      " [0.16667102 0.16667049 0.16666333 0.16666338 0.16666394 0.16666785]\n",
      " [0.16666836 0.16666803 0.16666356 0.16666698 0.16666606 0.16666692]\n",
      " [0.16667074 0.16667023 0.16666351 0.16666374 0.16666417 0.16666763]\n",
      " [0.16666777 0.16666752 0.1666645  0.16666709 0.16666658 0.16666652]\n",
      " [0.16667472 0.1666737  0.1666546  0.1666487  0.16667908 0.16666919]\n",
      " [0.16666675 0.16666768 0.16666606 0.16666517 0.16666746 0.16666687]\n",
      " [0.16667026 0.1666696  0.16666326 0.16666421 0.16666459 0.1666681 ]\n",
      " [0.16667072 0.1666702  0.16666362 0.16666378 0.16666415 0.16666754]\n",
      " [0.1666694  0.16666904 0.16666389 0.16666478 0.16666491 0.16666795]\n",
      " [0.16667478 0.16666937 0.16665828 0.16664915 0.16667812 0.16667032]\n",
      " [0.16666695 0.16666786 0.16666527 0.16666733 0.16666627 0.16666636]\n",
      " [0.16668084 0.16667086 0.16665018 0.1666488  0.16668175 0.16666755]\n",
      " [0.16666946 0.1666692  0.1666641  0.16666463 0.16666478 0.16666785]\n",
      " [0.16667095 0.16667005 0.16666281 0.1666637  0.16666424 0.16666827]\n",
      " [0.16667408 0.16667563 0.16665421 0.16666153 0.16667138 0.16666314]\n",
      " [0.1666703  0.1666668  0.16666274 0.1666649  0.16666837 0.16666694]\n",
      " [0.16667011 0.16666904 0.1666652  0.16666406 0.16666478 0.16666684]\n",
      " [0.16667001 0.16666968 0.1666639  0.1666642  0.16666463 0.16666764]\n",
      " [0.1666713  0.16667032 0.16666226 0.16666354 0.16666403 0.16666855]]\n",
      "*****************\n",
      "Y_pred: [0 0 0 0 1 0 4 0 1 0 0 0 0 0 0 1 0 4 0 0 0 0 0 1 0 0 1 0 0 0 4 0 0 1 0 3 0\n",
      " 0 1 1 1 0 0 0 1 0 1 0 0 4 0 0 0 4 0 0 0 0 0 0 1 0 4 4 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 4 0 0 0 4 0 0 0 0 0 1 1 0 3 1 0 0 0 0 1 0 4 0 1 0 0 1 0 1 1 1 0 0 0 0\n",
      " 4 1 0 0 0 4 1 4 0 0 1 0 0 0 0]\n",
      "*****************\n",
      "Y_test: [[[1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]]]\n",
      "*****************\n",
      "Y_test: [[0 5 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 4 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 4 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 4 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 4 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 4 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 4 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 4 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [1 0 0 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 09:25:12.914699: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:655] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "pred = classifier.predict(X_test)\n",
    "print(\"Y_pred:\", pred)\n",
    "print(\"*****************\")\n",
    "y_pred = np.argmax(pred, axis = 1)\n",
    "print(\"Y_pred:\", y_pred)\n",
    "print(\"*****************\")\n",
    "print(\"Y_test:\", y_test)\n",
    "y_true = np.argmax(y_test, axis = 1)\n",
    "print(\"*****************\")\n",
    "print(\"Y_test:\", y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "kf2vqlsamx7r"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass-multioutput and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Making the Confusion Matrix\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m----> 3\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSW\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:317\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(\n\u001b[1;32m    233\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    234\u001b[0m ):\n\u001b[1;32m    235\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     92\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     97\u001b[0m             type_true, type_pred\n\u001b[1;32m     98\u001b[0m         )\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    102\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass-multioutput and multiclass targets"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "target_names = ['P', 'R', 'SO', 'SW', 'T', 'W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "EQPEuDuBnkgN"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "id": "ZE0yRVvRm4ng",
    "outputId": "42f566aa-545c-4004-8122-2679209bfb46"
   },
   "outputs": [],
   "source": [
    "p = sns.heatmap(pd.DataFrame(cm), annot=True,xticklabels=target_names, yticklabels=target_names, cmap=\"YlGnBu\" ,fmt='g')\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vA-IrzYPrkah"
   },
   "source": [
    "#**Classification Report**\n",
    "#**Classification Report**\n",
    "\n",
    "### * **True Positive Rate**\n",
    "number of samples actually and predicted as  `Positive` / total number of samples actually `Positive`  \n",
    "Also called **Sensitivity or Recall**.  \n",
    "![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/64d5540cbadeb83f864d7a731b7ab43cccd0f353)\n",
    "\n",
    "\n",
    "### * **Positive Predictive Value**\n",
    "number of samples actually and predicted as  `Positive` / total number of samples predicted as `Positive`  \n",
    "Also called **Precision**.  \n",
    "![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/699fcdb880b7f6a92742bc0845b8b60b59806a98)\n",
    "\n",
    "### * **F1 score**\n",
    "Harmonic Mean of Precision and Recall.  \n",
    "![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/5663ca95d471868169c4e4ea57c936f1b6f4a588)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h9PnAQtCm7wC",
    "outputId": "e873edd8-dc2a-4fac-bbfb-442837a1bdf9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#import classification_report\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(\u001b[43my_true\u001b[49m,y_pred, target_names \u001b[38;5;241m=\u001b[39m target_names))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "#import classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true,y_pred, target_names = target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4WoHrjxrooT"
   },
   "source": [
    "#**ROC curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PxrEaVsSRRXu",
    "outputId": "54ff68b0-ada7-4aee-b340-ebd1489e9278"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m6\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     fpr[i], tpr[i], _ \u001b[38;5;241m=\u001b[39m roc_curve(y_test[:, i], \u001b[43mpred\u001b[49m[:, i])\n\u001b[1;32m      8\u001b[0m     roc_auc[i] \u001b[38;5;241m=\u001b[39m auc(fpr[i], tpr[i])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Plot of a ROC curve for a specific class\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(6):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(6):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "6t01_ocrm-zD",
    "outputId": "7ae6a573-234c-4b5d-c5a5-425b20a9725c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m lw\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m6\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m     fpr[i], tpr[i], _ \u001b[38;5;241m=\u001b[39m roc_curve(y_test[:, i], \u001b[43mpred\u001b[49m[:, i])\n\u001b[1;32m      7\u001b[0m     roc_auc[i] \u001b[38;5;241m=\u001b[39m auc(fpr[i], tpr[i])\n\u001b[1;32m      8\u001b[0m colors \u001b[38;5;241m=\u001b[39mcycle([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdarkorange\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124molive\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpurple\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "lw=2\n",
    "for i in range(6):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "colors =cycle(['blue', 'green', 'red','darkorange','olive','purple'])\n",
    "for i, color in zip(range(6), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='AUC = {1:0.4f}'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate',fontsize=15)\n",
    "plt.ylabel('True Positive Rate',fontsize=15)\n",
    "# plt.title('Receiver operating characteristic for multi-class data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VquM03p9oKOS"
   },
   "source": [
    "# **Finetuing the Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Gzn1ezQnZfv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2942/1183103113.py:14: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  classifier = KerasClassifier(build_fn = build_classifier)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 1ms/step - loss: 1.7882 - accuracy: 0.2731\n",
      "Epoch 2/800\n",
      "17/17 [==============================] - 0s 886us/step - loss: 1.7779 - accuracy: 0.3038\n",
      "Epoch 3/800\n",
      "17/17 [==============================] - 0s 890us/step - loss: 1.7593 - accuracy: 0.3038\n",
      "Epoch 4/800\n",
      "17/17 [==============================] - 0s 893us/step - loss: 1.7155 - accuracy: 0.3462\n",
      "Epoch 5/800\n",
      "17/17 [==============================] - 0s 876us/step - loss: 1.6384 - accuracy: 0.5308\n",
      "Epoch 6/800\n",
      "17/17 [==============================] - 0s 865us/step - loss: 1.5821 - accuracy: 0.5231\n",
      "Epoch 7/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 1.5150 - accuracy: 0.5231\n",
      "Epoch 8/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 1.4558 - accuracy: 0.5154\n",
      "Epoch 9/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 1.3910 - accuracy: 0.5231\n",
      "Epoch 10/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 1.3415 - accuracy: 0.5231\n",
      "Epoch 11/800\n",
      "17/17 [==============================] - 0s 829us/step - loss: 1.3059 - accuracy: 0.5231\n",
      "Epoch 12/800\n",
      "17/17 [==============================] - 0s 835us/step - loss: 1.2801 - accuracy: 0.5308\n",
      "Epoch 13/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 1.2558 - accuracy: 0.5308\n",
      "Epoch 14/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 1.2393 - accuracy: 0.5346\n",
      "Epoch 15/800\n",
      "17/17 [==============================] - 0s 827us/step - loss: 1.2199 - accuracy: 0.5423\n",
      "Epoch 16/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 1.2019 - accuracy: 0.5577\n",
      "Epoch 17/800\n",
      "17/17 [==============================] - 0s 829us/step - loss: 1.1844 - accuracy: 0.5577\n",
      "Epoch 18/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 1.1645 - accuracy: 0.5577\n",
      "Epoch 19/800\n",
      "17/17 [==============================] - 0s 826us/step - loss: 1.1502 - accuracy: 0.5615\n",
      "Epoch 20/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 1.1326 - accuracy: 0.5731\n",
      "Epoch 21/800\n",
      "17/17 [==============================] - 0s 810us/step - loss: 1.1219 - accuracy: 0.5731\n",
      "Epoch 22/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 1.1066 - accuracy: 0.5731\n",
      "Epoch 23/800\n",
      "17/17 [==============================] - 0s 831us/step - loss: 1.0976 - accuracy: 0.5731\n",
      "Epoch 24/800\n",
      "17/17 [==============================] - 0s 846us/step - loss: 1.0854 - accuracy: 0.5731\n",
      "Epoch 25/800\n",
      "17/17 [==============================] - 0s 848us/step - loss: 1.0763 - accuracy: 0.5731\n",
      "Epoch 26/800\n",
      "17/17 [==============================] - 0s 843us/step - loss: 1.0739 - accuracy: 0.5731\n",
      "Epoch 27/800\n",
      "17/17 [==============================] - 0s 839us/step - loss: 1.0609 - accuracy: 0.5731\n",
      "Epoch 28/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 1.0496 - accuracy: 0.5731\n",
      "Epoch 29/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 1.0440 - accuracy: 0.5731\n",
      "Epoch 30/800\n",
      "17/17 [==============================] - 0s 846us/step - loss: 1.0342 - accuracy: 0.5731\n",
      "Epoch 31/800\n",
      "17/17 [==============================] - 0s 834us/step - loss: 1.0296 - accuracy: 0.5731\n",
      "Epoch 32/800\n",
      "17/17 [==============================] - 0s 843us/step - loss: 1.0224 - accuracy: 0.5731\n",
      "Epoch 33/800\n",
      "17/17 [==============================] - 0s 831us/step - loss: 1.0165 - accuracy: 0.5731\n",
      "Epoch 34/800\n",
      "17/17 [==============================] - 0s 836us/step - loss: 1.0146 - accuracy: 0.5731\n",
      "Epoch 35/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 1.0086 - accuracy: 0.5769\n",
      "Epoch 36/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 1.0014 - accuracy: 0.5731\n",
      "Epoch 37/800\n",
      "17/17 [==============================] - 0s 822us/step - loss: 0.9930 - accuracy: 0.5731\n",
      "Epoch 38/800\n",
      "17/17 [==============================] - 0s 834us/step - loss: 0.9911 - accuracy: 0.5808\n",
      "Epoch 39/800\n",
      "17/17 [==============================] - 0s 848us/step - loss: 0.9818 - accuracy: 0.5808\n",
      "Epoch 40/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 0.9840 - accuracy: 0.5846\n",
      "Epoch 41/800\n",
      "17/17 [==============================] - 0s 847us/step - loss: 0.9760 - accuracy: 0.5808\n",
      "Epoch 42/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.9639 - accuracy: 0.5885\n",
      "Epoch 43/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.9671 - accuracy: 0.6000\n",
      "Epoch 44/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.9721 - accuracy: 0.5885\n",
      "Epoch 45/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.9659 - accuracy: 0.6154\n",
      "Epoch 46/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.9530 - accuracy: 0.5962\n",
      "Epoch 47/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.9495 - accuracy: 0.6154\n",
      "Epoch 48/800\n",
      "17/17 [==============================] - 0s 817us/step - loss: 0.9356 - accuracy: 0.6115\n",
      "Epoch 49/800\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.9265 - accuracy: 0.6154\n",
      "Epoch 50/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 0.9261 - accuracy: 0.6192\n",
      "Epoch 51/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.9171 - accuracy: 0.6154\n",
      "Epoch 52/800\n",
      "17/17 [==============================] - 0s 827us/step - loss: 0.9111 - accuracy: 0.6231\n",
      "Epoch 53/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.9067 - accuracy: 0.6269\n",
      "Epoch 54/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.8968 - accuracy: 0.6462\n",
      "Epoch 55/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.9023 - accuracy: 0.6308\n",
      "Epoch 56/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 0.8853 - accuracy: 0.6423\n",
      "Epoch 57/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.8783 - accuracy: 0.6462\n",
      "Epoch 58/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.8814 - accuracy: 0.6500\n",
      "Epoch 59/800\n",
      "17/17 [==============================] - 0s 826us/step - loss: 0.8764 - accuracy: 0.6538\n",
      "Epoch 60/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.8583 - accuracy: 0.6577\n",
      "Epoch 61/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.8541 - accuracy: 0.6577\n",
      "Epoch 62/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.8431 - accuracy: 0.6538\n",
      "Epoch 63/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.8386 - accuracy: 0.6615\n",
      "Epoch 64/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.8386 - accuracy: 0.6692\n",
      "Epoch 65/800\n",
      "17/17 [==============================] - 0s 829us/step - loss: 0.8307 - accuracy: 0.6808\n",
      "Epoch 66/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 0.8210 - accuracy: 0.6808\n",
      "Epoch 67/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.8199 - accuracy: 0.6731\n",
      "Epoch 68/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.8279 - accuracy: 0.6654\n",
      "Epoch 69/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.8211 - accuracy: 0.6808\n",
      "Epoch 70/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.7995 - accuracy: 0.6769\n",
      "Epoch 71/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.7951 - accuracy: 0.6654\n",
      "Epoch 72/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.7941 - accuracy: 0.6808\n",
      "Epoch 73/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.7953 - accuracy: 0.6923\n",
      "Epoch 74/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.7884 - accuracy: 0.6808\n",
      "Epoch 75/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 0.7903 - accuracy: 0.6846\n",
      "Epoch 76/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.7804 - accuracy: 0.6769\n",
      "Epoch 77/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.7717 - accuracy: 0.6731\n",
      "Epoch 78/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 0.7693 - accuracy: 0.6731\n",
      "Epoch 79/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.7672 - accuracy: 0.6808\n",
      "Epoch 80/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.7675 - accuracy: 0.6923\n",
      "Epoch 81/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.7611 - accuracy: 0.6808\n",
      "Epoch 82/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.7677 - accuracy: 0.6808\n",
      "Epoch 83/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 0.7507 - accuracy: 0.6846\n",
      "Epoch 84/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.7458 - accuracy: 0.6808\n",
      "Epoch 85/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.7466 - accuracy: 0.6846\n",
      "Epoch 86/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 0.7480 - accuracy: 0.6962\n",
      "Epoch 87/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.7416 - accuracy: 0.6885\n",
      "Epoch 88/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.7643 - accuracy: 0.6923\n",
      "Epoch 89/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 0.7346 - accuracy: 0.6962\n",
      "Epoch 90/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.7410 - accuracy: 0.6962\n",
      "Epoch 91/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.7264 - accuracy: 0.6962\n",
      "Epoch 92/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.7239 - accuracy: 0.7000\n",
      "Epoch 93/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.7232 - accuracy: 0.6962\n",
      "Epoch 94/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.7173 - accuracy: 0.7038\n",
      "Epoch 95/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.7147 - accuracy: 0.7192\n",
      "Epoch 96/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.7120 - accuracy: 0.7038\n",
      "Epoch 97/800\n",
      "17/17 [==============================] - 0s 817us/step - loss: 0.7088 - accuracy: 0.6962\n",
      "Epoch 98/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.7059 - accuracy: 0.7038\n",
      "Epoch 99/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.7069 - accuracy: 0.7077\n",
      "Epoch 100/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.7039 - accuracy: 0.7077\n",
      "Epoch 101/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.7008 - accuracy: 0.7038\n",
      "Epoch 102/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 0.6945 - accuracy: 0.7231\n",
      "Epoch 103/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.6998 - accuracy: 0.7115\n",
      "Epoch 104/800\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.6894 - accuracy: 0.7192\n",
      "Epoch 105/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.6881 - accuracy: 0.7269\n",
      "Epoch 106/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.6931 - accuracy: 0.7077\n",
      "Epoch 107/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.6875 - accuracy: 0.7115\n",
      "Epoch 108/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.6811 - accuracy: 0.7192\n",
      "Epoch 109/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.6786 - accuracy: 0.7269\n",
      "Epoch 110/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.6802 - accuracy: 0.7115\n",
      "Epoch 111/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.6767 - accuracy: 0.7308\n",
      "Epoch 112/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.6726 - accuracy: 0.7231\n",
      "Epoch 113/800\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.6698 - accuracy: 0.7269\n",
      "Epoch 114/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.6674 - accuracy: 0.7346\n",
      "Epoch 115/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.6687 - accuracy: 0.7192\n",
      "Epoch 116/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.6708 - accuracy: 0.7385\n",
      "Epoch 117/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.6876 - accuracy: 0.6962\n",
      "Epoch 118/800\n",
      "17/17 [==============================] - 0s 834us/step - loss: 0.6673 - accuracy: 0.7385\n",
      "Epoch 119/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.6571 - accuracy: 0.7500\n",
      "Epoch 120/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.6518 - accuracy: 0.7231\n",
      "Epoch 121/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.6522 - accuracy: 0.7308\n",
      "Epoch 122/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.6595 - accuracy: 0.7269\n",
      "Epoch 123/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 0.6566 - accuracy: 0.7385\n",
      "Epoch 124/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.6484 - accuracy: 0.7462\n",
      "Epoch 125/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.6394 - accuracy: 0.7385\n",
      "Epoch 126/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.6416 - accuracy: 0.7500\n",
      "Epoch 127/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.6356 - accuracy: 0.7538\n",
      "Epoch 128/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.6433 - accuracy: 0.7423\n",
      "Epoch 129/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.6372 - accuracy: 0.7462\n",
      "Epoch 130/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.6323 - accuracy: 0.7615\n",
      "Epoch 131/800\n",
      "17/17 [==============================] - 0s 795us/step - loss: 0.6403 - accuracy: 0.7538\n",
      "Epoch 132/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.6278 - accuracy: 0.7538\n",
      "Epoch 133/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.6248 - accuracy: 0.7577\n",
      "Epoch 134/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.6197 - accuracy: 0.7615\n",
      "Epoch 135/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.6189 - accuracy: 0.7654\n",
      "Epoch 136/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.6208 - accuracy: 0.7538\n",
      "Epoch 137/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.6122 - accuracy: 0.7615\n",
      "Epoch 138/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.6120 - accuracy: 0.7577\n",
      "Epoch 139/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.6099 - accuracy: 0.7615\n",
      "Epoch 140/800\n",
      "17/17 [==============================] - 0s 861us/step - loss: 0.6096 - accuracy: 0.7615\n",
      "Epoch 141/800\n",
      "17/17 [==============================] - 0s 777us/step - loss: 0.6041 - accuracy: 0.7577\n",
      "Epoch 142/800\n",
      "17/17 [==============================] - 0s 775us/step - loss: 0.6070 - accuracy: 0.7615\n",
      "Epoch 143/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.6025 - accuracy: 0.7654\n",
      "Epoch 144/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.6053 - accuracy: 0.7500\n",
      "Epoch 145/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.5988 - accuracy: 0.7577\n",
      "Epoch 146/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.5984 - accuracy: 0.7654\n",
      "Epoch 147/800\n",
      "17/17 [==============================] - 0s 777us/step - loss: 0.5937 - accuracy: 0.7615\n",
      "Epoch 148/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.5922 - accuracy: 0.7654\n",
      "Epoch 149/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.5925 - accuracy: 0.7654\n",
      "Epoch 150/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.5918 - accuracy: 0.7654\n",
      "Epoch 151/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.5863 - accuracy: 0.7769\n",
      "Epoch 152/800\n",
      "17/17 [==============================] - 0s 787us/step - loss: 0.5902 - accuracy: 0.7615\n",
      "Epoch 153/800\n",
      "17/17 [==============================] - 0s 777us/step - loss: 0.5906 - accuracy: 0.7538\n",
      "Epoch 154/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.5838 - accuracy: 0.7692\n",
      "Epoch 155/800\n",
      "17/17 [==============================] - 0s 779us/step - loss: 0.5783 - accuracy: 0.7615\n",
      "Epoch 156/800\n",
      "17/17 [==============================] - 0s 772us/step - loss: 0.5813 - accuracy: 0.7615\n",
      "Epoch 157/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.5784 - accuracy: 0.7654\n",
      "Epoch 158/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.5757 - accuracy: 0.7731\n",
      "Epoch 159/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 0.5705 - accuracy: 0.7731\n",
      "Epoch 160/800\n",
      "17/17 [==============================] - 0s 779us/step - loss: 0.5670 - accuracy: 0.7731\n",
      "Epoch 161/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.5690 - accuracy: 0.7692\n",
      "Epoch 162/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.5651 - accuracy: 0.7731\n",
      "Epoch 163/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.5665 - accuracy: 0.7769\n",
      "Epoch 164/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.5808 - accuracy: 0.7692\n",
      "Epoch 165/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 0.5729 - accuracy: 0.7731\n",
      "Epoch 166/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.5632 - accuracy: 0.7692\n",
      "Epoch 167/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.5579 - accuracy: 0.7769\n",
      "Epoch 168/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.5553 - accuracy: 0.7731\n",
      "Epoch 169/800\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.5546 - accuracy: 0.7731\n",
      "Epoch 170/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.5501 - accuracy: 0.7769\n",
      "Epoch 171/800\n",
      "17/17 [==============================] - 0s 778us/step - loss: 0.5485 - accuracy: 0.7769\n",
      "Epoch 172/800\n",
      "17/17 [==============================] - 0s 779us/step - loss: 0.5481 - accuracy: 0.7808\n",
      "Epoch 173/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.5492 - accuracy: 0.7885\n",
      "Epoch 174/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.5454 - accuracy: 0.7731\n",
      "Epoch 175/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.5390 - accuracy: 0.7846\n",
      "Epoch 176/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.5439 - accuracy: 0.7885\n",
      "Epoch 177/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.5479 - accuracy: 0.7846\n",
      "Epoch 178/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.5384 - accuracy: 0.7923\n",
      "Epoch 179/800\n",
      "17/17 [==============================] - 0s 778us/step - loss: 0.5424 - accuracy: 0.7885\n",
      "Epoch 180/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.5410 - accuracy: 0.7962\n",
      "Epoch 181/800\n",
      "17/17 [==============================] - 0s 778us/step - loss: 0.5334 - accuracy: 0.7962\n",
      "Epoch 182/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.5331 - accuracy: 0.7885\n",
      "Epoch 183/800\n",
      "17/17 [==============================] - 0s 778us/step - loss: 0.5365 - accuracy: 0.7885\n",
      "Epoch 184/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.5359 - accuracy: 0.7846\n",
      "Epoch 185/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.5295 - accuracy: 0.7923\n",
      "Epoch 186/800\n",
      "17/17 [==============================] - 0s 772us/step - loss: 0.5276 - accuracy: 0.7885\n",
      "Epoch 187/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.5263 - accuracy: 0.7846\n",
      "Epoch 188/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.5332 - accuracy: 0.7846\n",
      "Epoch 189/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.5254 - accuracy: 0.7962\n",
      "Epoch 190/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.5252 - accuracy: 0.7846\n",
      "Epoch 191/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.5335 - accuracy: 0.7846\n",
      "Epoch 192/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.5207 - accuracy: 0.7962\n",
      "Epoch 193/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.5193 - accuracy: 0.8000\n",
      "Epoch 194/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.5165 - accuracy: 0.7962\n",
      "Epoch 195/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.5162 - accuracy: 0.8038\n",
      "Epoch 196/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.5159 - accuracy: 0.7923\n",
      "Epoch 197/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.5169 - accuracy: 0.8077\n",
      "Epoch 198/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.5150 - accuracy: 0.7885\n",
      "Epoch 199/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.5122 - accuracy: 0.8000\n",
      "Epoch 200/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.5116 - accuracy: 0.8077\n",
      "Epoch 201/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.5056 - accuracy: 0.8077\n",
      "Epoch 202/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.5067 - accuracy: 0.8038\n",
      "Epoch 203/800\n",
      "17/17 [==============================] - 0s 806us/step - loss: 0.5100 - accuracy: 0.7923\n",
      "Epoch 204/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.5172 - accuracy: 0.7962\n",
      "Epoch 205/800\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.4999 - accuracy: 0.8038\n",
      "Epoch 206/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.5082 - accuracy: 0.7962\n",
      "Epoch 207/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.5024 - accuracy: 0.8000\n",
      "Epoch 208/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.5041 - accuracy: 0.8000\n",
      "Epoch 209/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.5024 - accuracy: 0.8000\n",
      "Epoch 210/800\n",
      "17/17 [==============================] - 0s 800us/step - loss: 0.5066 - accuracy: 0.8115\n",
      "Epoch 211/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.5101 - accuracy: 0.8000\n",
      "Epoch 212/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.4969 - accuracy: 0.7962\n",
      "Epoch 213/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.5007 - accuracy: 0.7962\n",
      "Epoch 214/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.5063 - accuracy: 0.8115\n",
      "Epoch 215/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.4967 - accuracy: 0.8000\n",
      "Epoch 216/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.4959 - accuracy: 0.8077\n",
      "Epoch 217/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.4957 - accuracy: 0.8115\n",
      "Epoch 218/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.4955 - accuracy: 0.8038\n",
      "Epoch 219/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.5015 - accuracy: 0.7962\n",
      "Epoch 220/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.4984 - accuracy: 0.8038\n",
      "Epoch 221/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.4974 - accuracy: 0.8154\n",
      "Epoch 222/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.4910 - accuracy: 0.8038\n",
      "Epoch 223/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.4921 - accuracy: 0.8308\n",
      "Epoch 224/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.4880 - accuracy: 0.8000\n",
      "Epoch 225/800\n",
      "17/17 [==============================] - 0s 733us/step - loss: 0.4837 - accuracy: 0.8038\n",
      "Epoch 226/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.4844 - accuracy: 0.8231\n",
      "Epoch 227/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.4861 - accuracy: 0.8038\n",
      "Epoch 228/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.4827 - accuracy: 0.8115\n",
      "Epoch 229/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.4818 - accuracy: 0.8192\n",
      "Epoch 230/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.4784 - accuracy: 0.8115\n",
      "Epoch 231/800\n",
      "17/17 [==============================] - 0s 772us/step - loss: 0.4860 - accuracy: 0.8115\n",
      "Epoch 232/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.5023 - accuracy: 0.8154\n",
      "Epoch 233/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.5241 - accuracy: 0.8231\n",
      "Epoch 234/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.4886 - accuracy: 0.8154\n",
      "Epoch 235/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.4817 - accuracy: 0.8192\n",
      "Epoch 236/800\n",
      "17/17 [==============================] - 0s 732us/step - loss: 0.4846 - accuracy: 0.8154\n",
      "Epoch 237/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.4707 - accuracy: 0.8231\n",
      "Epoch 238/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 0.4721 - accuracy: 0.8308\n",
      "Epoch 239/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.4715 - accuracy: 0.8269\n",
      "Epoch 240/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.4676 - accuracy: 0.8231\n",
      "Epoch 241/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.4692 - accuracy: 0.8192\n",
      "Epoch 242/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.4704 - accuracy: 0.8192\n",
      "Epoch 243/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.4745 - accuracy: 0.8154\n",
      "Epoch 244/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.4639 - accuracy: 0.8231\n",
      "Epoch 245/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.4634 - accuracy: 0.8385\n",
      "Epoch 246/800\n",
      "17/17 [==============================] - 0s 775us/step - loss: 0.4613 - accuracy: 0.8346\n",
      "Epoch 247/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.4613 - accuracy: 0.8385\n",
      "Epoch 248/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.4600 - accuracy: 0.8231\n",
      "Epoch 249/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.4595 - accuracy: 0.8346\n",
      "Epoch 250/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.4646 - accuracy: 0.8269\n",
      "Epoch 251/800\n",
      "17/17 [==============================] - 0s 787us/step - loss: 0.4627 - accuracy: 0.8231\n",
      "Epoch 252/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.4570 - accuracy: 0.8308\n",
      "Epoch 253/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.4575 - accuracy: 0.8231\n",
      "Epoch 254/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.4571 - accuracy: 0.8308\n",
      "Epoch 255/800\n",
      "17/17 [==============================] - 0s 778us/step - loss: 0.4593 - accuracy: 0.8346\n",
      "Epoch 256/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.4546 - accuracy: 0.8346\n",
      "Epoch 257/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.4525 - accuracy: 0.8346\n",
      "Epoch 258/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.4503 - accuracy: 0.8462\n",
      "Epoch 259/800\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.4536 - accuracy: 0.8385\n",
      "Epoch 260/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.4539 - accuracy: 0.8385\n",
      "Epoch 261/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.4479 - accuracy: 0.8231\n",
      "Epoch 262/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.4545 - accuracy: 0.8308\n",
      "Epoch 263/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.4479 - accuracy: 0.8385\n",
      "Epoch 264/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.4443 - accuracy: 0.8269\n",
      "Epoch 265/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.4444 - accuracy: 0.8385\n",
      "Epoch 266/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.4422 - accuracy: 0.8385\n",
      "Epoch 267/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 0.4587 - accuracy: 0.8231\n",
      "Epoch 268/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.4493 - accuracy: 0.8385\n",
      "Epoch 269/800\n",
      "17/17 [==============================] - 0s 779us/step - loss: 0.4506 - accuracy: 0.8308\n",
      "Epoch 270/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.4388 - accuracy: 0.8423\n",
      "Epoch 271/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 0.4415 - accuracy: 0.8385\n",
      "Epoch 272/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.4370 - accuracy: 0.8346\n",
      "Epoch 273/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.4356 - accuracy: 0.8269\n",
      "Epoch 274/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.4357 - accuracy: 0.8423\n",
      "Epoch 275/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.4336 - accuracy: 0.8423\n",
      "Epoch 276/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 0.4330 - accuracy: 0.8462\n",
      "Epoch 277/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.4410 - accuracy: 0.8346\n",
      "Epoch 278/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.4374 - accuracy: 0.8462\n",
      "Epoch 279/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.4308 - accuracy: 0.8385\n",
      "Epoch 280/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.4287 - accuracy: 0.8346\n",
      "Epoch 281/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.4280 - accuracy: 0.8385\n",
      "Epoch 282/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.4268 - accuracy: 0.8462\n",
      "Epoch 283/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.4291 - accuracy: 0.8462\n",
      "Epoch 284/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.4237 - accuracy: 0.8500\n",
      "Epoch 285/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.4276 - accuracy: 0.8462\n",
      "Epoch 286/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.4219 - accuracy: 0.8615\n",
      "Epoch 287/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.4384 - accuracy: 0.8385\n",
      "Epoch 288/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.4260 - accuracy: 0.8423\n",
      "Epoch 289/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.4242 - accuracy: 0.8500\n",
      "Epoch 290/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.4375 - accuracy: 0.8385\n",
      "Epoch 291/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.4292 - accuracy: 0.8385\n",
      "Epoch 292/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.4200 - accuracy: 0.8423\n",
      "Epoch 293/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.4182 - accuracy: 0.8385\n",
      "Epoch 294/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.4170 - accuracy: 0.8385\n",
      "Epoch 295/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.4211 - accuracy: 0.8462\n",
      "Epoch 296/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.4217 - accuracy: 0.8423\n",
      "Epoch 297/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.4413 - accuracy: 0.8346\n",
      "Epoch 298/800\n",
      "17/17 [==============================] - 0s 713us/step - loss: 0.4245 - accuracy: 0.8423\n",
      "Epoch 299/800\n",
      "17/17 [==============================] - 0s 722us/step - loss: 0.4212 - accuracy: 0.8577\n",
      "Epoch 300/800\n",
      "17/17 [==============================] - 0s 725us/step - loss: 0.4095 - accuracy: 0.8423\n",
      "Epoch 301/800\n",
      "17/17 [==============================] - 0s 724us/step - loss: 0.4294 - accuracy: 0.8385\n",
      "Epoch 302/800\n",
      "17/17 [==============================] - 0s 732us/step - loss: 0.4223 - accuracy: 0.8423\n",
      "Epoch 303/800\n",
      "17/17 [==============================] - 0s 729us/step - loss: 0.4070 - accuracy: 0.8462\n",
      "Epoch 304/800\n",
      "17/17 [==============================] - 0s 707us/step - loss: 0.4128 - accuracy: 0.8615\n",
      "Epoch 305/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.4074 - accuracy: 0.8462\n",
      "Epoch 306/800\n",
      "17/17 [==============================] - 0s 717us/step - loss: 0.4070 - accuracy: 0.8538\n",
      "Epoch 307/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.4072 - accuracy: 0.8500\n",
      "Epoch 308/800\n",
      "17/17 [==============================] - 0s 722us/step - loss: 0.4108 - accuracy: 0.8500\n",
      "Epoch 309/800\n",
      "17/17 [==============================] - 0s 727us/step - loss: 0.4102 - accuracy: 0.8577\n",
      "Epoch 310/800\n",
      "17/17 [==============================] - 0s 729us/step - loss: 0.4126 - accuracy: 0.8462\n",
      "Epoch 311/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.4009 - accuracy: 0.8538\n",
      "Epoch 312/800\n",
      "17/17 [==============================] - 0s 736us/step - loss: 0.4043 - accuracy: 0.8423\n",
      "Epoch 313/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.3931 - accuracy: 0.8462\n",
      "Epoch 314/800\n",
      "17/17 [==============================] - 0s 736us/step - loss: 0.3997 - accuracy: 0.8462\n",
      "Epoch 315/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.3978 - accuracy: 0.8385\n",
      "Epoch 316/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.3914 - accuracy: 0.8577\n",
      "Epoch 317/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.3911 - accuracy: 0.8462\n",
      "Epoch 318/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.3958 - accuracy: 0.8346\n",
      "Epoch 319/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.3894 - accuracy: 0.8538\n",
      "Epoch 320/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.3899 - accuracy: 0.8538\n",
      "Epoch 321/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.3912 - accuracy: 0.8462\n",
      "Epoch 322/800\n",
      "17/17 [==============================] - 0s 733us/step - loss: 0.3897 - accuracy: 0.8462\n",
      "Epoch 323/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.3879 - accuracy: 0.8423\n",
      "Epoch 324/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.3852 - accuracy: 0.8500\n",
      "Epoch 325/800\n",
      "17/17 [==============================] - 0s 719us/step - loss: 0.3870 - accuracy: 0.8462\n",
      "Epoch 326/800\n",
      "17/17 [==============================] - 0s 729us/step - loss: 0.3831 - accuracy: 0.8500\n",
      "Epoch 327/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 0.3798 - accuracy: 0.8538\n",
      "Epoch 328/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.3839 - accuracy: 0.8500\n",
      "Epoch 329/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.3861 - accuracy: 0.8423\n",
      "Epoch 330/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.3814 - accuracy: 0.8615\n",
      "Epoch 331/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.3873 - accuracy: 0.8423\n",
      "Epoch 332/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.3829 - accuracy: 0.8500\n",
      "Epoch 333/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.3873 - accuracy: 0.8385\n",
      "Epoch 334/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.3884 - accuracy: 0.8500\n",
      "Epoch 335/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.3857 - accuracy: 0.8423\n",
      "Epoch 336/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.3737 - accuracy: 0.8654\n",
      "Epoch 337/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.3759 - accuracy: 0.8500\n",
      "Epoch 338/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.3742 - accuracy: 0.8577\n",
      "Epoch 339/800\n",
      "17/17 [==============================] - 0s 736us/step - loss: 0.3723 - accuracy: 0.8615\n",
      "Epoch 340/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.3710 - accuracy: 0.8577\n",
      "Epoch 341/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.3717 - accuracy: 0.8692\n",
      "Epoch 342/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.3767 - accuracy: 0.8654\n",
      "Epoch 343/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.3683 - accuracy: 0.8577\n",
      "Epoch 344/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.3616 - accuracy: 0.8577\n",
      "Epoch 345/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.3654 - accuracy: 0.8615\n",
      "Epoch 346/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.3660 - accuracy: 0.8731\n",
      "Epoch 347/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.3643 - accuracy: 0.8692\n",
      "Epoch 348/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.3589 - accuracy: 0.8654\n",
      "Epoch 349/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.3584 - accuracy: 0.8731\n",
      "Epoch 350/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.3642 - accuracy: 0.8731\n",
      "Epoch 351/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.3562 - accuracy: 0.8654\n",
      "Epoch 352/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.3598 - accuracy: 0.8654\n",
      "Epoch 353/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.3581 - accuracy: 0.8731\n",
      "Epoch 354/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.3550 - accuracy: 0.8846\n",
      "Epoch 355/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.3679 - accuracy: 0.8654\n",
      "Epoch 356/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.3520 - accuracy: 0.8769\n",
      "Epoch 357/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.3520 - accuracy: 0.8692\n",
      "Epoch 358/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.3531 - accuracy: 0.8769\n",
      "Epoch 359/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.3514 - accuracy: 0.8731\n",
      "Epoch 360/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.3444 - accuracy: 0.8808\n",
      "Epoch 361/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.3517 - accuracy: 0.8769\n",
      "Epoch 362/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.3509 - accuracy: 0.8769\n",
      "Epoch 363/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.3636 - accuracy: 0.8654\n",
      "Epoch 364/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.3410 - accuracy: 0.8846\n",
      "Epoch 365/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.3420 - accuracy: 0.8808\n",
      "Epoch 366/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.3418 - accuracy: 0.8885\n",
      "Epoch 367/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.3437 - accuracy: 0.8731\n",
      "Epoch 368/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.3395 - accuracy: 0.8846\n",
      "Epoch 369/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.3453 - accuracy: 0.8769\n",
      "Epoch 370/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.3392 - accuracy: 0.8846\n",
      "Epoch 371/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.3391 - accuracy: 0.8885\n",
      "Epoch 372/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.3592 - accuracy: 0.8808\n",
      "Epoch 373/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.3442 - accuracy: 0.8808\n",
      "Epoch 374/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.3303 - accuracy: 0.8846\n",
      "Epoch 375/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.3296 - accuracy: 0.8923\n",
      "Epoch 376/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.3342 - accuracy: 0.8885\n",
      "Epoch 377/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.3283 - accuracy: 0.8846\n",
      "Epoch 378/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.3321 - accuracy: 0.8769\n",
      "Epoch 379/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.3253 - accuracy: 0.8923\n",
      "Epoch 380/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.3309 - accuracy: 0.8885\n",
      "Epoch 381/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.3261 - accuracy: 0.8885\n",
      "Epoch 382/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.3226 - accuracy: 0.8962\n",
      "Epoch 383/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.3241 - accuracy: 0.8962\n",
      "Epoch 384/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.3303 - accuracy: 0.8731\n",
      "Epoch 385/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.3185 - accuracy: 0.9000\n",
      "Epoch 386/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.3152 - accuracy: 0.9000\n",
      "Epoch 387/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.3228 - accuracy: 0.8962\n",
      "Epoch 388/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.3147 - accuracy: 0.9000\n",
      "Epoch 389/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.3150 - accuracy: 0.9000\n",
      "Epoch 390/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.3155 - accuracy: 0.9000\n",
      "Epoch 391/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.3120 - accuracy: 0.8923\n",
      "Epoch 392/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.3070 - accuracy: 0.9000\n",
      "Epoch 393/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.3114 - accuracy: 0.9000\n",
      "Epoch 394/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.3041 - accuracy: 0.9038\n",
      "Epoch 395/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.3103 - accuracy: 0.9038\n",
      "Epoch 396/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.3054 - accuracy: 0.9077\n",
      "Epoch 397/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.3128 - accuracy: 0.9038\n",
      "Epoch 398/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.3026 - accuracy: 0.9077\n",
      "Epoch 399/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.3016 - accuracy: 0.9000\n",
      "Epoch 400/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.3085 - accuracy: 0.9077\n",
      "Epoch 401/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.3190 - accuracy: 0.8962\n",
      "Epoch 402/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.3393 - accuracy: 0.8808\n",
      "Epoch 403/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.3034 - accuracy: 0.9038\n",
      "Epoch 404/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.2973 - accuracy: 0.9077\n",
      "Epoch 405/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.3149 - accuracy: 0.8962\n",
      "Epoch 406/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.3089 - accuracy: 0.9000\n",
      "Epoch 407/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.3052 - accuracy: 0.9077\n",
      "Epoch 408/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.2919 - accuracy: 0.9038\n",
      "Epoch 409/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.2886 - accuracy: 0.9192\n",
      "Epoch 410/800\n",
      "17/17 [==============================] - 0s 777us/step - loss: 0.2866 - accuracy: 0.9192\n",
      "Epoch 411/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.2890 - accuracy: 0.9115\n",
      "Epoch 412/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.2883 - accuracy: 0.9115\n",
      "Epoch 413/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.2860 - accuracy: 0.9115\n",
      "Epoch 414/800\n",
      "17/17 [==============================] - 0s 736us/step - loss: 0.2837 - accuracy: 0.9231\n",
      "Epoch 415/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.2854 - accuracy: 0.9192\n",
      "Epoch 416/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.2814 - accuracy: 0.9192\n",
      "Epoch 417/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.2803 - accuracy: 0.9192\n",
      "Epoch 418/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.2806 - accuracy: 0.9269\n",
      "Epoch 419/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.2814 - accuracy: 0.9231\n",
      "Epoch 420/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.2902 - accuracy: 0.9115\n",
      "Epoch 421/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.2765 - accuracy: 0.9192\n",
      "Epoch 422/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.2764 - accuracy: 0.9269\n",
      "Epoch 423/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.2764 - accuracy: 0.9115\n",
      "Epoch 424/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.2761 - accuracy: 0.9192\n",
      "Epoch 425/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.2790 - accuracy: 0.9154\n",
      "Epoch 426/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.2855 - accuracy: 0.9038\n",
      "Epoch 427/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.2708 - accuracy: 0.9269\n",
      "Epoch 428/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.2743 - accuracy: 0.9269\n",
      "Epoch 429/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.2821 - accuracy: 0.9000\n",
      "Epoch 430/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.2902 - accuracy: 0.9115\n",
      "Epoch 431/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.2704 - accuracy: 0.9231\n",
      "Epoch 432/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.2689 - accuracy: 0.9269\n",
      "Epoch 433/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.2657 - accuracy: 0.9231\n",
      "Epoch 434/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.2681 - accuracy: 0.9346\n",
      "Epoch 435/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.2668 - accuracy: 0.9231\n",
      "Epoch 436/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.2643 - accuracy: 0.9308\n",
      "Epoch 437/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.2678 - accuracy: 0.9269\n",
      "Epoch 438/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.2655 - accuracy: 0.9154\n",
      "Epoch 439/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.2808 - accuracy: 0.9000\n",
      "Epoch 440/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.2741 - accuracy: 0.9231\n",
      "Epoch 441/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.2695 - accuracy: 0.9269\n",
      "Epoch 442/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.2573 - accuracy: 0.9308\n",
      "Epoch 443/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.2585 - accuracy: 0.9269\n",
      "Epoch 444/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.2539 - accuracy: 0.9269\n",
      "Epoch 445/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.2621 - accuracy: 0.9192\n",
      "Epoch 446/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.2538 - accuracy: 0.9192\n",
      "Epoch 447/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.2608 - accuracy: 0.9192\n",
      "Epoch 448/800\n",
      "17/17 [==============================] - 0s 721us/step - loss: 0.2494 - accuracy: 0.9308\n",
      "Epoch 449/800\n",
      "17/17 [==============================] - 0s 720us/step - loss: 0.2529 - accuracy: 0.9269\n",
      "Epoch 450/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.2479 - accuracy: 0.9308\n",
      "Epoch 451/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.2515 - accuracy: 0.9269\n",
      "Epoch 452/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.2539 - accuracy: 0.9269\n",
      "Epoch 453/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.2560 - accuracy: 0.9269\n",
      "Epoch 454/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.2469 - accuracy: 0.9231\n",
      "Epoch 455/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.2440 - accuracy: 0.9231\n",
      "Epoch 456/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.2656 - accuracy: 0.9115\n",
      "Epoch 457/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.2687 - accuracy: 0.9000\n",
      "Epoch 458/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.2647 - accuracy: 0.9192\n",
      "Epoch 459/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.2447 - accuracy: 0.9308\n",
      "Epoch 460/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.2421 - accuracy: 0.9308\n",
      "Epoch 461/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.2382 - accuracy: 0.9346\n",
      "Epoch 462/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.2415 - accuracy: 0.9308\n",
      "Epoch 463/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.2430 - accuracy: 0.9269\n",
      "Epoch 464/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.2478 - accuracy: 0.9269\n",
      "Epoch 465/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.2427 - accuracy: 0.9346\n",
      "Epoch 466/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.2362 - accuracy: 0.9308\n",
      "Epoch 467/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.2578 - accuracy: 0.9192\n",
      "Epoch 468/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.2399 - accuracy: 0.9308\n",
      "Epoch 469/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.2375 - accuracy: 0.9385\n",
      "Epoch 470/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.2331 - accuracy: 0.9346\n",
      "Epoch 471/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.2328 - accuracy: 0.9346\n",
      "Epoch 472/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.2308 - accuracy: 0.9346\n",
      "Epoch 473/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.2291 - accuracy: 0.9308\n",
      "Epoch 474/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.2499 - accuracy: 0.9346\n",
      "Epoch 475/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.2361 - accuracy: 0.9269\n",
      "Epoch 476/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.2536 - accuracy: 0.9154\n",
      "Epoch 477/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.2244 - accuracy: 0.9346\n",
      "Epoch 478/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.2277 - accuracy: 0.9269\n",
      "Epoch 479/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.2275 - accuracy: 0.9308\n",
      "Epoch 480/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.2306 - accuracy: 0.9346\n",
      "Epoch 481/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.2281 - accuracy: 0.9308\n",
      "Epoch 482/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.2265 - accuracy: 0.9308\n",
      "Epoch 483/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.2220 - accuracy: 0.9385\n",
      "Epoch 484/800\n",
      "17/17 [==============================] - 0s 728us/step - loss: 0.2224 - accuracy: 0.9346\n",
      "Epoch 485/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.2197 - accuracy: 0.9385\n",
      "Epoch 486/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.2229 - accuracy: 0.9346\n",
      "Epoch 487/800\n",
      "17/17 [==============================] - 0s 723us/step - loss: 0.2214 - accuracy: 0.9346\n",
      "Epoch 488/800\n",
      "17/17 [==============================] - 0s 719us/step - loss: 0.2198 - accuracy: 0.9423\n",
      "Epoch 489/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.2221 - accuracy: 0.9346\n",
      "Epoch 490/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.2219 - accuracy: 0.9346\n",
      "Epoch 491/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.2292 - accuracy: 0.9346\n",
      "Epoch 492/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.2243 - accuracy: 0.9346\n",
      "Epoch 493/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.2255 - accuracy: 0.9308\n",
      "Epoch 494/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.2180 - accuracy: 0.9269\n",
      "Epoch 495/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.2173 - accuracy: 0.9346\n",
      "Epoch 496/800\n",
      "17/17 [==============================] - 0s 721us/step - loss: 0.2463 - accuracy: 0.9154\n",
      "Epoch 497/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.2253 - accuracy: 0.9269\n",
      "Epoch 498/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.2175 - accuracy: 0.9385\n",
      "Epoch 499/800\n",
      "17/17 [==============================] - 0s 726us/step - loss: 0.2256 - accuracy: 0.9346\n",
      "Epoch 500/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.2137 - accuracy: 0.9385\n",
      "Epoch 501/800\n",
      "17/17 [==============================] - 0s 729us/step - loss: 0.2120 - accuracy: 0.9346\n",
      "Epoch 502/800\n",
      "17/17 [==============================] - 0s 723us/step - loss: 0.2095 - accuracy: 0.9423\n",
      "Epoch 503/800\n",
      "17/17 [==============================] - 0s 728us/step - loss: 0.2066 - accuracy: 0.9423\n",
      "Epoch 504/800\n",
      "17/17 [==============================] - 0s 727us/step - loss: 0.2172 - accuracy: 0.9308\n",
      "Epoch 505/800\n",
      "17/17 [==============================] - 0s 732us/step - loss: 0.2122 - accuracy: 0.9423\n",
      "Epoch 506/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.2144 - accuracy: 0.9308\n",
      "Epoch 507/800\n",
      "17/17 [==============================] - 0s 728us/step - loss: 0.2081 - accuracy: 0.9423\n",
      "Epoch 508/800\n",
      "17/17 [==============================] - 0s 724us/step - loss: 0.2058 - accuracy: 0.9423\n",
      "Epoch 509/800\n",
      "17/17 [==============================] - 0s 732us/step - loss: 0.2032 - accuracy: 0.9385\n",
      "Epoch 510/800\n",
      "17/17 [==============================] - 0s 719us/step - loss: 0.2050 - accuracy: 0.9346\n",
      "Epoch 511/800\n",
      "17/17 [==============================] - 0s 719us/step - loss: 0.2039 - accuracy: 0.9385\n",
      "Epoch 512/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.2093 - accuracy: 0.9346\n",
      "Epoch 513/800\n",
      "17/17 [==============================] - 0s 710us/step - loss: 0.2071 - accuracy: 0.9308\n",
      "Epoch 514/800\n",
      "17/17 [==============================] - 0s 725us/step - loss: 0.2088 - accuracy: 0.9346\n",
      "Epoch 515/800\n",
      "17/17 [==============================] - 0s 721us/step - loss: 0.2029 - accuracy: 0.9346\n",
      "Epoch 516/800\n",
      "17/17 [==============================] - 0s 713us/step - loss: 0.2114 - accuracy: 0.9308\n",
      "Epoch 517/800\n",
      "17/17 [==============================] - 0s 724us/step - loss: 0.2051 - accuracy: 0.9385\n",
      "Epoch 518/800\n",
      "17/17 [==============================] - 0s 722us/step - loss: 0.2068 - accuracy: 0.9346\n",
      "Epoch 519/800\n",
      "17/17 [==============================] - 0s 717us/step - loss: 0.1965 - accuracy: 0.9462\n",
      "Epoch 520/800\n",
      "17/17 [==============================] - 0s 724us/step - loss: 0.2053 - accuracy: 0.9269\n",
      "Epoch 521/800\n",
      "17/17 [==============================] - 0s 721us/step - loss: 0.2107 - accuracy: 0.9346\n",
      "Epoch 522/800\n",
      "17/17 [==============================] - 0s 723us/step - loss: 0.2032 - accuracy: 0.9346\n",
      "Epoch 523/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.2051 - accuracy: 0.9385\n",
      "Epoch 524/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.1967 - accuracy: 0.9423\n",
      "Epoch 525/800\n",
      "17/17 [==============================] - 0s 722us/step - loss: 0.1999 - accuracy: 0.9269\n",
      "Epoch 526/800\n",
      "17/17 [==============================] - 0s 726us/step - loss: 0.1915 - accuracy: 0.9385\n",
      "Epoch 527/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.2009 - accuracy: 0.9385\n",
      "Epoch 528/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.1946 - accuracy: 0.9346\n",
      "Epoch 529/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.2014 - accuracy: 0.9346\n",
      "Epoch 530/800\n",
      "17/17 [==============================] - 0s 728us/step - loss: 0.1962 - accuracy: 0.9346\n",
      "Epoch 531/800\n",
      "17/17 [==============================] - 0s 721us/step - loss: 0.2010 - accuracy: 0.9269\n",
      "Epoch 532/800\n",
      "17/17 [==============================] - 0s 726us/step - loss: 0.1944 - accuracy: 0.9308\n",
      "Epoch 533/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.2055 - accuracy: 0.9269\n",
      "Epoch 534/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.1989 - accuracy: 0.9308\n",
      "Epoch 535/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.1972 - accuracy: 0.9308\n",
      "Epoch 536/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.1895 - accuracy: 0.9385\n",
      "Epoch 537/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.1874 - accuracy: 0.9385\n",
      "Epoch 538/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.1952 - accuracy: 0.9385\n",
      "Epoch 539/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.1878 - accuracy: 0.9500\n",
      "Epoch 540/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.1887 - accuracy: 0.9346\n",
      "Epoch 541/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.1909 - accuracy: 0.9423\n",
      "Epoch 542/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.1927 - accuracy: 0.9385\n",
      "Epoch 543/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.1838 - accuracy: 0.9462\n",
      "Epoch 544/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.1837 - accuracy: 0.9462\n",
      "Epoch 545/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.1802 - accuracy: 0.9462\n",
      "Epoch 546/800\n",
      "17/17 [==============================] - 0s 732us/step - loss: 0.1930 - accuracy: 0.9462\n",
      "Epoch 547/800\n",
      "17/17 [==============================] - 0s 727us/step - loss: 0.1902 - accuracy: 0.9308\n",
      "Epoch 548/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.1847 - accuracy: 0.9423\n",
      "Epoch 549/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.1823 - accuracy: 0.9423\n",
      "Epoch 550/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.1791 - accuracy: 0.9385\n",
      "Epoch 551/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.1824 - accuracy: 0.9385\n",
      "Epoch 552/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.1800 - accuracy: 0.9423\n",
      "Epoch 553/800\n",
      "17/17 [==============================] - 0s 732us/step - loss: 0.1796 - accuracy: 0.9462\n",
      "Epoch 554/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.1929 - accuracy: 0.9385\n",
      "Epoch 555/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.1768 - accuracy: 0.9423\n",
      "Epoch 556/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.1755 - accuracy: 0.9462\n",
      "Epoch 557/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.1773 - accuracy: 0.9462\n",
      "Epoch 558/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.1750 - accuracy: 0.9500\n",
      "Epoch 559/800\n",
      "17/17 [==============================] - 0s 736us/step - loss: 0.1849 - accuracy: 0.9385\n",
      "Epoch 560/800\n",
      "17/17 [==============================] - 0s 725us/step - loss: 0.1739 - accuracy: 0.9423\n",
      "Epoch 561/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.1840 - accuracy: 0.9462\n",
      "Epoch 562/800\n",
      "17/17 [==============================] - 0s 723us/step - loss: 0.1731 - accuracy: 0.9423\n",
      "Epoch 563/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 0.1711 - accuracy: 0.9423\n",
      "Epoch 564/800\n",
      "17/17 [==============================] - 0s 720us/step - loss: 0.1749 - accuracy: 0.9423\n",
      "Epoch 565/800\n",
      "17/17 [==============================] - 0s 722us/step - loss: 0.1722 - accuracy: 0.9500\n",
      "Epoch 566/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.1716 - accuracy: 0.9462\n",
      "Epoch 567/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.1769 - accuracy: 0.9423\n",
      "Epoch 568/800\n",
      "17/17 [==============================] - 0s 724us/step - loss: 0.1732 - accuracy: 0.9423\n",
      "Epoch 569/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.1679 - accuracy: 0.9538\n",
      "Epoch 570/800\n",
      "17/17 [==============================] - 0s 729us/step - loss: 0.1694 - accuracy: 0.9538\n",
      "Epoch 571/800\n",
      "17/17 [==============================] - 0s 733us/step - loss: 0.1666 - accuracy: 0.9538\n",
      "Epoch 572/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.1691 - accuracy: 0.9500\n",
      "Epoch 573/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.1676 - accuracy: 0.9500\n",
      "Epoch 574/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 0.1703 - accuracy: 0.9577\n",
      "Epoch 575/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 0.1651 - accuracy: 0.9538\n",
      "Epoch 576/800\n",
      "17/17 [==============================] - 0s 728us/step - loss: 0.1767 - accuracy: 0.9538\n",
      "Epoch 577/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.1770 - accuracy: 0.9462\n",
      "Epoch 578/800\n",
      "17/17 [==============================] - 0s 718us/step - loss: 0.1686 - accuracy: 0.9500\n",
      "Epoch 579/800\n",
      "17/17 [==============================] - 0s 726us/step - loss: 0.1621 - accuracy: 0.9538\n",
      "Epoch 580/800\n",
      "17/17 [==============================] - 0s 727us/step - loss: 0.1642 - accuracy: 0.9538\n",
      "Epoch 581/800\n",
      "17/17 [==============================] - 0s 727us/step - loss: 0.1623 - accuracy: 0.9538\n",
      "Epoch 582/800\n",
      "17/17 [==============================] - 0s 725us/step - loss: 0.1652 - accuracy: 0.9462\n",
      "Epoch 583/800\n",
      "17/17 [==============================] - 0s 724us/step - loss: 0.1701 - accuracy: 0.9385\n",
      "Epoch 584/800\n",
      "17/17 [==============================] - 0s 728us/step - loss: 0.1762 - accuracy: 0.9462\n",
      "Epoch 585/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 0.1632 - accuracy: 0.9500\n",
      "Epoch 586/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.1625 - accuracy: 0.9538\n",
      "Epoch 587/800\n",
      "17/17 [==============================] - 0s 725us/step - loss: 0.1594 - accuracy: 0.9538\n",
      "Epoch 588/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.1601 - accuracy: 0.9500\n",
      "Epoch 589/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.1647 - accuracy: 0.9538\n",
      "Epoch 590/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.1730 - accuracy: 0.9385\n",
      "Epoch 591/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.1612 - accuracy: 0.9538\n",
      "Epoch 592/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.1811 - accuracy: 0.9346\n",
      "Epoch 593/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.1829 - accuracy: 0.9462\n",
      "Epoch 594/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.1599 - accuracy: 0.9500\n",
      "Epoch 595/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.1579 - accuracy: 0.9500\n",
      "Epoch 596/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.1573 - accuracy: 0.9462\n",
      "Epoch 597/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.1597 - accuracy: 0.9577\n",
      "Epoch 598/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.1583 - accuracy: 0.9538\n",
      "Epoch 599/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.1600 - accuracy: 0.9538\n",
      "Epoch 600/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.1658 - accuracy: 0.9423\n",
      "Epoch 601/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.1817 - accuracy: 0.9462\n",
      "Epoch 602/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.1909 - accuracy: 0.9308\n",
      "Epoch 603/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.1605 - accuracy: 0.9500\n",
      "Epoch 604/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.1603 - accuracy: 0.9500\n",
      "Epoch 605/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.1587 - accuracy: 0.9423\n",
      "Epoch 606/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.1563 - accuracy: 0.9538\n",
      "Epoch 607/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.1559 - accuracy: 0.9462\n",
      "Epoch 608/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.1521 - accuracy: 0.9577\n",
      "Epoch 609/800\n",
      "17/17 [==============================] - 0s 726us/step - loss: 0.1528 - accuracy: 0.9538\n",
      "Epoch 610/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.1543 - accuracy: 0.9577\n",
      "Epoch 611/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.1576 - accuracy: 0.9577\n",
      "Epoch 612/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.1557 - accuracy: 0.9500\n",
      "Epoch 613/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.1511 - accuracy: 0.9538\n",
      "Epoch 614/800\n",
      "17/17 [==============================] - 0s 721us/step - loss: 0.1482 - accuracy: 0.9538\n",
      "Epoch 615/800\n",
      "17/17 [==============================] - 0s 719us/step - loss: 0.1490 - accuracy: 0.9538\n",
      "Epoch 616/800\n",
      "17/17 [==============================] - 0s 725us/step - loss: 0.1523 - accuracy: 0.9577\n",
      "Epoch 617/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.1499 - accuracy: 0.9577\n",
      "Epoch 618/800\n",
      "17/17 [==============================] - 0s 722us/step - loss: 0.1495 - accuracy: 0.9500\n",
      "Epoch 619/800\n",
      "17/17 [==============================] - 0s 729us/step - loss: 0.1465 - accuracy: 0.9538\n",
      "Epoch 620/800\n",
      "17/17 [==============================] - 0s 728us/step - loss: 0.1522 - accuracy: 0.9615\n",
      "Epoch 621/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.1464 - accuracy: 0.9538\n",
      "Epoch 622/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.1561 - accuracy: 0.9500\n",
      "Epoch 623/800\n",
      "17/17 [==============================] - 0s 728us/step - loss: 0.1481 - accuracy: 0.9538\n",
      "Epoch 624/800\n",
      "17/17 [==============================] - 0s 718us/step - loss: 0.1442 - accuracy: 0.9577\n",
      "Epoch 625/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.1448 - accuracy: 0.9577\n",
      "Epoch 626/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.1428 - accuracy: 0.9538\n",
      "Epoch 627/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.1476 - accuracy: 0.9577\n",
      "Epoch 628/800\n",
      "17/17 [==============================] - 0s 723us/step - loss: 0.1503 - accuracy: 0.9577\n",
      "Epoch 629/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.1475 - accuracy: 0.9500\n",
      "Epoch 630/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.1465 - accuracy: 0.9538\n",
      "Epoch 631/800\n",
      "17/17 [==============================] - 0s 718us/step - loss: 0.1441 - accuracy: 0.9577\n",
      "Epoch 632/800\n",
      "17/17 [==============================] - 0s 726us/step - loss: 0.1394 - accuracy: 0.9577\n",
      "Epoch 633/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.1541 - accuracy: 0.9538\n",
      "Epoch 634/800\n",
      "17/17 [==============================] - 0s 724us/step - loss: 0.1483 - accuracy: 0.9615\n",
      "Epoch 635/800\n",
      "17/17 [==============================] - 0s 729us/step - loss: 0.1385 - accuracy: 0.9577\n",
      "Epoch 636/800\n",
      "17/17 [==============================] - 0s 726us/step - loss: 0.1412 - accuracy: 0.9538\n",
      "Epoch 637/800\n",
      "17/17 [==============================] - 0s 736us/step - loss: 0.1423 - accuracy: 0.9577\n",
      "Epoch 638/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.1385 - accuracy: 0.9538\n",
      "Epoch 639/800\n",
      "17/17 [==============================] - 0s 723us/step - loss: 0.1394 - accuracy: 0.9577\n",
      "Epoch 640/800\n",
      "17/17 [==============================] - 0s 712us/step - loss: 0.1368 - accuracy: 0.9538\n",
      "Epoch 641/800\n",
      "17/17 [==============================] - 0s 736us/step - loss: 0.1398 - accuracy: 0.9577\n",
      "Epoch 642/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.1357 - accuracy: 0.9577\n",
      "Epoch 643/800\n",
      "17/17 [==============================] - 0s 724us/step - loss: 0.1353 - accuracy: 0.9577\n",
      "Epoch 644/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.1366 - accuracy: 0.9500\n",
      "Epoch 645/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.1429 - accuracy: 0.9577\n",
      "Epoch 646/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.1553 - accuracy: 0.9385\n",
      "Epoch 647/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.1698 - accuracy: 0.9423\n",
      "Epoch 648/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.1540 - accuracy: 0.9500\n",
      "Epoch 649/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.1448 - accuracy: 0.9462\n",
      "Epoch 650/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.1354 - accuracy: 0.9577\n",
      "Epoch 651/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.1342 - accuracy: 0.9538\n",
      "Epoch 652/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.1374 - accuracy: 0.9538\n",
      "Epoch 653/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.1357 - accuracy: 0.9500\n",
      "Epoch 654/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.1405 - accuracy: 0.9577\n",
      "Epoch 655/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.1375 - accuracy: 0.9577\n",
      "Epoch 656/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.1303 - accuracy: 0.9577\n",
      "Epoch 657/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.1296 - accuracy: 0.9577\n",
      "Epoch 658/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.1332 - accuracy: 0.9538\n",
      "Epoch 659/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.1318 - accuracy: 0.9538\n",
      "Epoch 660/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.1326 - accuracy: 0.9577\n",
      "Epoch 661/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.1305 - accuracy: 0.9577\n",
      "Epoch 662/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.1298 - accuracy: 0.9577\n",
      "Epoch 663/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.1318 - accuracy: 0.9538\n",
      "Epoch 664/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.1333 - accuracy: 0.9577\n",
      "Epoch 665/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.1337 - accuracy: 0.9577\n",
      "Epoch 666/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.1655 - accuracy: 0.9423\n",
      "Epoch 667/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.1401 - accuracy: 0.9538\n",
      "Epoch 668/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.1871 - accuracy: 0.9385\n",
      "Epoch 669/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.1397 - accuracy: 0.9577\n",
      "Epoch 670/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.1371 - accuracy: 0.9615\n",
      "Epoch 671/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.1252 - accuracy: 0.9654\n",
      "Epoch 672/800\n",
      "17/17 [==============================] - 0s 726us/step - loss: 0.1288 - accuracy: 0.9654\n",
      "Epoch 673/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.1262 - accuracy: 0.9615\n",
      "Epoch 674/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.1244 - accuracy: 0.9615\n",
      "Epoch 675/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 0.1223 - accuracy: 0.9615\n",
      "Epoch 676/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.1231 - accuracy: 0.9615\n",
      "Epoch 677/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.1229 - accuracy: 0.9615\n",
      "Epoch 678/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.1271 - accuracy: 0.9615\n",
      "Epoch 679/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 0.1217 - accuracy: 0.9577\n",
      "Epoch 680/800\n",
      "17/17 [==============================] - 0s 715us/step - loss: 0.1316 - accuracy: 0.9654\n",
      "Epoch 681/800\n",
      "17/17 [==============================] - 0s 717us/step - loss: 0.1245 - accuracy: 0.9615\n",
      "Epoch 682/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.1306 - accuracy: 0.9615\n",
      "Epoch 683/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.1255 - accuracy: 0.9577\n",
      "Epoch 684/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.1237 - accuracy: 0.9615\n",
      "Epoch 685/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.1217 - accuracy: 0.9654\n",
      "Epoch 686/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.1225 - accuracy: 0.9654\n",
      "Epoch 687/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.1216 - accuracy: 0.9654\n",
      "Epoch 688/800\n",
      "17/17 [==============================] - 0s 732us/step - loss: 0.1201 - accuracy: 0.9654\n",
      "Epoch 689/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.1188 - accuracy: 0.9654\n",
      "Epoch 690/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.1218 - accuracy: 0.9615\n",
      "Epoch 691/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.1245 - accuracy: 0.9615\n",
      "Epoch 692/800\n",
      "17/17 [==============================] - 0s 733us/step - loss: 0.1215 - accuracy: 0.9615\n",
      "Epoch 693/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.1243 - accuracy: 0.9615\n",
      "Epoch 694/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.1167 - accuracy: 0.9654\n",
      "Epoch 695/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.1196 - accuracy: 0.9615\n",
      "Epoch 696/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.1165 - accuracy: 0.9615\n",
      "Epoch 697/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.1177 - accuracy: 0.9654\n",
      "Epoch 698/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.1294 - accuracy: 0.9654\n",
      "Epoch 699/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.1322 - accuracy: 0.9538\n",
      "Epoch 700/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.1342 - accuracy: 0.9731\n",
      "Epoch 701/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.1345 - accuracy: 0.9692\n",
      "Epoch 702/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.1203 - accuracy: 0.9654\n",
      "Epoch 703/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.1158 - accuracy: 0.9692\n",
      "Epoch 704/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.1171 - accuracy: 0.9615\n",
      "Epoch 705/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.1160 - accuracy: 0.9654\n",
      "Epoch 706/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.1154 - accuracy: 0.9692\n",
      "Epoch 707/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.1166 - accuracy: 0.9654\n",
      "Epoch 708/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.1142 - accuracy: 0.9654\n",
      "Epoch 709/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.1150 - accuracy: 0.9615\n",
      "Epoch 710/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.1328 - accuracy: 0.9577\n",
      "Epoch 711/800\n",
      "17/17 [==============================] - 0s 726us/step - loss: 0.1175 - accuracy: 0.9654\n",
      "Epoch 712/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.1121 - accuracy: 0.9615\n",
      "Epoch 713/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.1157 - accuracy: 0.9692\n",
      "Epoch 714/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.1146 - accuracy: 0.9654\n",
      "Epoch 715/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.1110 - accuracy: 0.9731\n",
      "Epoch 716/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.1122 - accuracy: 0.9692\n",
      "Epoch 717/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.1117 - accuracy: 0.9731\n",
      "Epoch 718/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.1115 - accuracy: 0.9731\n",
      "Epoch 719/800\n",
      "17/17 [==============================] - 0s 727us/step - loss: 0.1108 - accuracy: 0.9615\n",
      "Epoch 720/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.1135 - accuracy: 0.9692\n",
      "Epoch 721/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.1170 - accuracy: 0.9692\n",
      "Epoch 722/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.1169 - accuracy: 0.9615\n",
      "Epoch 723/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.1322 - accuracy: 0.9577\n",
      "Epoch 724/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.1072 - accuracy: 0.9692\n",
      "Epoch 725/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.1096 - accuracy: 0.9731\n",
      "Epoch 726/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.1097 - accuracy: 0.9731\n",
      "Epoch 727/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.1210 - accuracy: 0.9654\n",
      "Epoch 728/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.1166 - accuracy: 0.9654\n",
      "Epoch 729/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.1163 - accuracy: 0.9692\n",
      "Epoch 730/800\n",
      "17/17 [==============================] - 0s 719us/step - loss: 0.1151 - accuracy: 0.9731\n",
      "Epoch 731/800\n",
      "17/17 [==============================] - 0s 720us/step - loss: 0.1183 - accuracy: 0.9654\n",
      "Epoch 732/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.1402 - accuracy: 0.9577\n",
      "Epoch 733/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.1271 - accuracy: 0.9654\n",
      "Epoch 734/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.1263 - accuracy: 0.9731\n",
      "Epoch 735/800\n",
      "17/17 [==============================] - 0s 732us/step - loss: 0.1062 - accuracy: 0.9654\n",
      "Epoch 736/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.1051 - accuracy: 0.9692\n",
      "Epoch 737/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.1085 - accuracy: 0.9769\n",
      "Epoch 738/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.1044 - accuracy: 0.9692\n",
      "Epoch 739/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.1059 - accuracy: 0.9731\n",
      "Epoch 740/800\n",
      "17/17 [==============================] - 0s 726us/step - loss: 0.1072 - accuracy: 0.9731\n",
      "Epoch 741/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.1052 - accuracy: 0.9731\n",
      "Epoch 742/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.1025 - accuracy: 0.9692\n",
      "Epoch 743/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.1174 - accuracy: 0.9615\n",
      "Epoch 744/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.1101 - accuracy: 0.9654\n",
      "Epoch 745/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.1062 - accuracy: 0.9731\n",
      "Epoch 746/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.1059 - accuracy: 0.9692\n",
      "Epoch 747/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.1011 - accuracy: 0.9731\n",
      "Epoch 748/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.0997 - accuracy: 0.9769\n",
      "Epoch 749/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.1004 - accuracy: 0.9769\n",
      "Epoch 750/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.0995 - accuracy: 0.9731\n",
      "Epoch 751/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.1047 - accuracy: 0.9769\n",
      "Epoch 752/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.1005 - accuracy: 0.9769\n",
      "Epoch 753/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.1079 - accuracy: 0.9692\n",
      "Epoch 754/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.1042 - accuracy: 0.9769\n",
      "Epoch 755/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.1009 - accuracy: 0.9731\n",
      "Epoch 756/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.0983 - accuracy: 0.9731\n",
      "Epoch 757/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.1022 - accuracy: 0.9769\n",
      "Epoch 758/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.1048 - accuracy: 0.9731\n",
      "Epoch 759/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.0993 - accuracy: 0.9808\n",
      "Epoch 760/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.1063 - accuracy: 0.9731\n",
      "Epoch 761/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.1052 - accuracy: 0.9731\n",
      "Epoch 762/800\n",
      "17/17 [==============================] - 0s 736us/step - loss: 0.1005 - accuracy: 0.9769\n",
      "Epoch 763/800\n",
      "17/17 [==============================] - 0s 733us/step - loss: 0.1071 - accuracy: 0.9654\n",
      "Epoch 764/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.0984 - accuracy: 0.9654\n",
      "Epoch 765/800\n",
      "17/17 [==============================] - 0s 736us/step - loss: 0.0986 - accuracy: 0.9692\n",
      "Epoch 766/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.0949 - accuracy: 0.9731\n",
      "Epoch 767/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.0959 - accuracy: 0.9769\n",
      "Epoch 768/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.0975 - accuracy: 0.9769\n",
      "Epoch 769/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.1034 - accuracy: 0.9692\n",
      "Epoch 770/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.1170 - accuracy: 0.9654\n",
      "Epoch 771/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.1129 - accuracy: 0.9731\n",
      "Epoch 772/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.0992 - accuracy: 0.9692\n",
      "Epoch 773/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.0974 - accuracy: 0.9769\n",
      "Epoch 774/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.1005 - accuracy: 0.9731\n",
      "Epoch 775/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.0929 - accuracy: 0.9769\n",
      "Epoch 776/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.0975 - accuracy: 0.9731\n",
      "Epoch 777/800\n",
      "17/17 [==============================] - 0s 779us/step - loss: 0.0921 - accuracy: 0.9769\n",
      "Epoch 778/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.0925 - accuracy: 0.9731\n",
      "Epoch 779/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.0909 - accuracy: 0.9769\n",
      "Epoch 780/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.0929 - accuracy: 0.9769\n",
      "Epoch 781/800\n",
      "17/17 [==============================] - 0s 733us/step - loss: 0.0949 - accuracy: 0.9731\n",
      "Epoch 782/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.0994 - accuracy: 0.9692\n",
      "Epoch 783/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.0923 - accuracy: 0.9769\n",
      "Epoch 784/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.0923 - accuracy: 0.9769\n",
      "Epoch 785/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.0928 - accuracy: 0.9769\n",
      "Epoch 786/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.0932 - accuracy: 0.9731\n",
      "Epoch 787/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.0925 - accuracy: 0.9769\n",
      "Epoch 788/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.0878 - accuracy: 0.9769\n",
      "Epoch 789/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.0949 - accuracy: 0.9769\n",
      "Epoch 790/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.0924 - accuracy: 0.9769\n",
      "Epoch 791/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.0933 - accuracy: 0.9808\n",
      "Epoch 792/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.0924 - accuracy: 0.9731\n",
      "Epoch 793/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.0928 - accuracy: 0.9769\n",
      "Epoch 794/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.0904 - accuracy: 0.9769\n",
      "Epoch 795/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.0903 - accuracy: 0.9808\n",
      "Epoch 796/800\n",
      "17/17 [==============================] - 0s 732us/step - loss: 0.0949 - accuracy: 0.9769\n",
      "Epoch 797/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.0904 - accuracy: 0.9808\n",
      "Epoch 798/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.0888 - accuracy: 0.9769\n",
      "Epoch 799/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.0882 - accuracy: 0.9731\n",
      "Epoch 800/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.0854 - accuracy: 0.9769\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Epoch 1/800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 220, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 268, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 192, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 221, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 1ms/step - loss: 1.7888 - accuracy: 0.2462\n",
      "Epoch 2/800\n",
      "17/17 [==============================] - 0s 948us/step - loss: 1.7794 - accuracy: 0.2923\n",
      "Epoch 3/800\n",
      "17/17 [==============================] - 0s 963us/step - loss: 1.7597 - accuracy: 0.2923\n",
      "Epoch 4/800\n",
      "17/17 [==============================] - 0s 943us/step - loss: 1.7103 - accuracy: 0.3423\n",
      "Epoch 5/800\n",
      "17/17 [==============================] - 0s 994us/step - loss: 1.6333 - accuracy: 0.5269\n",
      "Epoch 6/800\n",
      "17/17 [==============================] - 0s 913us/step - loss: 1.5404 - accuracy: 0.5038\n",
      "Epoch 7/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 1.4803 - accuracy: 0.4962\n",
      "Epoch 8/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 1.4172 - accuracy: 0.5115\n",
      "Epoch 9/800\n",
      "17/17 [==============================] - 0s 796us/step - loss: 1.3648 - accuracy: 0.5154\n",
      "Epoch 10/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 1.3300 - accuracy: 0.5231\n",
      "Epoch 11/800\n",
      "17/17 [==============================] - 0s 782us/step - loss: 1.3025 - accuracy: 0.5192\n",
      "Epoch 12/800\n",
      "17/17 [==============================] - 0s 804us/step - loss: 1.2808 - accuracy: 0.5192\n",
      "Epoch 13/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 1.2623 - accuracy: 0.5308\n",
      "Epoch 14/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 1.2487 - accuracy: 0.5385\n",
      "Epoch 15/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 1.2277 - accuracy: 0.5462\n",
      "Epoch 16/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 1.2092 - accuracy: 0.5500\n",
      "Epoch 17/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 1.1916 - accuracy: 0.5500\n",
      "Epoch 18/800\n",
      "17/17 [==============================] - 0s 796us/step - loss: 1.1693 - accuracy: 0.5538\n",
      "Epoch 19/800\n",
      "17/17 [==============================] - 0s 806us/step - loss: 1.1568 - accuracy: 0.5654\n",
      "Epoch 20/800\n",
      "17/17 [==============================] - 0s 795us/step - loss: 1.1385 - accuracy: 0.5615\n",
      "Epoch 21/800\n",
      "17/17 [==============================] - 0s 800us/step - loss: 1.1161 - accuracy: 0.5654\n",
      "Epoch 22/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 1.1100 - accuracy: 0.5654\n",
      "Epoch 23/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 1.0964 - accuracy: 0.5654\n",
      "Epoch 24/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 1.0873 - accuracy: 0.5654\n",
      "Epoch 25/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 1.0774 - accuracy: 0.5654\n",
      "Epoch 26/800\n",
      "17/17 [==============================] - 0s 841us/step - loss: 1.0659 - accuracy: 0.5654\n",
      "Epoch 27/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 1.0564 - accuracy: 0.5654\n",
      "Epoch 28/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 1.0494 - accuracy: 0.5654\n",
      "Epoch 29/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 1.0403 - accuracy: 0.5654\n",
      "Epoch 30/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 1.0347 - accuracy: 0.5654\n",
      "Epoch 31/800\n",
      "17/17 [==============================] - 0s 777us/step - loss: 1.0273 - accuracy: 0.5692\n",
      "Epoch 32/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 1.0206 - accuracy: 0.5731\n",
      "Epoch 33/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 1.0114 - accuracy: 0.5731\n",
      "Epoch 34/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 1.0054 - accuracy: 0.5731\n",
      "Epoch 35/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 1.0029 - accuracy: 0.5769\n",
      "Epoch 36/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.9931 - accuracy: 0.5769\n",
      "Epoch 37/800\n",
      "17/17 [==============================] - 0s 800us/step - loss: 0.9891 - accuracy: 0.5769\n",
      "Epoch 38/800\n",
      "17/17 [==============================] - 0s 775us/step - loss: 0.9813 - accuracy: 0.5769\n",
      "Epoch 39/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.9795 - accuracy: 0.5846\n",
      "Epoch 40/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.9722 - accuracy: 0.5846\n",
      "Epoch 41/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.9690 - accuracy: 0.5846\n",
      "Epoch 42/800\n",
      "17/17 [==============================] - 0s 787us/step - loss: 0.9638 - accuracy: 0.5846\n",
      "Epoch 43/800\n",
      "17/17 [==============================] - 0s 888us/step - loss: 0.9591 - accuracy: 0.5885\n",
      "Epoch 44/800\n",
      "17/17 [==============================] - 0s 778us/step - loss: 0.9529 - accuracy: 0.5923\n",
      "Epoch 45/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.9773 - accuracy: 0.5923\n",
      "Epoch 46/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.9532 - accuracy: 0.5885\n",
      "Epoch 47/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.9360 - accuracy: 0.5962\n",
      "Epoch 48/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.9367 - accuracy: 0.5923\n",
      "Epoch 49/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.9288 - accuracy: 0.5923\n",
      "Epoch 50/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.9245 - accuracy: 0.5885\n",
      "Epoch 51/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.9194 - accuracy: 0.5962\n",
      "Epoch 52/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.9157 - accuracy: 0.6115\n",
      "Epoch 53/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.9108 - accuracy: 0.6115\n",
      "Epoch 54/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.9081 - accuracy: 0.6154\n",
      "Epoch 55/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.9035 - accuracy: 0.6154\n",
      "Epoch 56/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.9027 - accuracy: 0.6231\n",
      "Epoch 57/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.8941 - accuracy: 0.6192\n",
      "Epoch 58/800\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.8888 - accuracy: 0.6154\n",
      "Epoch 59/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.8851 - accuracy: 0.6192\n",
      "Epoch 60/800\n",
      "17/17 [==============================] - 0s 806us/step - loss: 0.8837 - accuracy: 0.6231\n",
      "Epoch 61/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.8912 - accuracy: 0.6192\n",
      "Epoch 62/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.8922 - accuracy: 0.6154\n",
      "Epoch 63/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.9127 - accuracy: 0.6269\n",
      "Epoch 64/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.8779 - accuracy: 0.6269\n",
      "Epoch 65/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.8675 - accuracy: 0.6269\n",
      "Epoch 66/800\n",
      "17/17 [==============================] - 0s 796us/step - loss: 0.8592 - accuracy: 0.6385\n",
      "Epoch 67/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.8542 - accuracy: 0.6423\n",
      "Epoch 68/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.8509 - accuracy: 0.6500\n",
      "Epoch 69/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.8469 - accuracy: 0.6500\n",
      "Epoch 70/800\n",
      "17/17 [==============================] - 0s 867us/step - loss: 0.8469 - accuracy: 0.6423\n",
      "Epoch 71/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.8432 - accuracy: 0.6462\n",
      "Epoch 72/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.8525 - accuracy: 0.6577\n",
      "Epoch 73/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.8385 - accuracy: 0.6577\n",
      "Epoch 74/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.8330 - accuracy: 0.6577\n",
      "Epoch 75/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.8383 - accuracy: 0.6346\n",
      "Epoch 76/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 0.8331 - accuracy: 0.6500\n",
      "Epoch 77/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.8227 - accuracy: 0.6615\n",
      "Epoch 78/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.8117 - accuracy: 0.6577\n",
      "Epoch 79/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.8265 - accuracy: 0.6538\n",
      "Epoch 80/800\n",
      "17/17 [==============================] - 0s 800us/step - loss: 0.8178 - accuracy: 0.6731\n",
      "Epoch 81/800\n",
      "17/17 [==============================] - 0s 826us/step - loss: 0.8044 - accuracy: 0.6577\n",
      "Epoch 82/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.8078 - accuracy: 0.6615\n",
      "Epoch 83/800\n",
      "17/17 [==============================] - 0s 775us/step - loss: 0.8029 - accuracy: 0.6577\n",
      "Epoch 84/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.7961 - accuracy: 0.6577\n",
      "Epoch 85/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.7901 - accuracy: 0.6692\n",
      "Epoch 86/800\n",
      "17/17 [==============================] - 0s 778us/step - loss: 0.7920 - accuracy: 0.6769\n",
      "Epoch 87/800\n",
      "17/17 [==============================] - 0s 804us/step - loss: 0.7869 - accuracy: 0.6654\n",
      "Epoch 88/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.7808 - accuracy: 0.6692\n",
      "Epoch 89/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.7773 - accuracy: 0.6615\n",
      "Epoch 90/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.7765 - accuracy: 0.6692\n",
      "Epoch 91/800\n",
      "17/17 [==============================] - 0s 778us/step - loss: 0.7722 - accuracy: 0.6615\n",
      "Epoch 92/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.7706 - accuracy: 0.6692\n",
      "Epoch 93/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 0.7643 - accuracy: 0.6808\n",
      "Epoch 94/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.7744 - accuracy: 0.6846\n",
      "Epoch 95/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.7680 - accuracy: 0.6808\n",
      "Epoch 96/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.7569 - accuracy: 0.6846\n",
      "Epoch 97/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.7578 - accuracy: 0.6808\n",
      "Epoch 98/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.7539 - accuracy: 0.6846\n",
      "Epoch 99/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.7648 - accuracy: 0.6731\n",
      "Epoch 100/800\n",
      "17/17 [==============================] - 0s 831us/step - loss: 0.7604 - accuracy: 0.6731\n",
      "Epoch 101/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.7504 - accuracy: 0.6846\n",
      "Epoch 102/800\n",
      "17/17 [==============================] - 0s 777us/step - loss: 0.7372 - accuracy: 0.6846\n",
      "Epoch 103/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.7393 - accuracy: 0.6885\n",
      "Epoch 104/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.7310 - accuracy: 0.6808\n",
      "Epoch 105/800\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.7374 - accuracy: 0.6846\n",
      "Epoch 106/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.7421 - accuracy: 0.6846\n",
      "Epoch 107/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.7283 - accuracy: 0.6962\n",
      "Epoch 108/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.7229 - accuracy: 0.6808\n",
      "Epoch 109/800\n",
      "17/17 [==============================] - 0s 804us/step - loss: 0.7201 - accuracy: 0.6885\n",
      "Epoch 110/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.7179 - accuracy: 0.7000\n",
      "Epoch 111/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.7155 - accuracy: 0.6923\n",
      "Epoch 112/800\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.7165 - accuracy: 0.6962\n",
      "Epoch 113/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.7181 - accuracy: 0.7000\n",
      "Epoch 114/800\n",
      "17/17 [==============================] - 0s 796us/step - loss: 0.7171 - accuracy: 0.7000\n",
      "Epoch 115/800\n",
      "17/17 [==============================] - 0s 800us/step - loss: 0.6999 - accuracy: 0.7115\n",
      "Epoch 116/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.6993 - accuracy: 0.7115\n",
      "Epoch 117/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.6955 - accuracy: 0.7115\n",
      "Epoch 118/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.6985 - accuracy: 0.7000\n",
      "Epoch 119/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.6886 - accuracy: 0.7077\n",
      "Epoch 120/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.7031 - accuracy: 0.7000\n",
      "Epoch 121/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.6909 - accuracy: 0.7192\n",
      "Epoch 122/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.6910 - accuracy: 0.7269\n",
      "Epoch 123/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.6955 - accuracy: 0.7115\n",
      "Epoch 124/800\n",
      "17/17 [==============================] - 0s 782us/step - loss: 0.6890 - accuracy: 0.7231\n",
      "Epoch 125/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.6815 - accuracy: 0.7192\n",
      "Epoch 126/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.6716 - accuracy: 0.7308\n",
      "Epoch 127/800\n",
      "17/17 [==============================] - 0s 842us/step - loss: 0.6832 - accuracy: 0.7115\n",
      "Epoch 128/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.6776 - accuracy: 0.7038\n",
      "Epoch 129/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.6702 - accuracy: 0.7308\n",
      "Epoch 130/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.6670 - accuracy: 0.7269\n",
      "Epoch 131/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.6643 - accuracy: 0.7423\n",
      "Epoch 132/800\n",
      "17/17 [==============================] - 0s 800us/step - loss: 0.6593 - accuracy: 0.7346\n",
      "Epoch 133/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.6589 - accuracy: 0.7385\n",
      "Epoch 134/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.6656 - accuracy: 0.7269\n",
      "Epoch 135/800\n",
      "17/17 [==============================] - 0s 800us/step - loss: 0.6701 - accuracy: 0.7385\n",
      "Epoch 136/800\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.6758 - accuracy: 0.7269\n",
      "Epoch 137/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.6640 - accuracy: 0.7231\n",
      "Epoch 138/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.6591 - accuracy: 0.7231\n",
      "Epoch 139/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.6589 - accuracy: 0.7500\n",
      "Epoch 140/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.6487 - accuracy: 0.7308\n",
      "Epoch 141/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.6529 - accuracy: 0.7462\n",
      "Epoch 142/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.6463 - accuracy: 0.7346\n",
      "Epoch 143/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.6595 - accuracy: 0.7462\n",
      "Epoch 144/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.6370 - accuracy: 0.7577\n",
      "Epoch 145/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.6357 - accuracy: 0.7500\n",
      "Epoch 146/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.6398 - accuracy: 0.7654\n",
      "Epoch 147/800\n",
      "17/17 [==============================] - 0s 806us/step - loss: 0.6386 - accuracy: 0.7577\n",
      "Epoch 148/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.6305 - accuracy: 0.7462\n",
      "Epoch 149/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.6305 - accuracy: 0.7577\n",
      "Epoch 150/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.6281 - accuracy: 0.7462\n",
      "Epoch 151/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.6265 - accuracy: 0.7385\n",
      "Epoch 152/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.6271 - accuracy: 0.7615\n",
      "Epoch 153/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.6265 - accuracy: 0.7654\n",
      "Epoch 154/800\n",
      "17/17 [==============================] - 0s 796us/step - loss: 0.6200 - accuracy: 0.7346\n",
      "Epoch 155/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 0.6213 - accuracy: 0.7731\n",
      "Epoch 156/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.6204 - accuracy: 0.7731\n",
      "Epoch 157/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.6370 - accuracy: 0.7692\n",
      "Epoch 158/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.6202 - accuracy: 0.7654\n",
      "Epoch 159/800\n",
      "17/17 [==============================] - 0s 800us/step - loss: 0.6151 - accuracy: 0.7769\n",
      "Epoch 160/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.6149 - accuracy: 0.7692\n",
      "Epoch 161/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.6177 - accuracy: 0.7577\n",
      "Epoch 162/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.6320 - accuracy: 0.7500\n",
      "Epoch 163/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.6250 - accuracy: 0.7615\n",
      "Epoch 164/800\n",
      "17/17 [==============================] - 0s 795us/step - loss: 0.6250 - accuracy: 0.7577\n",
      "Epoch 165/800\n",
      "17/17 [==============================] - 0s 822us/step - loss: 0.6162 - accuracy: 0.7808\n",
      "Epoch 166/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.6073 - accuracy: 0.7846\n",
      "Epoch 167/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.6076 - accuracy: 0.7731\n",
      "Epoch 168/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.6050 - accuracy: 0.7923\n",
      "Epoch 169/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.6198 - accuracy: 0.7462\n",
      "Epoch 170/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.6114 - accuracy: 0.7769\n",
      "Epoch 171/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.6091 - accuracy: 0.7769\n",
      "Epoch 172/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.6004 - accuracy: 0.7808\n",
      "Epoch 173/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.5971 - accuracy: 0.7808\n",
      "Epoch 174/800\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.6054 - accuracy: 0.7731\n",
      "Epoch 175/800\n",
      "17/17 [==============================] - 0s 817us/step - loss: 0.6029 - accuracy: 0.7808\n",
      "Epoch 176/800\n",
      "17/17 [==============================] - 0s 817us/step - loss: 0.6033 - accuracy: 0.7885\n",
      "Epoch 177/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.5933 - accuracy: 0.7885\n",
      "Epoch 178/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.5993 - accuracy: 0.7846\n",
      "Epoch 179/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.5984 - accuracy: 0.7731\n",
      "Epoch 180/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.6027 - accuracy: 0.7692\n",
      "Epoch 181/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.6056 - accuracy: 0.7769\n",
      "Epoch 182/800\n",
      "17/17 [==============================] - 0s 822us/step - loss: 0.6108 - accuracy: 0.7654\n",
      "Epoch 183/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.5947 - accuracy: 0.7846\n",
      "Epoch 184/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.6073 - accuracy: 0.7692\n",
      "Epoch 185/800\n",
      "17/17 [==============================] - 0s 806us/step - loss: 0.5868 - accuracy: 0.7923\n",
      "Epoch 186/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.5933 - accuracy: 0.7846\n",
      "Epoch 187/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.5894 - accuracy: 0.7808\n",
      "Epoch 188/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.5921 - accuracy: 0.7769\n",
      "Epoch 189/800\n",
      "17/17 [==============================] - 0s 787us/step - loss: 0.5902 - accuracy: 0.7885\n",
      "Epoch 190/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.5812 - accuracy: 0.7885\n",
      "Epoch 191/800\n",
      "17/17 [==============================] - 0s 795us/step - loss: 0.5858 - accuracy: 0.7769\n",
      "Epoch 192/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.6175 - accuracy: 0.7577\n",
      "Epoch 193/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.6143 - accuracy: 0.7538\n",
      "Epoch 194/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.5859 - accuracy: 0.7846\n",
      "Epoch 195/800\n",
      "17/17 [==============================] - 0s 795us/step - loss: 0.5829 - accuracy: 0.7962\n",
      "Epoch 196/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.5780 - accuracy: 0.8000\n",
      "Epoch 197/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.5790 - accuracy: 0.8000\n",
      "Epoch 198/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.5727 - accuracy: 0.7962\n",
      "Epoch 199/800\n",
      "17/17 [==============================] - 0s 795us/step - loss: 0.5803 - accuracy: 0.7962\n",
      "Epoch 200/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.5819 - accuracy: 0.7923\n",
      "Epoch 201/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.5827 - accuracy: 0.8000\n",
      "Epoch 202/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.5701 - accuracy: 0.7962\n",
      "Epoch 203/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.5719 - accuracy: 0.7923\n",
      "Epoch 204/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.5698 - accuracy: 0.8000\n",
      "Epoch 205/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.5733 - accuracy: 0.7885\n",
      "Epoch 206/800\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.5715 - accuracy: 0.7846\n",
      "Epoch 207/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.5692 - accuracy: 0.7923\n",
      "Epoch 208/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.5679 - accuracy: 0.8000\n",
      "Epoch 209/800\n",
      "17/17 [==============================] - 0s 787us/step - loss: 0.5807 - accuracy: 0.7923\n",
      "Epoch 210/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.5785 - accuracy: 0.7885\n",
      "Epoch 211/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.5728 - accuracy: 0.7923\n",
      "Epoch 212/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.5670 - accuracy: 0.7962\n",
      "Epoch 213/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.5652 - accuracy: 0.8038\n",
      "Epoch 214/800\n",
      "17/17 [==============================] - 0s 804us/step - loss: 0.5768 - accuracy: 0.7962\n",
      "Epoch 215/800\n",
      "17/17 [==============================] - 0s 806us/step - loss: 0.5728 - accuracy: 0.8000\n",
      "Epoch 216/800\n",
      "17/17 [==============================] - 0s 779us/step - loss: 0.5689 - accuracy: 0.7923\n",
      "Epoch 217/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.5658 - accuracy: 0.7962\n",
      "Epoch 218/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.5637 - accuracy: 0.8038\n",
      "Epoch 219/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.5702 - accuracy: 0.7846\n",
      "Epoch 220/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.6016 - accuracy: 0.7808\n",
      "Epoch 221/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.5637 - accuracy: 0.7885\n",
      "Epoch 222/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.5615 - accuracy: 0.7846\n",
      "Epoch 223/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.5652 - accuracy: 0.8000\n",
      "Epoch 224/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 0.5596 - accuracy: 0.7923\n",
      "Epoch 225/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.5591 - accuracy: 0.7846\n",
      "Epoch 226/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.5680 - accuracy: 0.7885\n",
      "Epoch 227/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.5614 - accuracy: 0.7962\n",
      "Epoch 228/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.5605 - accuracy: 0.7962\n",
      "Epoch 229/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.5593 - accuracy: 0.7962\n",
      "Epoch 230/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.5645 - accuracy: 0.7885\n",
      "Epoch 231/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.5695 - accuracy: 0.7808\n",
      "Epoch 232/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.5522 - accuracy: 0.7923\n",
      "Epoch 233/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.5563 - accuracy: 0.8000\n",
      "Epoch 234/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.5570 - accuracy: 0.7923\n",
      "Epoch 235/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.5773 - accuracy: 0.7808\n",
      "Epoch 236/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.5496 - accuracy: 0.8000\n",
      "Epoch 237/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.5505 - accuracy: 0.7923\n",
      "Epoch 238/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.5669 - accuracy: 0.7885\n",
      "Epoch 239/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.5507 - accuracy: 0.7962\n",
      "Epoch 240/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.5480 - accuracy: 0.8000\n",
      "Epoch 241/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.5680 - accuracy: 0.8038\n",
      "Epoch 242/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.5586 - accuracy: 0.7962\n",
      "Epoch 243/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.5465 - accuracy: 0.7962\n",
      "Epoch 244/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.5414 - accuracy: 0.8000\n",
      "Epoch 245/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.5448 - accuracy: 0.7962\n",
      "Epoch 246/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.5504 - accuracy: 0.7923\n",
      "Epoch 247/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.5405 - accuracy: 0.8038\n",
      "Epoch 248/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.5545 - accuracy: 0.7769\n",
      "Epoch 249/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.5462 - accuracy: 0.7962\n",
      "Epoch 250/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.5695 - accuracy: 0.7923\n",
      "Epoch 251/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.5432 - accuracy: 0.7962\n",
      "Epoch 252/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.5432 - accuracy: 0.7846\n",
      "Epoch 253/800\n",
      "17/17 [==============================] - 0s 772us/step - loss: 0.5449 - accuracy: 0.7885\n",
      "Epoch 254/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.5887 - accuracy: 0.7885\n",
      "Epoch 255/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.5444 - accuracy: 0.8154\n",
      "Epoch 256/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.5348 - accuracy: 0.8000\n",
      "Epoch 257/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.5560 - accuracy: 0.7769\n",
      "Epoch 258/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.5380 - accuracy: 0.7923\n",
      "Epoch 259/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.5421 - accuracy: 0.7808\n",
      "Epoch 260/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.5363 - accuracy: 0.8000\n",
      "Epoch 261/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.5322 - accuracy: 0.8000\n",
      "Epoch 262/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.5364 - accuracy: 0.7923\n",
      "Epoch 263/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.5470 - accuracy: 0.7885\n",
      "Epoch 264/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.5359 - accuracy: 0.8038\n",
      "Epoch 265/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.5422 - accuracy: 0.8000\n",
      "Epoch 266/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 0.5348 - accuracy: 0.8077\n",
      "Epoch 267/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.5460 - accuracy: 0.7962\n",
      "Epoch 268/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.5416 - accuracy: 0.7846\n",
      "Epoch 269/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.5398 - accuracy: 0.7923\n",
      "Epoch 270/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.5342 - accuracy: 0.7962\n",
      "Epoch 271/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.5253 - accuracy: 0.8115\n",
      "Epoch 272/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.5268 - accuracy: 0.8038\n",
      "Epoch 273/800\n",
      "17/17 [==============================] - 0s 728us/step - loss: 0.5459 - accuracy: 0.7885\n",
      "Epoch 274/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.5323 - accuracy: 0.8000\n",
      "Epoch 275/800\n",
      "17/17 [==============================] - 0s 732us/step - loss: 0.5282 - accuracy: 0.8115\n",
      "Epoch 276/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.5509 - accuracy: 0.7962\n",
      "Epoch 277/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.5330 - accuracy: 0.8038\n",
      "Epoch 278/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.5197 - accuracy: 0.8000\n",
      "Epoch 279/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.5244 - accuracy: 0.8000\n",
      "Epoch 280/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.5251 - accuracy: 0.7923\n",
      "Epoch 281/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.5193 - accuracy: 0.8000\n",
      "Epoch 282/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.5175 - accuracy: 0.8000\n",
      "Epoch 283/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.5166 - accuracy: 0.8077\n",
      "Epoch 284/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.5185 - accuracy: 0.7923\n",
      "Epoch 285/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.5234 - accuracy: 0.7923\n",
      "Epoch 286/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.5224 - accuracy: 0.8077\n",
      "Epoch 287/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 0.5136 - accuracy: 0.8000\n",
      "Epoch 288/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.5150 - accuracy: 0.7923\n",
      "Epoch 289/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.5213 - accuracy: 0.7962\n",
      "Epoch 290/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.5174 - accuracy: 0.8115\n",
      "Epoch 291/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.5136 - accuracy: 0.8038\n",
      "Epoch 292/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.5283 - accuracy: 0.8077\n",
      "Epoch 293/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.5527 - accuracy: 0.7808\n",
      "Epoch 294/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.5196 - accuracy: 0.7885\n",
      "Epoch 295/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.5137 - accuracy: 0.8077\n",
      "Epoch 296/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.5120 - accuracy: 0.8115\n",
      "Epoch 297/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.5074 - accuracy: 0.8154\n",
      "Epoch 298/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.5085 - accuracy: 0.8038\n",
      "Epoch 299/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.5116 - accuracy: 0.8115\n",
      "Epoch 300/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.5138 - accuracy: 0.8000\n",
      "Epoch 301/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.5183 - accuracy: 0.8000\n",
      "Epoch 302/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.5118 - accuracy: 0.8000\n",
      "Epoch 303/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.5090 - accuracy: 0.8077\n",
      "Epoch 304/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.5108 - accuracy: 0.7962\n",
      "Epoch 305/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.5066 - accuracy: 0.8000\n",
      "Epoch 306/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.5059 - accuracy: 0.8154\n",
      "Epoch 307/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.5070 - accuracy: 0.8038\n",
      "Epoch 308/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.5045 - accuracy: 0.8038\n",
      "Epoch 309/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.5031 - accuracy: 0.8077\n",
      "Epoch 310/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.5100 - accuracy: 0.8000\n",
      "Epoch 311/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.4999 - accuracy: 0.8269\n",
      "Epoch 312/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.5052 - accuracy: 0.8038\n",
      "Epoch 313/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.5019 - accuracy: 0.8115\n",
      "Epoch 314/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.5074 - accuracy: 0.7962\n",
      "Epoch 315/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.5014 - accuracy: 0.8038\n",
      "Epoch 316/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.4993 - accuracy: 0.8308\n",
      "Epoch 317/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.5288 - accuracy: 0.8000\n",
      "Epoch 318/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.5005 - accuracy: 0.8192\n",
      "Epoch 319/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.5000 - accuracy: 0.8192\n",
      "Epoch 320/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.5200 - accuracy: 0.8038\n",
      "Epoch 321/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.5006 - accuracy: 0.8192\n",
      "Epoch 322/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.5030 - accuracy: 0.8115\n",
      "Epoch 323/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.5036 - accuracy: 0.8154\n",
      "Epoch 324/800\n",
      "17/17 [==============================] - 0s 772us/step - loss: 0.5043 - accuracy: 0.7962\n",
      "Epoch 325/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.5173 - accuracy: 0.8000\n",
      "Epoch 326/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.5113 - accuracy: 0.8038\n",
      "Epoch 327/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.5139 - accuracy: 0.8077\n",
      "Epoch 328/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.5372 - accuracy: 0.7846\n",
      "Epoch 329/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.5167 - accuracy: 0.8077\n",
      "Epoch 330/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.5143 - accuracy: 0.8038\n",
      "Epoch 331/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.4927 - accuracy: 0.8269\n",
      "Epoch 332/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.4971 - accuracy: 0.8077\n",
      "Epoch 333/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.4927 - accuracy: 0.8231\n",
      "Epoch 334/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.5085 - accuracy: 0.8115\n",
      "Epoch 335/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.4942 - accuracy: 0.8231\n",
      "Epoch 336/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.4916 - accuracy: 0.8154\n",
      "Epoch 337/800\n",
      "17/17 [==============================] - 0s 729us/step - loss: 0.4941 - accuracy: 0.8269\n",
      "Epoch 338/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.4958 - accuracy: 0.8000\n",
      "Epoch 339/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.4897 - accuracy: 0.8077\n",
      "Epoch 340/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.4925 - accuracy: 0.8000\n",
      "Epoch 341/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.4884 - accuracy: 0.8115\n",
      "Epoch 342/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.4873 - accuracy: 0.8154\n",
      "Epoch 343/800\n",
      "17/17 [==============================] - 0s 831us/step - loss: 0.4915 - accuracy: 0.8154\n",
      "Epoch 344/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.4959 - accuracy: 0.8154\n",
      "Epoch 345/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.4882 - accuracy: 0.8115\n",
      "Epoch 346/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.4946 - accuracy: 0.8038\n",
      "Epoch 347/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.4865 - accuracy: 0.8231\n",
      "Epoch 348/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.4984 - accuracy: 0.8192\n",
      "Epoch 349/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.4925 - accuracy: 0.8077\n",
      "Epoch 350/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.4865 - accuracy: 0.8154\n",
      "Epoch 351/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.4992 - accuracy: 0.8077\n",
      "Epoch 352/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.4851 - accuracy: 0.8308\n",
      "Epoch 353/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.4864 - accuracy: 0.8115\n",
      "Epoch 354/800\n",
      "17/17 [==============================] - 0s 775us/step - loss: 0.4878 - accuracy: 0.8115\n",
      "Epoch 355/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.4831 - accuracy: 0.8231\n",
      "Epoch 356/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.4964 - accuracy: 0.8077\n",
      "Epoch 357/800\n",
      "17/17 [==============================] - 0s 800us/step - loss: 0.4834 - accuracy: 0.8269\n",
      "Epoch 358/800\n",
      "17/17 [==============================] - 0s 775us/step - loss: 0.4850 - accuracy: 0.8192\n",
      "Epoch 359/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.4822 - accuracy: 0.8154\n",
      "Epoch 360/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.4817 - accuracy: 0.8192\n",
      "Epoch 361/800\n",
      "17/17 [==============================] - 0s 772us/step - loss: 0.4874 - accuracy: 0.8077\n",
      "Epoch 362/800\n",
      "17/17 [==============================] - 0s 829us/step - loss: 0.4824 - accuracy: 0.8154\n",
      "Epoch 363/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.4866 - accuracy: 0.8192\n",
      "Epoch 364/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.4799 - accuracy: 0.8192\n",
      "Epoch 365/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.4782 - accuracy: 0.8192\n",
      "Epoch 366/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.4804 - accuracy: 0.8077\n",
      "Epoch 367/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.4911 - accuracy: 0.8154\n",
      "Epoch 368/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.4758 - accuracy: 0.8115\n",
      "Epoch 369/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 0.4750 - accuracy: 0.8231\n",
      "Epoch 370/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.4782 - accuracy: 0.8154\n",
      "Epoch 371/800\n",
      "17/17 [==============================] - 0s 804us/step - loss: 0.4804 - accuracy: 0.8115\n",
      "Epoch 372/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.4728 - accuracy: 0.8154\n",
      "Epoch 373/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.4857 - accuracy: 0.8154\n",
      "Epoch 374/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.4755 - accuracy: 0.8231\n",
      "Epoch 375/800\n",
      "17/17 [==============================] - 0s 782us/step - loss: 0.4808 - accuracy: 0.8192\n",
      "Epoch 376/800\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.4818 - accuracy: 0.8192\n",
      "Epoch 377/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.4726 - accuracy: 0.8385\n",
      "Epoch 378/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.4728 - accuracy: 0.8231\n",
      "Epoch 379/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.4942 - accuracy: 0.8154\n",
      "Epoch 380/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.4755 - accuracy: 0.8269\n",
      "Epoch 381/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.4925 - accuracy: 0.8231\n",
      "Epoch 382/800\n",
      "17/17 [==============================] - 0s 787us/step - loss: 0.4724 - accuracy: 0.8154\n",
      "Epoch 383/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.4704 - accuracy: 0.8269\n",
      "Epoch 384/800\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.4744 - accuracy: 0.8231\n",
      "Epoch 385/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.4851 - accuracy: 0.8192\n",
      "Epoch 386/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.4814 - accuracy: 0.8038\n",
      "Epoch 387/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.4867 - accuracy: 0.8077\n",
      "Epoch 388/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.4751 - accuracy: 0.8154\n",
      "Epoch 389/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.4741 - accuracy: 0.8231\n",
      "Epoch 390/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.4715 - accuracy: 0.8231\n",
      "Epoch 391/800\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.4716 - accuracy: 0.8231\n",
      "Epoch 392/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.4895 - accuracy: 0.8038\n",
      "Epoch 393/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.4739 - accuracy: 0.8077\n",
      "Epoch 394/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.4738 - accuracy: 0.8192\n",
      "Epoch 395/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.4738 - accuracy: 0.8231\n",
      "Epoch 396/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.5000 - accuracy: 0.8115\n",
      "Epoch 397/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.4912 - accuracy: 0.8231\n",
      "Epoch 398/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.4970 - accuracy: 0.8192\n",
      "Epoch 399/800\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.4804 - accuracy: 0.8154\n",
      "Epoch 400/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.4718 - accuracy: 0.8231\n",
      "Epoch 401/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.4626 - accuracy: 0.8308\n",
      "Epoch 402/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.4693 - accuracy: 0.8231\n",
      "Epoch 403/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.4655 - accuracy: 0.8269\n",
      "Epoch 404/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.4674 - accuracy: 0.8231\n",
      "Epoch 405/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.4713 - accuracy: 0.8308\n",
      "Epoch 406/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.4755 - accuracy: 0.8346\n",
      "Epoch 407/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.4760 - accuracy: 0.8231\n",
      "Epoch 408/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.4590 - accuracy: 0.8308\n",
      "Epoch 409/800\n",
      "17/17 [==============================] - 0s 796us/step - loss: 0.4618 - accuracy: 0.8308\n",
      "Epoch 410/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.4634 - accuracy: 0.8308\n",
      "Epoch 411/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.4576 - accuracy: 0.8308\n",
      "Epoch 412/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 0.4593 - accuracy: 0.8308\n",
      "Epoch 413/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.4635 - accuracy: 0.8231\n",
      "Epoch 414/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.4603 - accuracy: 0.8269\n",
      "Epoch 415/800\n",
      "17/17 [==============================] - 0s 804us/step - loss: 0.4590 - accuracy: 0.8192\n",
      "Epoch 416/800\n",
      "17/17 [==============================] - 0s 795us/step - loss: 0.4578 - accuracy: 0.8269\n",
      "Epoch 417/800\n",
      "17/17 [==============================] - 0s 804us/step - loss: 0.4622 - accuracy: 0.8115\n",
      "Epoch 418/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.4539 - accuracy: 0.8308\n",
      "Epoch 419/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.4630 - accuracy: 0.8154\n",
      "Epoch 420/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.4653 - accuracy: 0.8308\n",
      "Epoch 421/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.4644 - accuracy: 0.8192\n",
      "Epoch 422/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.4564 - accuracy: 0.8269\n",
      "Epoch 423/800\n",
      "17/17 [==============================] - 0s 800us/step - loss: 0.4783 - accuracy: 0.8385\n",
      "Epoch 424/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.4694 - accuracy: 0.8308\n",
      "Epoch 425/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.4569 - accuracy: 0.8231\n",
      "Epoch 426/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.4700 - accuracy: 0.8192\n",
      "Epoch 427/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.4896 - accuracy: 0.8077\n",
      "Epoch 428/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.4629 - accuracy: 0.8231\n",
      "Epoch 429/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.4546 - accuracy: 0.8385\n",
      "Epoch 430/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.4546 - accuracy: 0.8269\n",
      "Epoch 431/800\n",
      "17/17 [==============================] - 0s 787us/step - loss: 0.4605 - accuracy: 0.8231\n",
      "Epoch 432/800\n",
      "17/17 [==============================] - 0s 782us/step - loss: 0.4557 - accuracy: 0.8346\n",
      "Epoch 433/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.4491 - accuracy: 0.8385\n",
      "Epoch 434/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.4490 - accuracy: 0.8231\n",
      "Epoch 435/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.4489 - accuracy: 0.8308\n",
      "Epoch 436/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.4513 - accuracy: 0.8269\n",
      "Epoch 437/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.4545 - accuracy: 0.8231\n",
      "Epoch 438/800\n",
      "17/17 [==============================] - 0s 787us/step - loss: 0.4583 - accuracy: 0.8231\n",
      "Epoch 439/800\n",
      "17/17 [==============================] - 0s 806us/step - loss: 0.4574 - accuracy: 0.8154\n",
      "Epoch 440/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.4557 - accuracy: 0.8269\n",
      "Epoch 441/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.4513 - accuracy: 0.8385\n",
      "Epoch 442/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.4628 - accuracy: 0.8154\n",
      "Epoch 443/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.4547 - accuracy: 0.8308\n",
      "Epoch 444/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.4446 - accuracy: 0.8308\n",
      "Epoch 445/800\n",
      "17/17 [==============================] - 0s 787us/step - loss: 0.4665 - accuracy: 0.8192\n",
      "Epoch 446/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.4430 - accuracy: 0.8423\n",
      "Epoch 447/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.4457 - accuracy: 0.8346\n",
      "Epoch 448/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.4437 - accuracy: 0.8385\n",
      "Epoch 449/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.4456 - accuracy: 0.8269\n",
      "Epoch 450/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.4458 - accuracy: 0.8346\n",
      "Epoch 451/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.4389 - accuracy: 0.8462\n",
      "Epoch 452/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.4381 - accuracy: 0.8346\n",
      "Epoch 453/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.4462 - accuracy: 0.8269\n",
      "Epoch 454/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.4449 - accuracy: 0.8385\n",
      "Epoch 455/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.4498 - accuracy: 0.8269\n",
      "Epoch 456/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.4405 - accuracy: 0.8308\n",
      "Epoch 457/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.4383 - accuracy: 0.8423\n",
      "Epoch 458/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.4420 - accuracy: 0.8346\n",
      "Epoch 459/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.4414 - accuracy: 0.8423\n",
      "Epoch 460/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.4395 - accuracy: 0.8462\n",
      "Epoch 461/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.4484 - accuracy: 0.8346\n",
      "Epoch 462/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.4417 - accuracy: 0.8346\n",
      "Epoch 463/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.4361 - accuracy: 0.8385\n",
      "Epoch 464/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.4351 - accuracy: 0.8346\n",
      "Epoch 465/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.4335 - accuracy: 0.8385\n",
      "Epoch 466/800\n",
      "17/17 [==============================] - 0s 806us/step - loss: 0.4319 - accuracy: 0.8462\n",
      "Epoch 467/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.4471 - accuracy: 0.8269\n",
      "Epoch 468/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.4510 - accuracy: 0.8308\n",
      "Epoch 469/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.4543 - accuracy: 0.8346\n",
      "Epoch 470/800\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.4524 - accuracy: 0.8346\n",
      "Epoch 471/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.4425 - accuracy: 0.8269\n",
      "Epoch 472/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.4428 - accuracy: 0.8385\n",
      "Epoch 473/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.4331 - accuracy: 0.8308\n",
      "Epoch 474/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.4326 - accuracy: 0.8423\n",
      "Epoch 475/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 0.4312 - accuracy: 0.8500\n",
      "Epoch 476/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.4357 - accuracy: 0.8308\n",
      "Epoch 477/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.4480 - accuracy: 0.8346\n",
      "Epoch 478/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.4324 - accuracy: 0.8385\n",
      "Epoch 479/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.4298 - accuracy: 0.8423\n",
      "Epoch 480/800\n",
      "17/17 [==============================] - 0s 806us/step - loss: 0.4311 - accuracy: 0.8346\n",
      "Epoch 481/800\n",
      "17/17 [==============================] - 0s 782us/step - loss: 0.4266 - accuracy: 0.8346\n",
      "Epoch 482/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.4331 - accuracy: 0.8308\n",
      "Epoch 483/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.4364 - accuracy: 0.8346\n",
      "Epoch 484/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.4409 - accuracy: 0.8192\n",
      "Epoch 485/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.4345 - accuracy: 0.8308\n",
      "Epoch 486/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 0.4293 - accuracy: 0.8346\n",
      "Epoch 487/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.4275 - accuracy: 0.8385\n",
      "Epoch 488/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.4269 - accuracy: 0.8385\n",
      "Epoch 489/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.4273 - accuracy: 0.8385\n",
      "Epoch 490/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.4282 - accuracy: 0.8308\n",
      "Epoch 491/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.4795 - accuracy: 0.8192\n",
      "Epoch 492/800\n",
      "17/17 [==============================] - 0s 775us/step - loss: 0.4329 - accuracy: 0.8308\n",
      "Epoch 493/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.4291 - accuracy: 0.8462\n",
      "Epoch 494/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.4374 - accuracy: 0.8269\n",
      "Epoch 495/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.4246 - accuracy: 0.8269\n",
      "Epoch 496/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.4285 - accuracy: 0.8500\n",
      "Epoch 497/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.4245 - accuracy: 0.8346\n",
      "Epoch 498/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.4227 - accuracy: 0.8346\n",
      "Epoch 499/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.4229 - accuracy: 0.8346\n",
      "Epoch 500/800\n",
      "17/17 [==============================] - 0s 806us/step - loss: 0.4183 - accuracy: 0.8462\n",
      "Epoch 501/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.4180 - accuracy: 0.8462\n",
      "Epoch 502/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.4232 - accuracy: 0.8346\n",
      "Epoch 503/800\n",
      "17/17 [==============================] - 0s 787us/step - loss: 0.4152 - accuracy: 0.8385\n",
      "Epoch 504/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.4210 - accuracy: 0.8346\n",
      "Epoch 505/800\n",
      "17/17 [==============================] - 0s 804us/step - loss: 0.4230 - accuracy: 0.8154\n",
      "Epoch 506/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.4222 - accuracy: 0.8385\n",
      "Epoch 507/800\n",
      "17/17 [==============================] - 0s 817us/step - loss: 0.4178 - accuracy: 0.8385\n",
      "Epoch 508/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.4204 - accuracy: 0.8346\n",
      "Epoch 509/800\n",
      "17/17 [==============================] - 0s 822us/step - loss: 0.4137 - accuracy: 0.8346\n",
      "Epoch 510/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.4147 - accuracy: 0.8385\n",
      "Epoch 511/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.4141 - accuracy: 0.8385\n",
      "Epoch 512/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.4166 - accuracy: 0.8423\n",
      "Epoch 513/800\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.4248 - accuracy: 0.8308\n",
      "Epoch 514/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.4271 - accuracy: 0.8269\n",
      "Epoch 515/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.4115 - accuracy: 0.8385\n",
      "Epoch 516/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.4052 - accuracy: 0.8385\n",
      "Epoch 517/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.4086 - accuracy: 0.8423\n",
      "Epoch 518/800\n",
      "17/17 [==============================] - 0s 795us/step - loss: 0.4069 - accuracy: 0.8385\n",
      "Epoch 519/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.4165 - accuracy: 0.8423\n",
      "Epoch 520/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.4098 - accuracy: 0.8385\n",
      "Epoch 521/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.4103 - accuracy: 0.8308\n",
      "Epoch 522/800\n",
      "17/17 [==============================] - 0s 800us/step - loss: 0.4101 - accuracy: 0.8385\n",
      "Epoch 523/800\n",
      "17/17 [==============================] - 0s 796us/step - loss: 0.4042 - accuracy: 0.8385\n",
      "Epoch 524/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.4011 - accuracy: 0.8500\n",
      "Epoch 525/800\n",
      "17/17 [==============================] - 0s 800us/step - loss: 0.4037 - accuracy: 0.8423\n",
      "Epoch 526/800\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.4026 - accuracy: 0.8538\n",
      "Epoch 527/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.4093 - accuracy: 0.8346\n",
      "Epoch 528/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 0.3991 - accuracy: 0.8615\n",
      "Epoch 529/800\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3975 - accuracy: 0.8500\n",
      "Epoch 530/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 0.4144 - accuracy: 0.8385\n",
      "Epoch 531/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.3983 - accuracy: 0.8538\n",
      "Epoch 532/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 0.4035 - accuracy: 0.8577\n",
      "Epoch 533/800\n",
      "17/17 [==============================] - 0s 796us/step - loss: 0.4067 - accuracy: 0.8385\n",
      "Epoch 534/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.4018 - accuracy: 0.8500\n",
      "Epoch 535/800\n",
      "17/17 [==============================] - 0s 817us/step - loss: 0.4036 - accuracy: 0.8577\n",
      "Epoch 536/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.4094 - accuracy: 0.8538\n",
      "Epoch 537/800\n",
      "17/17 [==============================] - 0s 817us/step - loss: 0.4189 - accuracy: 0.8423\n",
      "Epoch 538/800\n",
      "17/17 [==============================] - 0s 796us/step - loss: 0.4068 - accuracy: 0.8500\n",
      "Epoch 539/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.3988 - accuracy: 0.8500\n",
      "Epoch 540/800\n",
      "17/17 [==============================] - 0s 806us/step - loss: 0.3919 - accuracy: 0.8577\n",
      "Epoch 541/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.3937 - accuracy: 0.8577\n",
      "Epoch 542/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.3906 - accuracy: 0.8500\n",
      "Epoch 543/800\n",
      "17/17 [==============================] - 0s 800us/step - loss: 0.3927 - accuracy: 0.8538\n",
      "Epoch 544/800\n",
      "17/17 [==============================] - 0s 795us/step - loss: 0.3913 - accuracy: 0.8538\n",
      "Epoch 545/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 0.3949 - accuracy: 0.8615\n",
      "Epoch 546/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.3966 - accuracy: 0.8269\n",
      "Epoch 547/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 0.4278 - accuracy: 0.8538\n",
      "Epoch 548/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.3960 - accuracy: 0.8538\n",
      "Epoch 549/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.4085 - accuracy: 0.8269\n",
      "Epoch 550/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.3871 - accuracy: 0.8615\n",
      "Epoch 551/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.3849 - accuracy: 0.8615\n",
      "Epoch 552/800\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3811 - accuracy: 0.8654\n",
      "Epoch 553/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.3804 - accuracy: 0.8538\n",
      "Epoch 554/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.3800 - accuracy: 0.8615\n",
      "Epoch 555/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.3817 - accuracy: 0.8538\n",
      "Epoch 556/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.3865 - accuracy: 0.8577\n",
      "Epoch 557/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.3921 - accuracy: 0.8500\n",
      "Epoch 558/800\n",
      "17/17 [==============================] - 0s 795us/step - loss: 0.3764 - accuracy: 0.8654\n",
      "Epoch 559/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.3744 - accuracy: 0.8654\n",
      "Epoch 560/800\n",
      "17/17 [==============================] - 0s 775us/step - loss: 0.3780 - accuracy: 0.8654\n",
      "Epoch 561/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 0.3709 - accuracy: 0.8654\n",
      "Epoch 562/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.3694 - accuracy: 0.8692\n",
      "Epoch 563/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.3684 - accuracy: 0.8615\n",
      "Epoch 564/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.3699 - accuracy: 0.8577\n",
      "Epoch 565/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.3718 - accuracy: 0.8692\n",
      "Epoch 566/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.3733 - accuracy: 0.8538\n",
      "Epoch 567/800\n",
      "17/17 [==============================] - 0s 787us/step - loss: 0.3683 - accuracy: 0.8692\n",
      "Epoch 568/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.3645 - accuracy: 0.8692\n",
      "Epoch 569/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.3643 - accuracy: 0.8654\n",
      "Epoch 570/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.3657 - accuracy: 0.8731\n",
      "Epoch 571/800\n",
      "17/17 [==============================] - 0s 796us/step - loss: 0.3576 - accuracy: 0.8731\n",
      "Epoch 572/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.3605 - accuracy: 0.8692\n",
      "Epoch 573/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.3599 - accuracy: 0.8615\n",
      "Epoch 574/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.3599 - accuracy: 0.8692\n",
      "Epoch 575/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.3595 - accuracy: 0.8731\n",
      "Epoch 576/800\n",
      "17/17 [==============================] - 0s 826us/step - loss: 0.3589 - accuracy: 0.8615\n",
      "Epoch 577/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.3589 - accuracy: 0.8654\n",
      "Epoch 578/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.3558 - accuracy: 0.8692\n",
      "Epoch 579/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.3729 - accuracy: 0.8423\n",
      "Epoch 580/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.3588 - accuracy: 0.8731\n",
      "Epoch 581/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.3509 - accuracy: 0.8692\n",
      "Epoch 582/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.3532 - accuracy: 0.8577\n",
      "Epoch 583/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.3508 - accuracy: 0.8577\n",
      "Epoch 584/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.3501 - accuracy: 0.8654\n",
      "Epoch 585/800\n",
      "17/17 [==============================] - 0s 775us/step - loss: 0.3529 - accuracy: 0.8654\n",
      "Epoch 586/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.3479 - accuracy: 0.8731\n",
      "Epoch 587/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.3479 - accuracy: 0.8577\n",
      "Epoch 588/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.3474 - accuracy: 0.8692\n",
      "Epoch 589/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.3492 - accuracy: 0.8692\n",
      "Epoch 590/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.3441 - accuracy: 0.8654\n",
      "Epoch 591/800\n",
      "17/17 [==============================] - 0s 787us/step - loss: 0.3492 - accuracy: 0.8692\n",
      "Epoch 592/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.3421 - accuracy: 0.8769\n",
      "Epoch 593/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.3509 - accuracy: 0.8692\n",
      "Epoch 594/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.3411 - accuracy: 0.8731\n",
      "Epoch 595/800\n",
      "17/17 [==============================] - 0s 778us/step - loss: 0.3507 - accuracy: 0.8615\n",
      "Epoch 596/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.3401 - accuracy: 0.8769\n",
      "Epoch 597/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.3429 - accuracy: 0.8731\n",
      "Epoch 598/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.3419 - accuracy: 0.8538\n",
      "Epoch 599/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.3601 - accuracy: 0.8577\n",
      "Epoch 600/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.3538 - accuracy: 0.8615\n",
      "Epoch 601/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.3534 - accuracy: 0.8654\n",
      "Epoch 602/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.3506 - accuracy: 0.8615\n",
      "Epoch 603/800\n",
      "17/17 [==============================] - 0s 806us/step - loss: 0.3360 - accuracy: 0.8846\n",
      "Epoch 604/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.3354 - accuracy: 0.8808\n",
      "Epoch 605/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.3444 - accuracy: 0.8692\n",
      "Epoch 606/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.3419 - accuracy: 0.8654\n",
      "Epoch 607/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.3370 - accuracy: 0.8654\n",
      "Epoch 608/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.3481 - accuracy: 0.8577\n",
      "Epoch 609/800\n",
      "17/17 [==============================] - 0s 796us/step - loss: 0.3374 - accuracy: 0.8808\n",
      "Epoch 610/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.3315 - accuracy: 0.8692\n",
      "Epoch 611/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.3345 - accuracy: 0.8615\n",
      "Epoch 612/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.3289 - accuracy: 0.8692\n",
      "Epoch 613/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.3303 - accuracy: 0.8731\n",
      "Epoch 614/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.3294 - accuracy: 0.8769\n",
      "Epoch 615/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.3294 - accuracy: 0.8692\n",
      "Epoch 616/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.3445 - accuracy: 0.8615\n",
      "Epoch 617/800\n",
      "17/17 [==============================] - 0s 796us/step - loss: 0.3484 - accuracy: 0.8692\n",
      "Epoch 618/800\n",
      "17/17 [==============================] - 0s 787us/step - loss: 0.3274 - accuracy: 0.8769\n",
      "Epoch 619/800\n",
      "17/17 [==============================] - 0s 796us/step - loss: 0.3239 - accuracy: 0.8692\n",
      "Epoch 620/800\n",
      "17/17 [==============================] - 0s 787us/step - loss: 0.3255 - accuracy: 0.8769\n",
      "Epoch 621/800\n",
      "17/17 [==============================] - 0s 817us/step - loss: 0.3234 - accuracy: 0.8769\n",
      "Epoch 622/800\n",
      "17/17 [==============================] - 0s 779us/step - loss: 0.3348 - accuracy: 0.8808\n",
      "Epoch 623/800\n",
      "17/17 [==============================] - 0s 795us/step - loss: 0.3225 - accuracy: 0.8808\n",
      "Epoch 624/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 0.3363 - accuracy: 0.8769\n",
      "Epoch 625/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.3259 - accuracy: 0.8731\n",
      "Epoch 626/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.3214 - accuracy: 0.8846\n",
      "Epoch 627/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.3208 - accuracy: 0.8769\n",
      "Epoch 628/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.3270 - accuracy: 0.8731\n",
      "Epoch 629/800\n",
      "17/17 [==============================] - 0s 800us/step - loss: 0.3186 - accuracy: 0.8808\n",
      "Epoch 630/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.3202 - accuracy: 0.8808\n",
      "Epoch 631/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.3193 - accuracy: 0.8846\n",
      "Epoch 632/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.3174 - accuracy: 0.8769\n",
      "Epoch 633/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.3195 - accuracy: 0.8654\n",
      "Epoch 634/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.3163 - accuracy: 0.8769\n",
      "Epoch 635/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.3157 - accuracy: 0.8769\n",
      "Epoch 636/800\n",
      "17/17 [==============================] - 0s 796us/step - loss: 0.3195 - accuracy: 0.8692\n",
      "Epoch 637/800\n",
      "17/17 [==============================] - 0s 806us/step - loss: 0.3149 - accuracy: 0.8846\n",
      "Epoch 638/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.3140 - accuracy: 0.8808\n",
      "Epoch 639/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.3215 - accuracy: 0.8808\n",
      "Epoch 640/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.3262 - accuracy: 0.8808\n",
      "Epoch 641/800\n",
      "17/17 [==============================] - 0s 787us/step - loss: 0.3141 - accuracy: 0.8885\n",
      "Epoch 642/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.3132 - accuracy: 0.8885\n",
      "Epoch 643/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.3123 - accuracy: 0.8885\n",
      "Epoch 644/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 0.3118 - accuracy: 0.8885\n",
      "Epoch 645/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.3097 - accuracy: 0.8962\n",
      "Epoch 646/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.3092 - accuracy: 0.8846\n",
      "Epoch 647/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.3074 - accuracy: 0.8846\n",
      "Epoch 648/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.3083 - accuracy: 0.8769\n",
      "Epoch 649/800\n",
      "17/17 [==============================] - 0s 800us/step - loss: 0.3049 - accuracy: 0.8885\n",
      "Epoch 650/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.3164 - accuracy: 0.8808\n",
      "Epoch 651/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.3066 - accuracy: 0.8808\n",
      "Epoch 652/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.3097 - accuracy: 0.8808\n",
      "Epoch 653/800\n",
      "17/17 [==============================] - 0s 826us/step - loss: 0.3043 - accuracy: 0.8808\n",
      "Epoch 654/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.3081 - accuracy: 0.8846\n",
      "Epoch 655/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.3121 - accuracy: 0.8769\n",
      "Epoch 656/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.3039 - accuracy: 0.8846\n",
      "Epoch 657/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.2999 - accuracy: 0.8885\n",
      "Epoch 658/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.3034 - accuracy: 0.8923\n",
      "Epoch 659/800\n",
      "17/17 [==============================] - 0s 804us/step - loss: 0.3183 - accuracy: 0.9000\n",
      "Epoch 660/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.3141 - accuracy: 0.8885\n",
      "Epoch 661/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.3087 - accuracy: 0.8923\n",
      "Epoch 662/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.2992 - accuracy: 0.8885\n",
      "Epoch 663/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.3087 - accuracy: 0.8769\n",
      "Epoch 664/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.2957 - accuracy: 0.8962\n",
      "Epoch 665/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.3008 - accuracy: 0.8885\n",
      "Epoch 666/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.2987 - accuracy: 0.9077\n",
      "Epoch 667/800\n",
      "17/17 [==============================] - 0s 778us/step - loss: 0.2951 - accuracy: 0.8923\n",
      "Epoch 668/800\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.3016 - accuracy: 0.8962\n",
      "Epoch 669/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.2969 - accuracy: 0.9000\n",
      "Epoch 670/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.3053 - accuracy: 0.9000\n",
      "Epoch 671/800\n",
      "17/17 [==============================] - 0s 829us/step - loss: 0.2973 - accuracy: 0.8962\n",
      "Epoch 672/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.3112 - accuracy: 0.8923\n",
      "Epoch 673/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.3090 - accuracy: 0.8923\n",
      "Epoch 674/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.2989 - accuracy: 0.8962\n",
      "Epoch 675/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.2962 - accuracy: 0.8962\n",
      "Epoch 676/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.2897 - accuracy: 0.9000\n",
      "Epoch 677/800\n",
      "17/17 [==============================] - 0s 804us/step - loss: 0.2920 - accuracy: 0.8962\n",
      "Epoch 678/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.2902 - accuracy: 0.9000\n",
      "Epoch 679/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.2900 - accuracy: 0.9000\n",
      "Epoch 680/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.2873 - accuracy: 0.8962\n",
      "Epoch 681/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.3111 - accuracy: 0.8923\n",
      "Epoch 682/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.2957 - accuracy: 0.8962\n",
      "Epoch 683/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.2870 - accuracy: 0.9000\n",
      "Epoch 684/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.2866 - accuracy: 0.8962\n",
      "Epoch 685/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 0.2894 - accuracy: 0.9038\n",
      "Epoch 686/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.2905 - accuracy: 0.9000\n",
      "Epoch 687/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.2850 - accuracy: 0.9077\n",
      "Epoch 688/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.2898 - accuracy: 0.9038\n",
      "Epoch 689/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.2959 - accuracy: 0.9000\n",
      "Epoch 690/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.2940 - accuracy: 0.9038\n",
      "Epoch 691/800\n",
      "17/17 [==============================] - 0s 806us/step - loss: 0.2907 - accuracy: 0.8962\n",
      "Epoch 692/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 0.2853 - accuracy: 0.9000\n",
      "Epoch 693/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.2831 - accuracy: 0.8962\n",
      "Epoch 694/800\n",
      "17/17 [==============================] - 0s 831us/step - loss: 0.2870 - accuracy: 0.9038\n",
      "Epoch 695/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 0.2829 - accuracy: 0.9000\n",
      "Epoch 696/800\n",
      "17/17 [==============================] - 0s 840us/step - loss: 0.2825 - accuracy: 0.9000\n",
      "Epoch 697/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 0.2872 - accuracy: 0.9000\n",
      "Epoch 698/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.2864 - accuracy: 0.9038\n",
      "Epoch 699/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 0.2796 - accuracy: 0.8962\n",
      "Epoch 700/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.2859 - accuracy: 0.9000\n",
      "Epoch 701/800\n",
      "17/17 [==============================] - 0s 817us/step - loss: 0.2852 - accuracy: 0.9038\n",
      "Epoch 702/800\n",
      "17/17 [==============================] - 0s 822us/step - loss: 0.2803 - accuracy: 0.8962\n",
      "Epoch 703/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.2822 - accuracy: 0.9038\n",
      "Epoch 704/800\n",
      "17/17 [==============================] - 0s 856us/step - loss: 0.2793 - accuracy: 0.9000\n",
      "Epoch 705/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.2792 - accuracy: 0.8923\n",
      "Epoch 706/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.2896 - accuracy: 0.8962\n",
      "Epoch 707/800\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.2774 - accuracy: 0.9038\n",
      "Epoch 708/800\n",
      "17/17 [==============================] - 0s 787us/step - loss: 0.2727 - accuracy: 0.9077\n",
      "Epoch 709/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.2780 - accuracy: 0.8885\n",
      "Epoch 710/800\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.2799 - accuracy: 0.9077\n",
      "Epoch 711/800\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.2805 - accuracy: 0.8962\n",
      "Epoch 712/800\n",
      "17/17 [==============================] - 0s 782us/step - loss: 0.2750 - accuracy: 0.9038\n",
      "Epoch 713/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.2794 - accuracy: 0.8923\n",
      "Epoch 714/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.2734 - accuracy: 0.8962\n",
      "Epoch 715/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.2728 - accuracy: 0.9000\n",
      "Epoch 716/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.2774 - accuracy: 0.9000\n",
      "Epoch 717/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.2720 - accuracy: 0.9038\n",
      "Epoch 718/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.2807 - accuracy: 0.8962\n",
      "Epoch 719/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.2744 - accuracy: 0.9038\n",
      "Epoch 720/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.2743 - accuracy: 0.9038\n",
      "Epoch 721/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.2690 - accuracy: 0.9077\n",
      "Epoch 722/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.2688 - accuracy: 0.9038\n",
      "Epoch 723/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.2671 - accuracy: 0.9038\n",
      "Epoch 724/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.2657 - accuracy: 0.9077\n",
      "Epoch 725/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.2698 - accuracy: 0.9000\n",
      "Epoch 726/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.2878 - accuracy: 0.9000\n",
      "Epoch 727/800\n",
      "17/17 [==============================] - 0s 800us/step - loss: 0.2740 - accuracy: 0.9000\n",
      "Epoch 728/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.2758 - accuracy: 0.9038\n",
      "Epoch 729/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.2662 - accuracy: 0.9000\n",
      "Epoch 730/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.2732 - accuracy: 0.9038\n",
      "Epoch 731/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.2715 - accuracy: 0.8962\n",
      "Epoch 732/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.2808 - accuracy: 0.8846\n",
      "Epoch 733/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.2812 - accuracy: 0.9000\n",
      "Epoch 734/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.2680 - accuracy: 0.9038\n",
      "Epoch 735/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.2641 - accuracy: 0.9038\n",
      "Epoch 736/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.2587 - accuracy: 0.9115\n",
      "Epoch 737/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.2612 - accuracy: 0.9077\n",
      "Epoch 738/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.2608 - accuracy: 0.9038\n",
      "Epoch 739/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.2638 - accuracy: 0.9038\n",
      "Epoch 740/800\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.2597 - accuracy: 0.9077\n",
      "Epoch 741/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.2734 - accuracy: 0.9000\n",
      "Epoch 742/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.2639 - accuracy: 0.9077\n",
      "Epoch 743/800\n",
      "17/17 [==============================] - 0s 838us/step - loss: 0.2693 - accuracy: 0.9000\n",
      "Epoch 744/800\n",
      "17/17 [==============================] - 0s 804us/step - loss: 0.2629 - accuracy: 0.9038\n",
      "Epoch 745/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.2577 - accuracy: 0.9038\n",
      "Epoch 746/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.2564 - accuracy: 0.9038\n",
      "Epoch 747/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.2973 - accuracy: 0.8885\n",
      "Epoch 748/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.3302 - accuracy: 0.8731\n",
      "Epoch 749/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.2809 - accuracy: 0.8923\n",
      "Epoch 750/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.2699 - accuracy: 0.9077\n",
      "Epoch 751/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 0.2547 - accuracy: 0.9154\n",
      "Epoch 752/800\n",
      "17/17 [==============================] - 0s 782us/step - loss: 0.2528 - accuracy: 0.9077\n",
      "Epoch 753/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.2531 - accuracy: 0.9077\n",
      "Epoch 754/800\n",
      "17/17 [==============================] - 0s 867us/step - loss: 0.2513 - accuracy: 0.9115\n",
      "Epoch 755/800\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.2540 - accuracy: 0.9077\n",
      "Epoch 756/800\n",
      "17/17 [==============================] - 0s 806us/step - loss: 0.2519 - accuracy: 0.9077\n",
      "Epoch 757/800\n",
      "17/17 [==============================] - 0s 775us/step - loss: 0.2646 - accuracy: 0.9038\n",
      "Epoch 758/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.2524 - accuracy: 0.9000\n",
      "Epoch 759/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.2570 - accuracy: 0.9038\n",
      "Epoch 760/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.2506 - accuracy: 0.9077\n",
      "Epoch 761/800\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.2589 - accuracy: 0.8962\n",
      "Epoch 762/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 0.2493 - accuracy: 0.9077\n",
      "Epoch 763/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.2533 - accuracy: 0.9077\n",
      "Epoch 764/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.2541 - accuracy: 0.8962\n",
      "Epoch 765/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.2494 - accuracy: 0.9115\n",
      "Epoch 766/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.2470 - accuracy: 0.9077\n",
      "Epoch 767/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.2474 - accuracy: 0.9115\n",
      "Epoch 768/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.2467 - accuracy: 0.9077\n",
      "Epoch 769/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.2475 - accuracy: 0.9038\n",
      "Epoch 770/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.2554 - accuracy: 0.9077\n",
      "Epoch 771/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.2502 - accuracy: 0.9115\n",
      "Epoch 772/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.2473 - accuracy: 0.9038\n",
      "Epoch 773/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.2450 - accuracy: 0.9115\n",
      "Epoch 774/800\n",
      "17/17 [==============================] - 0s 822us/step - loss: 0.2444 - accuracy: 0.9077\n",
      "Epoch 775/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.2465 - accuracy: 0.9077\n",
      "Epoch 776/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.2844 - accuracy: 0.8846\n",
      "Epoch 777/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.2528 - accuracy: 0.9115\n",
      "Epoch 778/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.2423 - accuracy: 0.9154\n",
      "Epoch 779/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.2433 - accuracy: 0.9077\n",
      "Epoch 780/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.2613 - accuracy: 0.9115\n",
      "Epoch 781/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.2565 - accuracy: 0.9077\n",
      "Epoch 782/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.2515 - accuracy: 0.9154\n",
      "Epoch 783/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.2572 - accuracy: 0.9077\n",
      "Epoch 784/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.2500 - accuracy: 0.9115\n",
      "Epoch 785/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.2637 - accuracy: 0.9000\n",
      "Epoch 786/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.2451 - accuracy: 0.9154\n",
      "Epoch 787/800\n",
      "17/17 [==============================] - 0s 806us/step - loss: 0.2442 - accuracy: 0.9077\n",
      "Epoch 788/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.2481 - accuracy: 0.8962\n",
      "Epoch 789/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.2371 - accuracy: 0.9154\n",
      "Epoch 790/800\n",
      "17/17 [==============================] - 0s 775us/step - loss: 0.2399 - accuracy: 0.9077\n",
      "Epoch 791/800\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.2399 - accuracy: 0.9154\n",
      "Epoch 792/800\n",
      "17/17 [==============================] - 0s 848us/step - loss: 0.2380 - accuracy: 0.9192\n",
      "Epoch 793/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.2343 - accuracy: 0.9192\n",
      "Epoch 794/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.2355 - accuracy: 0.9154\n",
      "Epoch 795/800\n",
      "17/17 [==============================] - 0s 787us/step - loss: 0.2368 - accuracy: 0.9115\n",
      "Epoch 796/800\n",
      "17/17 [==============================] - 0s 796us/step - loss: 0.2442 - accuracy: 0.9154\n",
      "Epoch 797/800\n",
      "17/17 [==============================] - 0s 806us/step - loss: 0.2568 - accuracy: 0.9038\n",
      "Epoch 798/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.2393 - accuracy: 0.9192\n",
      "Epoch 799/800\n",
      "17/17 [==============================] - 0s 817us/step - loss: 0.2342 - accuracy: 0.9154\n",
      "Epoch 800/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.2348 - accuracy: 0.9231\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "Epoch 1/800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 220, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 268, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 192, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 221, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 1ms/step - loss: 1.7883 - accuracy: 0.3000\n",
      "Epoch 2/800\n",
      "17/17 [==============================] - 0s 938us/step - loss: 1.7774 - accuracy: 0.3000\n",
      "Epoch 3/800\n",
      "17/17 [==============================] - 0s 885us/step - loss: 1.7555 - accuracy: 0.3000\n",
      "Epoch 4/800\n",
      "17/17 [==============================] - 0s 903us/step - loss: 1.7112 - accuracy: 0.3462\n",
      "Epoch 5/800\n",
      "17/17 [==============================] - 0s 885us/step - loss: 1.6191 - accuracy: 0.4038\n",
      "Epoch 6/800\n",
      "17/17 [==============================] - 0s 842us/step - loss: 1.5388 - accuracy: 0.4462\n",
      "Epoch 7/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 1.4776 - accuracy: 0.4923\n",
      "Epoch 8/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 1.4185 - accuracy: 0.5038\n",
      "Epoch 9/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 1.3694 - accuracy: 0.5154\n",
      "Epoch 10/800\n",
      "17/17 [==============================] - 0s 736us/step - loss: 1.3299 - accuracy: 0.5154\n",
      "Epoch 11/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 1.3017 - accuracy: 0.5192\n",
      "Epoch 12/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 1.2817 - accuracy: 0.5154\n",
      "Epoch 13/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 1.2701 - accuracy: 0.5154\n",
      "Epoch 14/800\n",
      "17/17 [==============================] - 0s 733us/step - loss: 1.2553 - accuracy: 0.5231\n",
      "Epoch 15/800\n",
      "17/17 [==============================] - 0s 772us/step - loss: 1.2479 - accuracy: 0.5192\n",
      "Epoch 16/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 1.2330 - accuracy: 0.5269\n",
      "Epoch 17/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 1.2174 - accuracy: 0.5346\n",
      "Epoch 18/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 1.2075 - accuracy: 0.5462\n",
      "Epoch 19/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 1.1941 - accuracy: 0.5462\n",
      "Epoch 20/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 1.1834 - accuracy: 0.5423\n",
      "Epoch 21/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 1.1648 - accuracy: 0.5423\n",
      "Epoch 22/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 1.1492 - accuracy: 0.5577\n",
      "Epoch 23/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 1.1224 - accuracy: 0.5577\n",
      "Epoch 24/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 1.1033 - accuracy: 0.5654\n",
      "Epoch 25/800\n",
      "17/17 [==============================] - 0s 775us/step - loss: 1.0886 - accuracy: 0.5654\n",
      "Epoch 26/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 1.0803 - accuracy: 0.5654\n",
      "Epoch 27/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 1.0759 - accuracy: 0.5654\n",
      "Epoch 28/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 1.0618 - accuracy: 0.5692\n",
      "Epoch 29/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 1.0511 - accuracy: 0.5692\n",
      "Epoch 30/800\n",
      "17/17 [==============================] - 0s 772us/step - loss: 1.0460 - accuracy: 0.5654\n",
      "Epoch 31/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 1.0392 - accuracy: 0.5769\n",
      "Epoch 32/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 1.0308 - accuracy: 0.5731\n",
      "Epoch 33/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 1.0316 - accuracy: 0.5615\n",
      "Epoch 34/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 1.0152 - accuracy: 0.5654\n",
      "Epoch 35/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 1.0112 - accuracy: 0.5731\n",
      "Epoch 36/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 1.0081 - accuracy: 0.5731\n",
      "Epoch 37/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 1.0060 - accuracy: 0.5731\n",
      "Epoch 38/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.9948 - accuracy: 0.5808\n",
      "Epoch 39/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.9901 - accuracy: 0.5769\n",
      "Epoch 40/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.9819 - accuracy: 0.5769\n",
      "Epoch 41/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.9886 - accuracy: 0.5846\n",
      "Epoch 42/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.9719 - accuracy: 0.5846\n",
      "Epoch 43/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.9673 - accuracy: 0.5885\n",
      "Epoch 44/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.9637 - accuracy: 0.5923\n",
      "Epoch 45/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.9586 - accuracy: 0.5846\n",
      "Epoch 46/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.9579 - accuracy: 0.5846\n",
      "Epoch 47/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.9474 - accuracy: 0.5923\n",
      "Epoch 48/800\n",
      "17/17 [==============================] - 0s 732us/step - loss: 0.9463 - accuracy: 0.5923\n",
      "Epoch 49/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.9601 - accuracy: 0.6038\n",
      "Epoch 50/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.9378 - accuracy: 0.6038\n",
      "Epoch 51/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.9327 - accuracy: 0.6192\n",
      "Epoch 52/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.9256 - accuracy: 0.6154\n",
      "Epoch 53/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.9225 - accuracy: 0.6192\n",
      "Epoch 54/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.9222 - accuracy: 0.6192\n",
      "Epoch 55/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.9162 - accuracy: 0.6231\n",
      "Epoch 56/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.9106 - accuracy: 0.6192\n",
      "Epoch 57/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.9102 - accuracy: 0.6192\n",
      "Epoch 58/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.9114 - accuracy: 0.6231\n",
      "Epoch 59/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.8992 - accuracy: 0.6269\n",
      "Epoch 60/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.8967 - accuracy: 0.6308\n",
      "Epoch 61/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.8881 - accuracy: 0.6308\n",
      "Epoch 62/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.8871 - accuracy: 0.6308\n",
      "Epoch 63/800\n",
      "17/17 [==============================] - 0s 779us/step - loss: 0.8814 - accuracy: 0.6385\n",
      "Epoch 64/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.8764 - accuracy: 0.6346\n",
      "Epoch 65/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.8760 - accuracy: 0.6462\n",
      "Epoch 66/800\n",
      "17/17 [==============================] - 0s 772us/step - loss: 0.8723 - accuracy: 0.6538\n",
      "Epoch 67/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.8683 - accuracy: 0.6538\n",
      "Epoch 68/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.8602 - accuracy: 0.6615\n",
      "Epoch 69/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.8649 - accuracy: 0.6654\n",
      "Epoch 70/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.8662 - accuracy: 0.6692\n",
      "Epoch 71/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.8561 - accuracy: 0.6654\n",
      "Epoch 72/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.8460 - accuracy: 0.6692\n",
      "Epoch 73/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.8403 - accuracy: 0.6692\n",
      "Epoch 74/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.8371 - accuracy: 0.6615\n",
      "Epoch 75/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.8328 - accuracy: 0.6654\n",
      "Epoch 76/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.8304 - accuracy: 0.6692\n",
      "Epoch 77/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.8271 - accuracy: 0.6615\n",
      "Epoch 78/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.8339 - accuracy: 0.6731\n",
      "Epoch 79/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.8245 - accuracy: 0.6769\n",
      "Epoch 80/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.8268 - accuracy: 0.6731\n",
      "Epoch 81/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.8078 - accuracy: 0.6692\n",
      "Epoch 82/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.8039 - accuracy: 0.6731\n",
      "Epoch 83/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.8098 - accuracy: 0.6769\n",
      "Epoch 84/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.7999 - accuracy: 0.6808\n",
      "Epoch 85/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.8023 - accuracy: 0.6769\n",
      "Epoch 86/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.7877 - accuracy: 0.6654\n",
      "Epoch 87/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.7862 - accuracy: 0.6769\n",
      "Epoch 88/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.7865 - accuracy: 0.6731\n",
      "Epoch 89/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.7875 - accuracy: 0.6654\n",
      "Epoch 90/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.7748 - accuracy: 0.6769\n",
      "Epoch 91/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.7794 - accuracy: 0.6731\n",
      "Epoch 92/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.7746 - accuracy: 0.6885\n",
      "Epoch 93/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.7702 - accuracy: 0.6808\n",
      "Epoch 94/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.7763 - accuracy: 0.7038\n",
      "Epoch 95/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.7552 - accuracy: 0.6962\n",
      "Epoch 96/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.7510 - accuracy: 0.6923\n",
      "Epoch 97/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.7504 - accuracy: 0.7038\n",
      "Epoch 98/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.7428 - accuracy: 0.7154\n",
      "Epoch 99/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.7378 - accuracy: 0.7038\n",
      "Epoch 100/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.7347 - accuracy: 0.7000\n",
      "Epoch 101/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.7374 - accuracy: 0.7154\n",
      "Epoch 102/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.7382 - accuracy: 0.6923\n",
      "Epoch 103/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.7271 - accuracy: 0.7154\n",
      "Epoch 104/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.7264 - accuracy: 0.7308\n",
      "Epoch 105/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.7240 - accuracy: 0.7423\n",
      "Epoch 106/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.7149 - accuracy: 0.7269\n",
      "Epoch 107/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.7115 - accuracy: 0.7269\n",
      "Epoch 108/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.7108 - accuracy: 0.7346\n",
      "Epoch 109/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.7056 - accuracy: 0.7308\n",
      "Epoch 110/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.7012 - accuracy: 0.7385\n",
      "Epoch 111/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.7012 - accuracy: 0.7231\n",
      "Epoch 112/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.6966 - accuracy: 0.7385\n",
      "Epoch 113/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.6908 - accuracy: 0.7423\n",
      "Epoch 114/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.6880 - accuracy: 0.7462\n",
      "Epoch 115/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.6893 - accuracy: 0.7462\n",
      "Epoch 116/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.6821 - accuracy: 0.7423\n",
      "Epoch 117/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.6964 - accuracy: 0.7500\n",
      "Epoch 118/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.6809 - accuracy: 0.7423\n",
      "Epoch 119/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.6803 - accuracy: 0.7308\n",
      "Epoch 120/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.6804 - accuracy: 0.7308\n",
      "Epoch 121/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.6688 - accuracy: 0.7423\n",
      "Epoch 122/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.6665 - accuracy: 0.7385\n",
      "Epoch 123/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.6648 - accuracy: 0.7462\n",
      "Epoch 124/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.6658 - accuracy: 0.7423\n",
      "Epoch 125/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.6581 - accuracy: 0.7462\n",
      "Epoch 126/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.6547 - accuracy: 0.7308\n",
      "Epoch 127/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.6540 - accuracy: 0.7462\n",
      "Epoch 128/800\n",
      "17/17 [==============================] - 0s 775us/step - loss: 0.6514 - accuracy: 0.7385\n",
      "Epoch 129/800\n",
      "17/17 [==============================] - 0s 775us/step - loss: 0.6585 - accuracy: 0.7269\n",
      "Epoch 130/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.6477 - accuracy: 0.7346\n",
      "Epoch 131/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.6531 - accuracy: 0.7346\n",
      "Epoch 132/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.6424 - accuracy: 0.7423\n",
      "Epoch 133/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.6459 - accuracy: 0.7385\n",
      "Epoch 134/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.6376 - accuracy: 0.7423\n",
      "Epoch 135/800\n",
      "17/17 [==============================] - 0s 777us/step - loss: 0.6348 - accuracy: 0.7538\n",
      "Epoch 136/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.6377 - accuracy: 0.7385\n",
      "Epoch 137/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.6438 - accuracy: 0.7346\n",
      "Epoch 138/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.6483 - accuracy: 0.7346\n",
      "Epoch 139/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.6337 - accuracy: 0.7423\n",
      "Epoch 140/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.6408 - accuracy: 0.7385\n",
      "Epoch 141/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 0.6282 - accuracy: 0.7385\n",
      "Epoch 142/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.6215 - accuracy: 0.7538\n",
      "Epoch 143/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.6253 - accuracy: 0.7500\n",
      "Epoch 144/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.6185 - accuracy: 0.7500\n",
      "Epoch 145/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.6195 - accuracy: 0.7462\n",
      "Epoch 146/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.6159 - accuracy: 0.7577\n",
      "Epoch 147/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.6123 - accuracy: 0.7615\n",
      "Epoch 148/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.6104 - accuracy: 0.7615\n",
      "Epoch 149/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.6098 - accuracy: 0.7615\n",
      "Epoch 150/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.6129 - accuracy: 0.7462\n",
      "Epoch 151/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.6148 - accuracy: 0.7692\n",
      "Epoch 152/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.6090 - accuracy: 0.7577\n",
      "Epoch 153/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.6134 - accuracy: 0.7269\n",
      "Epoch 154/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.6133 - accuracy: 0.7462\n",
      "Epoch 155/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.6120 - accuracy: 0.7385\n",
      "Epoch 156/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.5990 - accuracy: 0.7654\n",
      "Epoch 157/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.5996 - accuracy: 0.7577\n",
      "Epoch 158/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.6000 - accuracy: 0.7500\n",
      "Epoch 159/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.5945 - accuracy: 0.7500\n",
      "Epoch 160/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.5920 - accuracy: 0.7538\n",
      "Epoch 161/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.5936 - accuracy: 0.7423\n",
      "Epoch 162/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.5940 - accuracy: 0.7538\n",
      "Epoch 163/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.5908 - accuracy: 0.7462\n",
      "Epoch 164/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.5879 - accuracy: 0.7615\n",
      "Epoch 165/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.5928 - accuracy: 0.7615\n",
      "Epoch 166/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.5875 - accuracy: 0.7577\n",
      "Epoch 167/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.5850 - accuracy: 0.7500\n",
      "Epoch 168/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.5855 - accuracy: 0.7615\n",
      "Epoch 169/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.5848 - accuracy: 0.7577\n",
      "Epoch 170/800\n",
      "17/17 [==============================] - 0s 733us/step - loss: 0.5848 - accuracy: 0.7615\n",
      "Epoch 171/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.5776 - accuracy: 0.7500\n",
      "Epoch 172/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.5788 - accuracy: 0.7538\n",
      "Epoch 173/800\n",
      "17/17 [==============================] - 0s 779us/step - loss: 0.5794 - accuracy: 0.7538\n",
      "Epoch 174/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.5746 - accuracy: 0.7654\n",
      "Epoch 175/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.5798 - accuracy: 0.7731\n",
      "Epoch 176/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.5805 - accuracy: 0.7692\n",
      "Epoch 177/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.5794 - accuracy: 0.7577\n",
      "Epoch 178/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.5695 - accuracy: 0.7654\n",
      "Epoch 179/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.5680 - accuracy: 0.7731\n",
      "Epoch 180/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.5669 - accuracy: 0.7654\n",
      "Epoch 181/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.5709 - accuracy: 0.7538\n",
      "Epoch 182/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.5659 - accuracy: 0.7577\n",
      "Epoch 183/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.5686 - accuracy: 0.7769\n",
      "Epoch 184/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.5676 - accuracy: 0.7654\n",
      "Epoch 185/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.5716 - accuracy: 0.7500\n",
      "Epoch 186/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.5604 - accuracy: 0.7769\n",
      "Epoch 187/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.5678 - accuracy: 0.7500\n",
      "Epoch 188/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.5798 - accuracy: 0.7500\n",
      "Epoch 189/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.5732 - accuracy: 0.7538\n",
      "Epoch 190/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.5627 - accuracy: 0.7731\n",
      "Epoch 191/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.5560 - accuracy: 0.7615\n",
      "Epoch 192/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.5539 - accuracy: 0.7769\n",
      "Epoch 193/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.5580 - accuracy: 0.7500\n",
      "Epoch 194/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.5519 - accuracy: 0.7692\n",
      "Epoch 195/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.5513 - accuracy: 0.7769\n",
      "Epoch 196/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.5464 - accuracy: 0.7731\n",
      "Epoch 197/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.5486 - accuracy: 0.7769\n",
      "Epoch 198/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.5505 - accuracy: 0.7808\n",
      "Epoch 199/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.5517 - accuracy: 0.7808\n",
      "Epoch 200/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.5448 - accuracy: 0.7731\n",
      "Epoch 201/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.5501 - accuracy: 0.7808\n",
      "Epoch 202/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.5439 - accuracy: 0.7808\n",
      "Epoch 203/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.5405 - accuracy: 0.7654\n",
      "Epoch 204/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.5421 - accuracy: 0.7808\n",
      "Epoch 205/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.5407 - accuracy: 0.7885\n",
      "Epoch 206/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.5373 - accuracy: 0.7808\n",
      "Epoch 207/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.5380 - accuracy: 0.7808\n",
      "Epoch 208/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.5373 - accuracy: 0.7808\n",
      "Epoch 209/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.5401 - accuracy: 0.7923\n",
      "Epoch 210/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.5370 - accuracy: 0.7769\n",
      "Epoch 211/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.5505 - accuracy: 0.7769\n",
      "Epoch 212/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.5545 - accuracy: 0.7808\n",
      "Epoch 213/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.5324 - accuracy: 0.7885\n",
      "Epoch 214/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.5383 - accuracy: 0.7808\n",
      "Epoch 215/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.5345 - accuracy: 0.8000\n",
      "Epoch 216/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.5418 - accuracy: 0.7654\n",
      "Epoch 217/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.5335 - accuracy: 0.8038\n",
      "Epoch 218/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.5384 - accuracy: 0.7769\n",
      "Epoch 219/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.5318 - accuracy: 0.7654\n",
      "Epoch 220/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.5240 - accuracy: 0.7808\n",
      "Epoch 221/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.5309 - accuracy: 0.8000\n",
      "Epoch 222/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.5301 - accuracy: 0.7885\n",
      "Epoch 223/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.5302 - accuracy: 0.7885\n",
      "Epoch 224/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.5246 - accuracy: 0.7885\n",
      "Epoch 225/800\n",
      "17/17 [==============================] - 0s 779us/step - loss: 0.5164 - accuracy: 0.8000\n",
      "Epoch 226/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.5172 - accuracy: 0.8000\n",
      "Epoch 227/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.5278 - accuracy: 0.7923\n",
      "Epoch 228/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.5236 - accuracy: 0.7885\n",
      "Epoch 229/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.5110 - accuracy: 0.8000\n",
      "Epoch 230/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.5128 - accuracy: 0.7885\n",
      "Epoch 231/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.5160 - accuracy: 0.7962\n",
      "Epoch 232/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.5319 - accuracy: 0.7846\n",
      "Epoch 233/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.5088 - accuracy: 0.7962\n",
      "Epoch 234/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.5088 - accuracy: 0.7962\n",
      "Epoch 235/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.5191 - accuracy: 0.7885\n",
      "Epoch 236/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.5126 - accuracy: 0.8038\n",
      "Epoch 237/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.5301 - accuracy: 0.7808\n",
      "Epoch 238/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.5218 - accuracy: 0.7808\n",
      "Epoch 239/800\n",
      "17/17 [==============================] - 0s 772us/step - loss: 0.5068 - accuracy: 0.8000\n",
      "Epoch 240/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.5038 - accuracy: 0.8038\n",
      "Epoch 241/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.5077 - accuracy: 0.8077\n",
      "Epoch 242/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.5035 - accuracy: 0.7962\n",
      "Epoch 243/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.5031 - accuracy: 0.8000\n",
      "Epoch 244/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.5037 - accuracy: 0.8038\n",
      "Epoch 245/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.5052 - accuracy: 0.7885\n",
      "Epoch 246/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.5168 - accuracy: 0.8038\n",
      "Epoch 247/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.4989 - accuracy: 0.8038\n",
      "Epoch 248/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.5374 - accuracy: 0.7885\n",
      "Epoch 249/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.5156 - accuracy: 0.8154\n",
      "Epoch 250/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.4980 - accuracy: 0.8115\n",
      "Epoch 251/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.5039 - accuracy: 0.8038\n",
      "Epoch 252/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.4960 - accuracy: 0.8077\n",
      "Epoch 253/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.4995 - accuracy: 0.8115\n",
      "Epoch 254/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.4934 - accuracy: 0.8038\n",
      "Epoch 255/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.4942 - accuracy: 0.8000\n",
      "Epoch 256/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.4944 - accuracy: 0.8038\n",
      "Epoch 257/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.5067 - accuracy: 0.7923\n",
      "Epoch 258/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.5087 - accuracy: 0.8115\n",
      "Epoch 259/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.5119 - accuracy: 0.8077\n",
      "Epoch 260/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.4920 - accuracy: 0.8077\n",
      "Epoch 261/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.4978 - accuracy: 0.8192\n",
      "Epoch 262/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.4873 - accuracy: 0.8192\n",
      "Epoch 263/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.4872 - accuracy: 0.8077\n",
      "Epoch 264/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.4916 - accuracy: 0.8231\n",
      "Epoch 265/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.4844 - accuracy: 0.8192\n",
      "Epoch 266/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.5032 - accuracy: 0.8000\n",
      "Epoch 267/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.4885 - accuracy: 0.7962\n",
      "Epoch 268/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.4852 - accuracy: 0.8115\n",
      "Epoch 269/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.4877 - accuracy: 0.8077\n",
      "Epoch 270/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.4860 - accuracy: 0.8192\n",
      "Epoch 271/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.4878 - accuracy: 0.8269\n",
      "Epoch 272/800\n",
      "17/17 [==============================] - 0s 787us/step - loss: 0.4807 - accuracy: 0.8154\n",
      "Epoch 273/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.4852 - accuracy: 0.8231\n",
      "Epoch 274/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.4934 - accuracy: 0.8038\n",
      "Epoch 275/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.4819 - accuracy: 0.7962\n",
      "Epoch 276/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.4831 - accuracy: 0.8115\n",
      "Epoch 277/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 0.4790 - accuracy: 0.8077\n",
      "Epoch 278/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.4910 - accuracy: 0.7962\n",
      "Epoch 279/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.4791 - accuracy: 0.8231\n",
      "Epoch 280/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.4804 - accuracy: 0.8231\n",
      "Epoch 281/800\n",
      "17/17 [==============================] - 0s 721us/step - loss: 0.4871 - accuracy: 0.8192\n",
      "Epoch 282/800\n",
      "17/17 [==============================] - 0s 727us/step - loss: 0.4828 - accuracy: 0.8192\n",
      "Epoch 283/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.4722 - accuracy: 0.8115\n",
      "Epoch 284/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.4726 - accuracy: 0.8038\n",
      "Epoch 285/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.4693 - accuracy: 0.8192\n",
      "Epoch 286/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.4776 - accuracy: 0.8038\n",
      "Epoch 287/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.4717 - accuracy: 0.8192\n",
      "Epoch 288/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.4673 - accuracy: 0.8269\n",
      "Epoch 289/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.4653 - accuracy: 0.8308\n",
      "Epoch 290/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.4661 - accuracy: 0.8308\n",
      "Epoch 291/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.4691 - accuracy: 0.8192\n",
      "Epoch 292/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.4701 - accuracy: 0.8231\n",
      "Epoch 293/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.4662 - accuracy: 0.8269\n",
      "Epoch 294/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.4632 - accuracy: 0.8346\n",
      "Epoch 295/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.4654 - accuracy: 0.8192\n",
      "Epoch 296/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.4632 - accuracy: 0.8231\n",
      "Epoch 297/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.4634 - accuracy: 0.8154\n",
      "Epoch 298/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.4673 - accuracy: 0.8269\n",
      "Epoch 299/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.4695 - accuracy: 0.8192\n",
      "Epoch 300/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.4578 - accuracy: 0.8346\n",
      "Epoch 301/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.4606 - accuracy: 0.8077\n",
      "Epoch 302/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.5454 - accuracy: 0.7923\n",
      "Epoch 303/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.4871 - accuracy: 0.7923\n",
      "Epoch 304/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.4650 - accuracy: 0.8115\n",
      "Epoch 305/800\n",
      "17/17 [==============================] - 0s 733us/step - loss: 0.4573 - accuracy: 0.8038\n",
      "Epoch 306/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.4649 - accuracy: 0.8038\n",
      "Epoch 307/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.4590 - accuracy: 0.8000\n",
      "Epoch 308/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.4552 - accuracy: 0.8231\n",
      "Epoch 309/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.4538 - accuracy: 0.8346\n",
      "Epoch 310/800\n",
      "17/17 [==============================] - 0s 728us/step - loss: 0.4525 - accuracy: 0.8385\n",
      "Epoch 311/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.4575 - accuracy: 0.8154\n",
      "Epoch 312/800\n",
      "17/17 [==============================] - 0s 736us/step - loss: 0.4585 - accuracy: 0.8269\n",
      "Epoch 313/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.4498 - accuracy: 0.8346\n",
      "Epoch 314/800\n",
      "17/17 [==============================] - 0s 725us/step - loss: 0.4546 - accuracy: 0.8423\n",
      "Epoch 315/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.4510 - accuracy: 0.8269\n",
      "Epoch 316/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.4509 - accuracy: 0.8231\n",
      "Epoch 317/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.4484 - accuracy: 0.8385\n",
      "Epoch 318/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.4460 - accuracy: 0.8346\n",
      "Epoch 319/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 0.4465 - accuracy: 0.8346\n",
      "Epoch 320/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.4537 - accuracy: 0.8269\n",
      "Epoch 321/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.4497 - accuracy: 0.8346\n",
      "Epoch 322/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.4446 - accuracy: 0.8423\n",
      "Epoch 323/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.4483 - accuracy: 0.8115\n",
      "Epoch 324/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.4474 - accuracy: 0.8269\n",
      "Epoch 325/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.4452 - accuracy: 0.8423\n",
      "Epoch 326/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.4424 - accuracy: 0.8423\n",
      "Epoch 327/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.4397 - accuracy: 0.8385\n",
      "Epoch 328/800\n",
      "17/17 [==============================] - 0s 736us/step - loss: 0.4424 - accuracy: 0.8385\n",
      "Epoch 329/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.4425 - accuracy: 0.8192\n",
      "Epoch 330/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.4457 - accuracy: 0.8154\n",
      "Epoch 331/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.4375 - accuracy: 0.8269\n",
      "Epoch 332/800\n",
      "17/17 [==============================] - 0s 736us/step - loss: 0.4380 - accuracy: 0.8269\n",
      "Epoch 333/800\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.4419 - accuracy: 0.8231\n",
      "Epoch 334/800\n",
      "17/17 [==============================] - 0s 736us/step - loss: 0.4405 - accuracy: 0.8192\n",
      "Epoch 335/800\n",
      "17/17 [==============================] - 0s 724us/step - loss: 0.4373 - accuracy: 0.8346\n",
      "Epoch 336/800\n",
      "17/17 [==============================] - 0s 725us/step - loss: 0.4402 - accuracy: 0.8231\n",
      "Epoch 337/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.4364 - accuracy: 0.8385\n",
      "Epoch 338/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.4455 - accuracy: 0.8346\n",
      "Epoch 339/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.4406 - accuracy: 0.8423\n",
      "Epoch 340/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.4344 - accuracy: 0.8385\n",
      "Epoch 341/800\n",
      "17/17 [==============================] - 0s 733us/step - loss: 0.4695 - accuracy: 0.8231\n",
      "Epoch 342/800\n",
      "17/17 [==============================] - 0s 728us/step - loss: 0.4375 - accuracy: 0.8500\n",
      "Epoch 343/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.4375 - accuracy: 0.8423\n",
      "Epoch 344/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.4423 - accuracy: 0.8269\n",
      "Epoch 345/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.4559 - accuracy: 0.8308\n",
      "Epoch 346/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.4323 - accuracy: 0.8423\n",
      "Epoch 347/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.4401 - accuracy: 0.8423\n",
      "Epoch 348/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.4439 - accuracy: 0.8346\n",
      "Epoch 349/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.4330 - accuracy: 0.8308\n",
      "Epoch 350/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.4291 - accuracy: 0.8385\n",
      "Epoch 351/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.4313 - accuracy: 0.8423\n",
      "Epoch 352/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.4296 - accuracy: 0.8423\n",
      "Epoch 353/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.4306 - accuracy: 0.8500\n",
      "Epoch 354/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.4245 - accuracy: 0.8308\n",
      "Epoch 355/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.4304 - accuracy: 0.8192\n",
      "Epoch 356/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.4264 - accuracy: 0.8462\n",
      "Epoch 357/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.4353 - accuracy: 0.8423\n",
      "Epoch 358/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.4309 - accuracy: 0.8423\n",
      "Epoch 359/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 0.4321 - accuracy: 0.8346\n",
      "Epoch 360/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.4210 - accuracy: 0.8538\n",
      "Epoch 361/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.4320 - accuracy: 0.8308\n",
      "Epoch 362/800\n",
      "17/17 [==============================] - 0s 721us/step - loss: 0.4429 - accuracy: 0.8192\n",
      "Epoch 363/800\n",
      "17/17 [==============================] - 0s 733us/step - loss: 0.4225 - accuracy: 0.8423\n",
      "Epoch 364/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.4211 - accuracy: 0.8500\n",
      "Epoch 365/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.4184 - accuracy: 0.8500\n",
      "Epoch 366/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.4203 - accuracy: 0.8462\n",
      "Epoch 367/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.4172 - accuracy: 0.8538\n",
      "Epoch 368/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.4175 - accuracy: 0.8462\n",
      "Epoch 369/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.4222 - accuracy: 0.8385\n",
      "Epoch 370/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.4226 - accuracy: 0.8423\n",
      "Epoch 371/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.4127 - accuracy: 0.8538\n",
      "Epoch 372/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.4131 - accuracy: 0.8538\n",
      "Epoch 373/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.4121 - accuracy: 0.8346\n",
      "Epoch 374/800\n",
      "17/17 [==============================] - 0s 779us/step - loss: 0.4130 - accuracy: 0.8538\n",
      "Epoch 375/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.4177 - accuracy: 0.8423\n",
      "Epoch 376/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.4075 - accuracy: 0.8538\n",
      "Epoch 377/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.4152 - accuracy: 0.8423\n",
      "Epoch 378/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.4083 - accuracy: 0.8577\n",
      "Epoch 379/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.4168 - accuracy: 0.8423\n",
      "Epoch 380/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.4128 - accuracy: 0.8500\n",
      "Epoch 381/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.4058 - accuracy: 0.8538\n",
      "Epoch 382/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.4122 - accuracy: 0.8462\n",
      "Epoch 383/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.4039 - accuracy: 0.8577\n",
      "Epoch 384/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.4045 - accuracy: 0.8500\n",
      "Epoch 385/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.4040 - accuracy: 0.8500\n",
      "Epoch 386/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.4088 - accuracy: 0.8500\n",
      "Epoch 387/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.4055 - accuracy: 0.8500\n",
      "Epoch 388/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.4055 - accuracy: 0.8346\n",
      "Epoch 389/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.4025 - accuracy: 0.8423\n",
      "Epoch 390/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.3996 - accuracy: 0.8538\n",
      "Epoch 391/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.3994 - accuracy: 0.8538\n",
      "Epoch 392/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.4009 - accuracy: 0.8538\n",
      "Epoch 393/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.3978 - accuracy: 0.8615\n",
      "Epoch 394/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.3974 - accuracy: 0.8500\n",
      "Epoch 395/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.4054 - accuracy: 0.8385\n",
      "Epoch 396/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.4103 - accuracy: 0.8423\n",
      "Epoch 397/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.3927 - accuracy: 0.8538\n",
      "Epoch 398/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.4114 - accuracy: 0.8500\n",
      "Epoch 399/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.4026 - accuracy: 0.8538\n",
      "Epoch 400/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.3934 - accuracy: 0.8423\n",
      "Epoch 401/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.3885 - accuracy: 0.8577\n",
      "Epoch 402/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.3971 - accuracy: 0.8615\n",
      "Epoch 403/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.4025 - accuracy: 0.8462\n",
      "Epoch 404/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.3912 - accuracy: 0.8538\n",
      "Epoch 405/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.3886 - accuracy: 0.8577\n",
      "Epoch 406/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.3874 - accuracy: 0.8615\n",
      "Epoch 407/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.3976 - accuracy: 0.8538\n",
      "Epoch 408/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.3921 - accuracy: 0.8538\n",
      "Epoch 409/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.3917 - accuracy: 0.8462\n",
      "Epoch 410/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.3871 - accuracy: 0.8615\n",
      "Epoch 411/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.3804 - accuracy: 0.8615\n",
      "Epoch 412/800\n",
      "17/17 [==============================] - 0s 775us/step - loss: 0.3864 - accuracy: 0.8577\n",
      "Epoch 413/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.3790 - accuracy: 0.8615\n",
      "Epoch 414/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.3809 - accuracy: 0.8654\n",
      "Epoch 415/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.3814 - accuracy: 0.8615\n",
      "Epoch 416/800\n",
      "17/17 [==============================] - 0s 778us/step - loss: 0.3824 - accuracy: 0.8577\n",
      "Epoch 417/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.3799 - accuracy: 0.8615\n",
      "Epoch 418/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.3844 - accuracy: 0.8577\n",
      "Epoch 419/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.3781 - accuracy: 0.8538\n",
      "Epoch 420/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.3838 - accuracy: 0.8500\n",
      "Epoch 421/800\n",
      "17/17 [==============================] - 0s 772us/step - loss: 0.3779 - accuracy: 0.8654\n",
      "Epoch 422/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.3817 - accuracy: 0.8538\n",
      "Epoch 423/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.3720 - accuracy: 0.8577\n",
      "Epoch 424/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.3782 - accuracy: 0.8615\n",
      "Epoch 425/800\n",
      "17/17 [==============================] - 0s 775us/step - loss: 0.3756 - accuracy: 0.8692\n",
      "Epoch 426/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.3861 - accuracy: 0.8615\n",
      "Epoch 427/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.3903 - accuracy: 0.8500\n",
      "Epoch 428/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.3715 - accuracy: 0.8654\n",
      "Epoch 429/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.3688 - accuracy: 0.8654\n",
      "Epoch 430/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.3645 - accuracy: 0.8654\n",
      "Epoch 431/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.3668 - accuracy: 0.8654\n",
      "Epoch 432/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.3752 - accuracy: 0.8462\n",
      "Epoch 433/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.3669 - accuracy: 0.8577\n",
      "Epoch 434/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.3633 - accuracy: 0.8654\n",
      "Epoch 435/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.3663 - accuracy: 0.8538\n",
      "Epoch 436/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.3589 - accuracy: 0.8769\n",
      "Epoch 437/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.3642 - accuracy: 0.8577\n",
      "Epoch 438/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.3614 - accuracy: 0.8692\n",
      "Epoch 439/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.3619 - accuracy: 0.8654\n",
      "Epoch 440/800\n",
      "17/17 [==============================] - 0s 772us/step - loss: 0.3596 - accuracy: 0.8577\n",
      "Epoch 441/800\n",
      "17/17 [==============================] - 0s 782us/step - loss: 0.3584 - accuracy: 0.8654\n",
      "Epoch 442/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.3588 - accuracy: 0.8731\n",
      "Epoch 443/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.3588 - accuracy: 0.8577\n",
      "Epoch 444/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.3553 - accuracy: 0.8731\n",
      "Epoch 445/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.3585 - accuracy: 0.8615\n",
      "Epoch 446/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.3541 - accuracy: 0.8654\n",
      "Epoch 447/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.3550 - accuracy: 0.8654\n",
      "Epoch 448/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.3508 - accuracy: 0.8692\n",
      "Epoch 449/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.3536 - accuracy: 0.8769\n",
      "Epoch 450/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.3769 - accuracy: 0.8615\n",
      "Epoch 451/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.3518 - accuracy: 0.8692\n",
      "Epoch 452/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.3513 - accuracy: 0.8692\n",
      "Epoch 453/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.3492 - accuracy: 0.8692\n",
      "Epoch 454/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.3484 - accuracy: 0.8615\n",
      "Epoch 455/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.3515 - accuracy: 0.8615\n",
      "Epoch 456/800\n",
      "17/17 [==============================] - 0s 733us/step - loss: 0.3467 - accuracy: 0.8769\n",
      "Epoch 457/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.3485 - accuracy: 0.8731\n",
      "Epoch 458/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.3499 - accuracy: 0.8692\n",
      "Epoch 459/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.3730 - accuracy: 0.8577\n",
      "Epoch 460/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.3521 - accuracy: 0.8654\n",
      "Epoch 461/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.3417 - accuracy: 0.8808\n",
      "Epoch 462/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 0.3412 - accuracy: 0.8692\n",
      "Epoch 463/800\n",
      "17/17 [==============================] - 0s 779us/step - loss: 0.3389 - accuracy: 0.8731\n",
      "Epoch 464/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.3421 - accuracy: 0.8731\n",
      "Epoch 465/800\n",
      "17/17 [==============================] - 0s 729us/step - loss: 0.3453 - accuracy: 0.8654\n",
      "Epoch 466/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.3408 - accuracy: 0.8692\n",
      "Epoch 467/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.3402 - accuracy: 0.8654\n",
      "Epoch 468/800\n",
      "17/17 [==============================] - 0s 733us/step - loss: 0.3385 - accuracy: 0.8692\n",
      "Epoch 469/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.3421 - accuracy: 0.8654\n",
      "Epoch 470/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.3436 - accuracy: 0.8692\n",
      "Epoch 471/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.3390 - accuracy: 0.8731\n",
      "Epoch 472/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.3378 - accuracy: 0.8769\n",
      "Epoch 473/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.3374 - accuracy: 0.8808\n",
      "Epoch 474/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.3317 - accuracy: 0.8731\n",
      "Epoch 475/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.3358 - accuracy: 0.8692\n",
      "Epoch 476/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.3796 - accuracy: 0.8462\n",
      "Epoch 477/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.3890 - accuracy: 0.8538\n",
      "Epoch 478/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.3417 - accuracy: 0.8692\n",
      "Epoch 479/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.3342 - accuracy: 0.8731\n",
      "Epoch 480/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.3321 - accuracy: 0.8769\n",
      "Epoch 481/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.3406 - accuracy: 0.8731\n",
      "Epoch 482/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.3361 - accuracy: 0.8769\n",
      "Epoch 483/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.3316 - accuracy: 0.8731\n",
      "Epoch 484/800\n",
      "17/17 [==============================] - 0s 729us/step - loss: 0.3344 - accuracy: 0.8692\n",
      "Epoch 485/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.3290 - accuracy: 0.8769\n",
      "Epoch 486/800\n",
      "17/17 [==============================] - 0s 728us/step - loss: 0.3261 - accuracy: 0.8808\n",
      "Epoch 487/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.3258 - accuracy: 0.8885\n",
      "Epoch 488/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.3271 - accuracy: 0.8808\n",
      "Epoch 489/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.3274 - accuracy: 0.8808\n",
      "Epoch 490/800\n",
      "17/17 [==============================] - 0s 723us/step - loss: 0.3256 - accuracy: 0.8846\n",
      "Epoch 491/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.3230 - accuracy: 0.8808\n",
      "Epoch 492/800\n",
      "17/17 [==============================] - 0s 723us/step - loss: 0.3228 - accuracy: 0.8846\n",
      "Epoch 493/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.3182 - accuracy: 0.8808\n",
      "Epoch 494/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.3194 - accuracy: 0.8885\n",
      "Epoch 495/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.3168 - accuracy: 0.8846\n",
      "Epoch 496/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.3253 - accuracy: 0.8731\n",
      "Epoch 497/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.3167 - accuracy: 0.8923\n",
      "Epoch 498/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.3131 - accuracy: 0.9038\n",
      "Epoch 499/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.3141 - accuracy: 0.8923\n",
      "Epoch 500/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.3138 - accuracy: 0.8962\n",
      "Epoch 501/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.3254 - accuracy: 0.8885\n",
      "Epoch 502/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.3139 - accuracy: 0.8885\n",
      "Epoch 503/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.3199 - accuracy: 0.8808\n",
      "Epoch 504/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.3278 - accuracy: 0.8846\n",
      "Epoch 505/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.3143 - accuracy: 0.8923\n",
      "Epoch 506/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.3096 - accuracy: 0.8846\n",
      "Epoch 507/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.3098 - accuracy: 0.8885\n",
      "Epoch 508/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.3139 - accuracy: 0.8846\n",
      "Epoch 509/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.3107 - accuracy: 0.8885\n",
      "Epoch 510/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.3100 - accuracy: 0.8846\n",
      "Epoch 511/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.3104 - accuracy: 0.8846\n",
      "Epoch 512/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.3062 - accuracy: 0.8923\n",
      "Epoch 513/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.3105 - accuracy: 0.8846\n",
      "Epoch 514/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.3110 - accuracy: 0.8769\n",
      "Epoch 515/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.3149 - accuracy: 0.8808\n",
      "Epoch 516/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.3187 - accuracy: 0.8808\n",
      "Epoch 517/800\n",
      "17/17 [==============================] - 0s 872us/step - loss: 0.3494 - accuracy: 0.8769\n",
      "Epoch 518/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.3093 - accuracy: 0.8885\n",
      "Epoch 519/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.3024 - accuracy: 0.8962\n",
      "Epoch 520/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.2994 - accuracy: 0.8962\n",
      "Epoch 521/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.2980 - accuracy: 0.8962\n",
      "Epoch 522/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.3012 - accuracy: 0.9000\n",
      "Epoch 523/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.2985 - accuracy: 0.8962\n",
      "Epoch 524/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.2977 - accuracy: 0.8962\n",
      "Epoch 525/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.3018 - accuracy: 0.8885\n",
      "Epoch 526/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.2967 - accuracy: 0.8962\n",
      "Epoch 527/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.2945 - accuracy: 0.8962\n",
      "Epoch 528/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.2991 - accuracy: 0.8923\n",
      "Epoch 529/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.2984 - accuracy: 0.8885\n",
      "Epoch 530/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.3047 - accuracy: 0.8885\n",
      "Epoch 531/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.3008 - accuracy: 0.8962\n",
      "Epoch 532/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.2959 - accuracy: 0.8885\n",
      "Epoch 533/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.2919 - accuracy: 0.8923\n",
      "Epoch 534/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.2941 - accuracy: 0.9038\n",
      "Epoch 535/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.2931 - accuracy: 0.8923\n",
      "Epoch 536/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.2906 - accuracy: 0.8885\n",
      "Epoch 537/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.2922 - accuracy: 0.9000\n",
      "Epoch 538/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.2911 - accuracy: 0.8923\n",
      "Epoch 539/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.2848 - accuracy: 0.8962\n",
      "Epoch 540/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.2866 - accuracy: 0.8923\n",
      "Epoch 541/800\n",
      "17/17 [==============================] - 0s 772us/step - loss: 0.2867 - accuracy: 0.8885\n",
      "Epoch 542/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.2894 - accuracy: 0.8962\n",
      "Epoch 543/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.2845 - accuracy: 0.8962\n",
      "Epoch 544/800\n",
      "17/17 [==============================] - 0s 778us/step - loss: 0.2833 - accuracy: 0.8923\n",
      "Epoch 545/800\n",
      "17/17 [==============================] - 0s 777us/step - loss: 0.2884 - accuracy: 0.8846\n",
      "Epoch 546/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.2857 - accuracy: 0.8962\n",
      "Epoch 547/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.2846 - accuracy: 0.8923\n",
      "Epoch 548/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.2802 - accuracy: 0.8885\n",
      "Epoch 549/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.2822 - accuracy: 0.8962\n",
      "Epoch 550/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.2827 - accuracy: 0.8962\n",
      "Epoch 551/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.2795 - accuracy: 0.8846\n",
      "Epoch 552/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.2778 - accuracy: 0.8962\n",
      "Epoch 553/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.2787 - accuracy: 0.8962\n",
      "Epoch 554/800\n",
      "17/17 [==============================] - 0s 777us/step - loss: 0.2784 - accuracy: 0.9000\n",
      "Epoch 555/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.2770 - accuracy: 0.9077\n",
      "Epoch 556/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.2817 - accuracy: 0.8923\n",
      "Epoch 557/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.2701 - accuracy: 0.8962\n",
      "Epoch 558/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.2718 - accuracy: 0.9038\n",
      "Epoch 559/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.2679 - accuracy: 0.9000\n",
      "Epoch 560/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.2694 - accuracy: 0.8962\n",
      "Epoch 561/800\n",
      "17/17 [==============================] - 0s 772us/step - loss: 0.2634 - accuracy: 0.9038\n",
      "Epoch 562/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 0.2657 - accuracy: 0.9038\n",
      "Epoch 563/800\n",
      "17/17 [==============================] - 0s 772us/step - loss: 0.2625 - accuracy: 0.9077\n",
      "Epoch 564/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.2621 - accuracy: 0.9077\n",
      "Epoch 565/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.2650 - accuracy: 0.9077\n",
      "Epoch 566/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.2610 - accuracy: 0.9077\n",
      "Epoch 567/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.2587 - accuracy: 0.9038\n",
      "Epoch 568/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.2726 - accuracy: 0.8923\n",
      "Epoch 569/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.2611 - accuracy: 0.9038\n",
      "Epoch 570/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.2589 - accuracy: 0.9115\n",
      "Epoch 571/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.2587 - accuracy: 0.9038\n",
      "Epoch 572/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.2573 - accuracy: 0.9038\n",
      "Epoch 573/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.2555 - accuracy: 0.9038\n",
      "Epoch 574/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.2553 - accuracy: 0.9077\n",
      "Epoch 575/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.2558 - accuracy: 0.9038\n",
      "Epoch 576/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.2535 - accuracy: 0.9115\n",
      "Epoch 577/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.2570 - accuracy: 0.9038\n",
      "Epoch 578/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 0.2539 - accuracy: 0.9115\n",
      "Epoch 579/800\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.2507 - accuracy: 0.9115\n",
      "Epoch 580/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.2516 - accuracy: 0.9077\n",
      "Epoch 581/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.2511 - accuracy: 0.9077\n",
      "Epoch 582/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.2532 - accuracy: 0.9115\n",
      "Epoch 583/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.2480 - accuracy: 0.9077\n",
      "Epoch 584/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.2499 - accuracy: 0.9077\n",
      "Epoch 585/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.2533 - accuracy: 0.9077\n",
      "Epoch 586/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.2503 - accuracy: 0.9077\n",
      "Epoch 587/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.2546 - accuracy: 0.9154\n",
      "Epoch 588/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.2529 - accuracy: 0.9038\n",
      "Epoch 589/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.2474 - accuracy: 0.9154\n",
      "Epoch 590/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.2539 - accuracy: 0.9038\n",
      "Epoch 591/800\n",
      "17/17 [==============================] - 0s 778us/step - loss: 0.2470 - accuracy: 0.9154\n",
      "Epoch 592/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.2448 - accuracy: 0.9115\n",
      "Epoch 593/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.2473 - accuracy: 0.9077\n",
      "Epoch 594/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.2459 - accuracy: 0.9077\n",
      "Epoch 595/800\n",
      "17/17 [==============================] - 0s 779us/step - loss: 0.2461 - accuracy: 0.9154\n",
      "Epoch 596/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.2431 - accuracy: 0.9115\n",
      "Epoch 597/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.2423 - accuracy: 0.9077\n",
      "Epoch 598/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.2415 - accuracy: 0.9115\n",
      "Epoch 599/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.2405 - accuracy: 0.9154\n",
      "Epoch 600/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.2393 - accuracy: 0.9154\n",
      "Epoch 601/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.2417 - accuracy: 0.9115\n",
      "Epoch 602/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.2376 - accuracy: 0.9192\n",
      "Epoch 603/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.2491 - accuracy: 0.9077\n",
      "Epoch 604/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.2432 - accuracy: 0.9154\n",
      "Epoch 605/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.2422 - accuracy: 0.9154\n",
      "Epoch 606/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.2425 - accuracy: 0.9115\n",
      "Epoch 607/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.2356 - accuracy: 0.9154\n",
      "Epoch 608/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 0.2354 - accuracy: 0.9192\n",
      "Epoch 609/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.2363 - accuracy: 0.9115\n",
      "Epoch 610/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.2339 - accuracy: 0.9154\n",
      "Epoch 611/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.2341 - accuracy: 0.9192\n",
      "Epoch 612/800\n",
      "17/17 [==============================] - 0s 779us/step - loss: 0.2390 - accuracy: 0.9038\n",
      "Epoch 613/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.2347 - accuracy: 0.9192\n",
      "Epoch 614/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.2359 - accuracy: 0.9231\n",
      "Epoch 615/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.2318 - accuracy: 0.9154\n",
      "Epoch 616/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.2314 - accuracy: 0.9269\n",
      "Epoch 617/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.2280 - accuracy: 0.9308\n",
      "Epoch 618/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.2278 - accuracy: 0.9192\n",
      "Epoch 619/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.2261 - accuracy: 0.9269\n",
      "Epoch 620/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.2353 - accuracy: 0.9192\n",
      "Epoch 621/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.2270 - accuracy: 0.9154\n",
      "Epoch 622/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.2258 - accuracy: 0.9231\n",
      "Epoch 623/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.2264 - accuracy: 0.9192\n",
      "Epoch 624/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.2419 - accuracy: 0.9077\n",
      "Epoch 625/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.2354 - accuracy: 0.9192\n",
      "Epoch 626/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.2475 - accuracy: 0.9000\n",
      "Epoch 627/800\n",
      "17/17 [==============================] - 0s 768us/step - loss: 0.2439 - accuracy: 0.9192\n",
      "Epoch 628/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.2524 - accuracy: 0.8962\n",
      "Epoch 629/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.2973 - accuracy: 0.8885\n",
      "Epoch 630/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.2509 - accuracy: 0.9115\n",
      "Epoch 631/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.2480 - accuracy: 0.9115\n",
      "Epoch 632/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.2340 - accuracy: 0.9192\n",
      "Epoch 633/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.2270 - accuracy: 0.9231\n",
      "Epoch 634/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.2293 - accuracy: 0.9269\n",
      "Epoch 635/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.2208 - accuracy: 0.9269\n",
      "Epoch 636/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.2237 - accuracy: 0.9231\n",
      "Epoch 637/800\n",
      "17/17 [==============================] - 0s 774us/step - loss: 0.2224 - accuracy: 0.9269\n",
      "Epoch 638/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.2251 - accuracy: 0.9308\n",
      "Epoch 639/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.2226 - accuracy: 0.9308\n",
      "Epoch 640/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.2232 - accuracy: 0.9192\n",
      "Epoch 641/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.2252 - accuracy: 0.9154\n",
      "Epoch 642/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.2200 - accuracy: 0.9269\n",
      "Epoch 643/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.2223 - accuracy: 0.9231\n",
      "Epoch 644/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.2209 - accuracy: 0.9269\n",
      "Epoch 645/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.2289 - accuracy: 0.9269\n",
      "Epoch 646/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.2230 - accuracy: 0.9269\n",
      "Epoch 647/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.2186 - accuracy: 0.9269\n",
      "Epoch 648/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.2198 - accuracy: 0.9308\n",
      "Epoch 649/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 0.2189 - accuracy: 0.9269\n",
      "Epoch 650/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.2165 - accuracy: 0.9269\n",
      "Epoch 651/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.2156 - accuracy: 0.9308\n",
      "Epoch 652/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.2154 - accuracy: 0.9346\n",
      "Epoch 653/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.2133 - accuracy: 0.9346\n",
      "Epoch 654/800\n",
      "17/17 [==============================] - 0s 725us/step - loss: 0.2135 - accuracy: 0.9346\n",
      "Epoch 655/800\n",
      "17/17 [==============================] - 0s 732us/step - loss: 0.2112 - accuracy: 0.9346\n",
      "Epoch 656/800\n",
      "17/17 [==============================] - 0s 720us/step - loss: 0.2137 - accuracy: 0.9308\n",
      "Epoch 657/800\n",
      "17/17 [==============================] - 0s 720us/step - loss: 0.2108 - accuracy: 0.9385\n",
      "Epoch 658/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.2142 - accuracy: 0.9269\n",
      "Epoch 659/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.2106 - accuracy: 0.9346\n",
      "Epoch 660/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.2103 - accuracy: 0.9346\n",
      "Epoch 661/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.2095 - accuracy: 0.9308\n",
      "Epoch 662/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.2099 - accuracy: 0.9346\n",
      "Epoch 663/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.2089 - accuracy: 0.9308\n",
      "Epoch 664/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.2132 - accuracy: 0.9231\n",
      "Epoch 665/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.2080 - accuracy: 0.9346\n",
      "Epoch 666/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.2102 - accuracy: 0.9346\n",
      "Epoch 667/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.2029 - accuracy: 0.9346\n",
      "Epoch 668/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.2070 - accuracy: 0.9231\n",
      "Epoch 669/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.2047 - accuracy: 0.9346\n",
      "Epoch 670/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.2020 - accuracy: 0.9346\n",
      "Epoch 671/800\n",
      "17/17 [==============================] - 0s 720us/step - loss: 0.2018 - accuracy: 0.9346\n",
      "Epoch 672/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.2012 - accuracy: 0.9346\n",
      "Epoch 673/800\n",
      "17/17 [==============================] - 0s 733us/step - loss: 0.2076 - accuracy: 0.9308\n",
      "Epoch 674/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.2114 - accuracy: 0.9231\n",
      "Epoch 675/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.2397 - accuracy: 0.9192\n",
      "Epoch 676/800\n",
      "17/17 [==============================] - 0s 728us/step - loss: 0.2323 - accuracy: 0.9192\n",
      "Epoch 677/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.2097 - accuracy: 0.9346\n",
      "Epoch 678/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.2024 - accuracy: 0.9346\n",
      "Epoch 679/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.2013 - accuracy: 0.9385\n",
      "Epoch 680/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.2020 - accuracy: 0.9385\n",
      "Epoch 681/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.1953 - accuracy: 0.9385\n",
      "Epoch 682/800\n",
      "17/17 [==============================] - 0s 720us/step - loss: 0.1946 - accuracy: 0.9385\n",
      "Epoch 683/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.1934 - accuracy: 0.9385\n",
      "Epoch 684/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.2039 - accuracy: 0.9346\n",
      "Epoch 685/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.1986 - accuracy: 0.9346\n",
      "Epoch 686/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 0.1970 - accuracy: 0.9385\n",
      "Epoch 687/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.1940 - accuracy: 0.9423\n",
      "Epoch 688/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.1937 - accuracy: 0.9346\n",
      "Epoch 689/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.1931 - accuracy: 0.9385\n",
      "Epoch 690/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.1925 - accuracy: 0.9385\n",
      "Epoch 691/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.1901 - accuracy: 0.9385\n",
      "Epoch 692/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.1928 - accuracy: 0.9346\n",
      "Epoch 693/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.1931 - accuracy: 0.9385\n",
      "Epoch 694/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.1951 - accuracy: 0.9269\n",
      "Epoch 695/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.1888 - accuracy: 0.9423\n",
      "Epoch 696/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.1899 - accuracy: 0.9385\n",
      "Epoch 697/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.1890 - accuracy: 0.9385\n",
      "Epoch 698/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.1884 - accuracy: 0.9385\n",
      "Epoch 699/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.1902 - accuracy: 0.9423\n",
      "Epoch 700/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.1881 - accuracy: 0.9385\n",
      "Epoch 701/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.1902 - accuracy: 0.9385\n",
      "Epoch 702/800\n",
      "17/17 [==============================] - 0s 772us/step - loss: 0.1931 - accuracy: 0.9346\n",
      "Epoch 703/800\n",
      "17/17 [==============================] - 0s 729us/step - loss: 0.1913 - accuracy: 0.9423\n",
      "Epoch 704/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.2078 - accuracy: 0.9346\n",
      "Epoch 705/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.2047 - accuracy: 0.9269\n",
      "Epoch 706/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.1886 - accuracy: 0.9423\n",
      "Epoch 707/800\n",
      "17/17 [==============================] - 0s 724us/step - loss: 0.1853 - accuracy: 0.9423\n",
      "Epoch 708/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.1844 - accuracy: 0.9423\n",
      "Epoch 709/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.1845 - accuracy: 0.9423\n",
      "Epoch 710/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.1834 - accuracy: 0.9423\n",
      "Epoch 711/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.1838 - accuracy: 0.9423\n",
      "Epoch 712/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.1845 - accuracy: 0.9423\n",
      "Epoch 713/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.1808 - accuracy: 0.9423\n",
      "Epoch 714/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.1820 - accuracy: 0.9423\n",
      "Epoch 715/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.1811 - accuracy: 0.9423\n",
      "Epoch 716/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.1829 - accuracy: 0.9423\n",
      "Epoch 717/800\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.1789 - accuracy: 0.9423\n",
      "Epoch 718/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.1778 - accuracy: 0.9423\n",
      "Epoch 719/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.1805 - accuracy: 0.9423\n",
      "Epoch 720/800\n",
      "17/17 [==============================] - 0s 729us/step - loss: 0.1800 - accuracy: 0.9385\n",
      "Epoch 721/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.1842 - accuracy: 0.9423\n",
      "Epoch 722/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.1793 - accuracy: 0.9462\n",
      "Epoch 723/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.1784 - accuracy: 0.9462\n",
      "Epoch 724/800\n",
      "17/17 [==============================] - 0s 729us/step - loss: 0.1764 - accuracy: 0.9462\n",
      "Epoch 725/800\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.1757 - accuracy: 0.9462\n",
      "Epoch 726/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.1792 - accuracy: 0.9462\n",
      "Epoch 727/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.1779 - accuracy: 0.9385\n",
      "Epoch 728/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.1864 - accuracy: 0.9346\n",
      "Epoch 729/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.1743 - accuracy: 0.9385\n",
      "Epoch 730/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.1780 - accuracy: 0.9346\n",
      "Epoch 731/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.1805 - accuracy: 0.9462\n",
      "Epoch 732/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.1834 - accuracy: 0.9423\n",
      "Epoch 733/800\n",
      "17/17 [==============================] - 0s 726us/step - loss: 0.1790 - accuracy: 0.9462\n",
      "Epoch 734/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.1744 - accuracy: 0.9423\n",
      "Epoch 735/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.1717 - accuracy: 0.9423\n",
      "Epoch 736/800\n",
      "17/17 [==============================] - 0s 754us/step - loss: 0.1740 - accuracy: 0.9385\n",
      "Epoch 737/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.1718 - accuracy: 0.9423\n",
      "Epoch 738/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.1704 - accuracy: 0.9423\n",
      "Epoch 739/800\n",
      "17/17 [==============================] - 0s 742us/step - loss: 0.1720 - accuracy: 0.9462\n",
      "Epoch 740/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.1703 - accuracy: 0.9462\n",
      "Epoch 741/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.1764 - accuracy: 0.9423\n",
      "Epoch 742/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.1952 - accuracy: 0.9346\n",
      "Epoch 743/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.1804 - accuracy: 0.9462\n",
      "Epoch 744/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.1772 - accuracy: 0.9423\n",
      "Epoch 745/800\n",
      "17/17 [==============================] - 0s 728us/step - loss: 0.1758 - accuracy: 0.9462\n",
      "Epoch 746/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 0.1716 - accuracy: 0.9462\n",
      "Epoch 747/800\n",
      "17/17 [==============================] - 0s 762us/step - loss: 0.1690 - accuracy: 0.9462\n",
      "Epoch 748/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.1689 - accuracy: 0.9500\n",
      "Epoch 749/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.1689 - accuracy: 0.9462\n",
      "Epoch 750/800\n",
      "17/17 [==============================] - 0s 755us/step - loss: 0.1674 - accuracy: 0.9462\n",
      "Epoch 751/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.1675 - accuracy: 0.9462\n",
      "Epoch 752/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.1675 - accuracy: 0.9462\n",
      "Epoch 753/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.1718 - accuracy: 0.9423\n",
      "Epoch 754/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.1707 - accuracy: 0.9462\n",
      "Epoch 755/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.1729 - accuracy: 0.9462\n",
      "Epoch 756/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.1684 - accuracy: 0.9462\n",
      "Epoch 757/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 0.1664 - accuracy: 0.9423\n",
      "Epoch 758/800\n",
      "17/17 [==============================] - 0s 741us/step - loss: 0.1659 - accuracy: 0.9423\n",
      "Epoch 759/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.1638 - accuracy: 0.9462\n",
      "Epoch 760/800\n",
      "17/17 [==============================] - 0s 736us/step - loss: 0.1664 - accuracy: 0.9462\n",
      "Epoch 761/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.2478 - accuracy: 0.9154\n",
      "Epoch 762/800\n",
      "17/17 [==============================] - 0s 759us/step - loss: 0.5824 - accuracy: 0.8731\n",
      "Epoch 763/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.2934 - accuracy: 0.8769\n",
      "Epoch 764/800\n",
      "17/17 [==============================] - 0s 751us/step - loss: 0.2180 - accuracy: 0.9154\n",
      "Epoch 765/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.1877 - accuracy: 0.9308\n",
      "Epoch 766/800\n",
      "17/17 [==============================] - 0s 744us/step - loss: 0.1710 - accuracy: 0.9462\n",
      "Epoch 767/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.1678 - accuracy: 0.9385\n",
      "Epoch 768/800\n",
      "17/17 [==============================] - 0s 746us/step - loss: 0.1643 - accuracy: 0.9423\n",
      "Epoch 769/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.1658 - accuracy: 0.9462\n",
      "Epoch 770/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.1740 - accuracy: 0.9385\n",
      "Epoch 771/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.1790 - accuracy: 0.9423\n",
      "Epoch 772/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.1632 - accuracy: 0.9423\n",
      "Epoch 773/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.1619 - accuracy: 0.9423\n",
      "Epoch 774/800\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.1617 - accuracy: 0.9500\n",
      "Epoch 775/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.1610 - accuracy: 0.9462\n",
      "Epoch 776/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 0.1600 - accuracy: 0.9462\n",
      "Epoch 777/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.1602 - accuracy: 0.9423\n",
      "Epoch 778/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.1620 - accuracy: 0.9462\n",
      "Epoch 779/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.1606 - accuracy: 0.9462\n",
      "Epoch 780/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.1600 - accuracy: 0.9423\n",
      "Epoch 781/800\n",
      "17/17 [==============================] - 0s 733us/step - loss: 0.1600 - accuracy: 0.9423\n",
      "Epoch 782/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 0.1595 - accuracy: 0.9500\n",
      "Epoch 783/800\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.1587 - accuracy: 0.9462\n",
      "Epoch 784/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.1600 - accuracy: 0.9500\n",
      "Epoch 785/800\n",
      "17/17 [==============================] - 0s 720us/step - loss: 0.1586 - accuracy: 0.9462\n",
      "Epoch 786/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.1585 - accuracy: 0.9462\n",
      "Epoch 787/800\n",
      "17/17 [==============================] - 0s 721us/step - loss: 0.1577 - accuracy: 0.9500\n",
      "Epoch 788/800\n",
      "17/17 [==============================] - 0s 736us/step - loss: 0.1585 - accuracy: 0.9500\n",
      "Epoch 789/800\n",
      "17/17 [==============================] - 0s 743us/step - loss: 0.1588 - accuracy: 0.9500\n",
      "Epoch 790/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.1582 - accuracy: 0.9462\n",
      "Epoch 791/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.1569 - accuracy: 0.9462\n",
      "Epoch 792/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.1565 - accuracy: 0.9500\n",
      "Epoch 793/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.1593 - accuracy: 0.9500\n",
      "Epoch 794/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.1561 - accuracy: 0.9462\n",
      "Epoch 795/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.1561 - accuracy: 0.9462\n",
      "Epoch 796/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.1557 - accuracy: 0.9500\n",
      "Epoch 797/800\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.1558 - accuracy: 0.9462\n",
      "Epoch 798/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.1551 - accuracy: 0.9500\n",
      "Epoch 799/800\n",
      "17/17 [==============================] - 0s 728us/step - loss: 0.1549 - accuracy: 0.9462\n",
      "Epoch 800/800\n",
      "17/17 [==============================] - 0s 740us/step - loss: 0.1552 - accuracy: 0.9462\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Epoch 1/800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 220, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 268, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 192, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 221, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 1ms/step - loss: 1.7888 - accuracy: 0.2615\n",
      "Epoch 2/800\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.7784 - accuracy: 0.2962\n",
      "Epoch 3/800\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.7592 - accuracy: 0.2962\n",
      "Epoch 4/800\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.7081 - accuracy: 0.2962\n",
      "Epoch 5/800\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.6356 - accuracy: 0.2962\n",
      "Epoch 6/800\n",
      "17/17 [==============================] - 0s 871us/step - loss: 1.5749 - accuracy: 0.3654\n",
      "Epoch 7/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 1.5213 - accuracy: 0.5115\n",
      "Epoch 8/800\n",
      "17/17 [==============================] - 0s 836us/step - loss: 1.4571 - accuracy: 0.5154\n",
      "Epoch 9/800\n",
      "17/17 [==============================] - 0s 833us/step - loss: 1.4036 - accuracy: 0.5154\n",
      "Epoch 10/800\n",
      "17/17 [==============================] - 0s 833us/step - loss: 1.3559 - accuracy: 0.5192\n",
      "Epoch 11/800\n",
      "17/17 [==============================] - 0s 827us/step - loss: 1.3214 - accuracy: 0.5231\n",
      "Epoch 12/800\n",
      "17/17 [==============================] - 0s 833us/step - loss: 1.2950 - accuracy: 0.5231\n",
      "Epoch 13/800\n",
      "17/17 [==============================] - 0s 833us/step - loss: 1.2704 - accuracy: 0.5308\n",
      "Epoch 14/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 1.2492 - accuracy: 0.5385\n",
      "Epoch 15/800\n",
      "17/17 [==============================] - 0s 837us/step - loss: 1.2303 - accuracy: 0.5500\n",
      "Epoch 16/800\n",
      "17/17 [==============================] - 0s 842us/step - loss: 1.2120 - accuracy: 0.5500\n",
      "Epoch 17/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 1.1923 - accuracy: 0.5500\n",
      "Epoch 18/800\n",
      "17/17 [==============================] - 0s 833us/step - loss: 1.1698 - accuracy: 0.5538\n",
      "Epoch 19/800\n",
      "17/17 [==============================] - 0s 810us/step - loss: 1.1548 - accuracy: 0.5577\n",
      "Epoch 20/800\n",
      "17/17 [==============================] - 0s 837us/step - loss: 1.1408 - accuracy: 0.5654\n",
      "Epoch 21/800\n",
      "17/17 [==============================] - 0s 842us/step - loss: 1.1267 - accuracy: 0.5654\n",
      "Epoch 22/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 1.1119 - accuracy: 0.5654\n",
      "Epoch 23/800\n",
      "17/17 [==============================] - 0s 827us/step - loss: 1.1046 - accuracy: 0.5654\n",
      "Epoch 24/800\n",
      "17/17 [==============================] - 0s 822us/step - loss: 1.0960 - accuracy: 0.5654\n",
      "Epoch 25/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 1.0845 - accuracy: 0.5654\n",
      "Epoch 26/800\n",
      "17/17 [==============================] - 0s 795us/step - loss: 1.0792 - accuracy: 0.5654\n",
      "Epoch 27/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 1.0680 - accuracy: 0.5654\n",
      "Epoch 28/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 1.0639 - accuracy: 0.5692\n",
      "Epoch 29/800\n",
      "17/17 [==============================] - 0s 826us/step - loss: 1.0514 - accuracy: 0.5654\n",
      "Epoch 30/800\n",
      "17/17 [==============================] - 0s 827us/step - loss: 1.0428 - accuracy: 0.5692\n",
      "Epoch 31/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 1.0379 - accuracy: 0.5692\n",
      "Epoch 32/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 1.0294 - accuracy: 0.5692\n",
      "Epoch 33/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 1.0329 - accuracy: 0.5731\n",
      "Epoch 34/800\n",
      "17/17 [==============================] - 0s 829us/step - loss: 1.0254 - accuracy: 0.5692\n",
      "Epoch 35/800\n",
      "17/17 [==============================] - 0s 817us/step - loss: 1.0090 - accuracy: 0.5692\n",
      "Epoch 36/800\n",
      "17/17 [==============================] - 0s 826us/step - loss: 1.0053 - accuracy: 0.5769\n",
      "Epoch 37/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 1.0031 - accuracy: 0.5808\n",
      "Epoch 38/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 1.0007 - accuracy: 0.5769\n",
      "Epoch 39/800\n",
      "17/17 [==============================] - 0s 827us/step - loss: 0.9906 - accuracy: 0.5846\n",
      "Epoch 40/800\n",
      "17/17 [==============================] - 0s 817us/step - loss: 0.9844 - accuracy: 0.5962\n",
      "Epoch 41/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.9891 - accuracy: 0.5962\n",
      "Epoch 42/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.9758 - accuracy: 0.6038\n",
      "Epoch 43/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.9670 - accuracy: 0.6000\n",
      "Epoch 44/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.9655 - accuracy: 0.6038\n",
      "Epoch 45/800\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.9660 - accuracy: 0.5962\n",
      "Epoch 46/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.9563 - accuracy: 0.6115\n",
      "Epoch 47/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.9495 - accuracy: 0.6038\n",
      "Epoch 48/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.9428 - accuracy: 0.6077\n",
      "Epoch 49/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 0.9402 - accuracy: 0.6154\n",
      "Epoch 50/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.9410 - accuracy: 0.6115\n",
      "Epoch 51/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.9387 - accuracy: 0.6154\n",
      "Epoch 52/800\n",
      "17/17 [==============================] - 0s 827us/step - loss: 0.9279 - accuracy: 0.6231\n",
      "Epoch 53/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.9251 - accuracy: 0.6308\n",
      "Epoch 54/800\n",
      "17/17 [==============================] - 0s 846us/step - loss: 0.9187 - accuracy: 0.6423\n",
      "Epoch 55/800\n",
      "17/17 [==============================] - 0s 842us/step - loss: 0.9152 - accuracy: 0.6385\n",
      "Epoch 56/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 0.9187 - accuracy: 0.6423\n",
      "Epoch 57/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.9081 - accuracy: 0.6385\n",
      "Epoch 58/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.9102 - accuracy: 0.6500\n",
      "Epoch 59/800\n",
      "17/17 [==============================] - 0s 833us/step - loss: 0.9029 - accuracy: 0.6308\n",
      "Epoch 60/800\n",
      "17/17 [==============================] - 0s 857us/step - loss: 0.8944 - accuracy: 0.6462\n",
      "Epoch 61/800\n",
      "17/17 [==============================] - 0s 869us/step - loss: 0.8931 - accuracy: 0.6462\n",
      "Epoch 62/800\n",
      "17/17 [==============================] - 0s 857us/step - loss: 0.8846 - accuracy: 0.6538\n",
      "Epoch 63/800\n",
      "17/17 [==============================] - 0s 848us/step - loss: 0.8812 - accuracy: 0.6462\n",
      "Epoch 64/800\n",
      "17/17 [==============================] - 0s 830us/step - loss: 0.8785 - accuracy: 0.6423\n",
      "Epoch 65/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 0.8793 - accuracy: 0.6423\n",
      "Epoch 66/800\n",
      "17/17 [==============================] - 0s 841us/step - loss: 0.8766 - accuracy: 0.6385\n",
      "Epoch 67/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.8731 - accuracy: 0.6500\n",
      "Epoch 68/800\n",
      "17/17 [==============================] - 0s 863us/step - loss: 0.8724 - accuracy: 0.6577\n",
      "Epoch 69/800\n",
      "17/17 [==============================] - 0s 840us/step - loss: 0.8710 - accuracy: 0.6462\n",
      "Epoch 70/800\n",
      "17/17 [==============================] - 0s 849us/step - loss: 0.8576 - accuracy: 0.6615\n",
      "Epoch 71/800\n",
      "17/17 [==============================] - 0s 847us/step - loss: 0.8613 - accuracy: 0.6692\n",
      "Epoch 72/800\n",
      "17/17 [==============================] - 0s 856us/step - loss: 0.8509 - accuracy: 0.6808\n",
      "Epoch 73/800\n",
      "17/17 [==============================] - 0s 864us/step - loss: 0.8507 - accuracy: 0.6808\n",
      "Epoch 74/800\n",
      "17/17 [==============================] - 0s 852us/step - loss: 0.8473 - accuracy: 0.6808\n",
      "Epoch 75/800\n",
      "17/17 [==============================] - 0s 840us/step - loss: 0.8311 - accuracy: 0.6769\n",
      "Epoch 76/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.8428 - accuracy: 0.6731\n",
      "Epoch 77/800\n",
      "17/17 [==============================] - 0s 834us/step - loss: 0.8482 - accuracy: 0.6692\n",
      "Epoch 78/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 0.8517 - accuracy: 0.6885\n",
      "Epoch 79/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.8364 - accuracy: 0.6846\n",
      "Epoch 80/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 0.8230 - accuracy: 0.6808\n",
      "Epoch 81/800\n",
      "17/17 [==============================] - 0s 858us/step - loss: 0.8031 - accuracy: 0.6846\n",
      "Epoch 82/800\n",
      "17/17 [==============================] - 0s 857us/step - loss: 0.8226 - accuracy: 0.6769\n",
      "Epoch 83/800\n",
      "17/17 [==============================] - 0s 857us/step - loss: 0.8161 - accuracy: 0.6923\n",
      "Epoch 84/800\n",
      "17/17 [==============================] - 0s 859us/step - loss: 0.7981 - accuracy: 0.6923\n",
      "Epoch 85/800\n",
      "17/17 [==============================] - 0s 861us/step - loss: 0.7966 - accuracy: 0.6769\n",
      "Epoch 86/800\n",
      "17/17 [==============================] - 0s 843us/step - loss: 0.7862 - accuracy: 0.6885\n",
      "Epoch 87/800\n",
      "17/17 [==============================] - 0s 855us/step - loss: 0.7816 - accuracy: 0.7000\n",
      "Epoch 88/800\n",
      "17/17 [==============================] - 0s 834us/step - loss: 0.8049 - accuracy: 0.6885\n",
      "Epoch 89/800\n",
      "17/17 [==============================] - 0s 849us/step - loss: 0.7957 - accuracy: 0.6769\n",
      "Epoch 90/800\n",
      "17/17 [==============================] - 0s 867us/step - loss: 0.7763 - accuracy: 0.6846\n",
      "Epoch 91/800\n",
      "17/17 [==============================] - 0s 866us/step - loss: 0.7685 - accuracy: 0.6962\n",
      "Epoch 92/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.7694 - accuracy: 0.6962\n",
      "Epoch 93/800\n",
      "17/17 [==============================] - 0s 834us/step - loss: 0.7587 - accuracy: 0.7000\n",
      "Epoch 94/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.7607 - accuracy: 0.6962\n",
      "Epoch 95/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.7652 - accuracy: 0.6808\n",
      "Epoch 96/800\n",
      "17/17 [==============================] - 0s 845us/step - loss: 0.7672 - accuracy: 0.7000\n",
      "Epoch 97/800\n",
      "17/17 [==============================] - 0s 865us/step - loss: 0.7458 - accuracy: 0.6885\n",
      "Epoch 98/800\n",
      "17/17 [==============================] - 0s 861us/step - loss: 0.7420 - accuracy: 0.7115\n",
      "Epoch 99/800\n",
      "17/17 [==============================] - 0s 826us/step - loss: 0.7395 - accuracy: 0.7154\n",
      "Epoch 100/800\n",
      "17/17 [==============================] - 0s 822us/step - loss: 0.7377 - accuracy: 0.7115\n",
      "Epoch 101/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 0.7246 - accuracy: 0.7192\n",
      "Epoch 102/800\n",
      "17/17 [==============================] - 0s 827us/step - loss: 0.7245 - accuracy: 0.7154\n",
      "Epoch 103/800\n",
      "17/17 [==============================] - 0s 840us/step - loss: 0.7203 - accuracy: 0.7231\n",
      "Epoch 104/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.7306 - accuracy: 0.7231\n",
      "Epoch 105/800\n",
      "17/17 [==============================] - 0s 827us/step - loss: 0.7180 - accuracy: 0.7308\n",
      "Epoch 106/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.7153 - accuracy: 0.7385\n",
      "Epoch 107/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.7162 - accuracy: 0.7231\n",
      "Epoch 108/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.7102 - accuracy: 0.7231\n",
      "Epoch 109/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 0.7462 - accuracy: 0.7154\n",
      "Epoch 110/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 0.7194 - accuracy: 0.7115\n",
      "Epoch 111/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.7083 - accuracy: 0.7538\n",
      "Epoch 112/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.7000 - accuracy: 0.7615\n",
      "Epoch 113/800\n",
      "17/17 [==============================] - 0s 833us/step - loss: 0.7016 - accuracy: 0.7115\n",
      "Epoch 114/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.6944 - accuracy: 0.7269\n",
      "Epoch 115/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 0.6917 - accuracy: 0.7192\n",
      "Epoch 116/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 0.6885 - accuracy: 0.7615\n",
      "Epoch 117/800\n",
      "17/17 [==============================] - 0s 830us/step - loss: 0.6971 - accuracy: 0.7308\n",
      "Epoch 118/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.6803 - accuracy: 0.7385\n",
      "Epoch 119/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.6812 - accuracy: 0.7385\n",
      "Epoch 120/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 0.6741 - accuracy: 0.7654\n",
      "Epoch 121/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 0.6850 - accuracy: 0.7269\n",
      "Epoch 122/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.6672 - accuracy: 0.7462\n",
      "Epoch 123/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.6679 - accuracy: 0.7462\n",
      "Epoch 124/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.6870 - accuracy: 0.7462\n",
      "Epoch 125/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.6794 - accuracy: 0.7615\n",
      "Epoch 126/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.6742 - accuracy: 0.7500\n",
      "Epoch 127/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.6678 - accuracy: 0.7615\n",
      "Epoch 128/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 0.6588 - accuracy: 0.7577\n",
      "Epoch 129/800\n",
      "17/17 [==============================] - 0s 834us/step - loss: 0.6519 - accuracy: 0.7462\n",
      "Epoch 130/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 0.6555 - accuracy: 0.7769\n",
      "Epoch 131/800\n",
      "17/17 [==============================] - 0s 826us/step - loss: 0.6498 - accuracy: 0.7692\n",
      "Epoch 132/800\n",
      "17/17 [==============================] - 0s 833us/step - loss: 0.6442 - accuracy: 0.7769\n",
      "Epoch 133/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.6464 - accuracy: 0.7692\n",
      "Epoch 134/800\n",
      "17/17 [==============================] - 0s 827us/step - loss: 0.6537 - accuracy: 0.7615\n",
      "Epoch 135/800\n",
      "17/17 [==============================] - 0s 826us/step - loss: 0.6448 - accuracy: 0.7692\n",
      "Epoch 136/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.6405 - accuracy: 0.7615\n",
      "Epoch 137/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.6354 - accuracy: 0.7654\n",
      "Epoch 138/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.6371 - accuracy: 0.7500\n",
      "Epoch 139/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.6411 - accuracy: 0.7577\n",
      "Epoch 140/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.6411 - accuracy: 0.7577\n",
      "Epoch 141/800\n",
      "17/17 [==============================] - 0s 842us/step - loss: 0.6255 - accuracy: 0.7731\n",
      "Epoch 142/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.6491 - accuracy: 0.7615\n",
      "Epoch 143/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.6277 - accuracy: 0.7731\n",
      "Epoch 144/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.6557 - accuracy: 0.7500\n",
      "Epoch 145/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.6228 - accuracy: 0.7808\n",
      "Epoch 146/800\n",
      "17/17 [==============================] - 0s 829us/step - loss: 0.6231 - accuracy: 0.7692\n",
      "Epoch 147/800\n",
      "17/17 [==============================] - 0s 843us/step - loss: 0.6233 - accuracy: 0.7654\n",
      "Epoch 148/800\n",
      "17/17 [==============================] - 0s 831us/step - loss: 0.6207 - accuracy: 0.7654\n",
      "Epoch 149/800\n",
      "17/17 [==============================] - 0s 839us/step - loss: 0.6157 - accuracy: 0.7769\n",
      "Epoch 150/800\n",
      "17/17 [==============================] - 0s 849us/step - loss: 0.6133 - accuracy: 0.7692\n",
      "Epoch 151/800\n",
      "17/17 [==============================] - 0s 835us/step - loss: 0.6189 - accuracy: 0.7654\n",
      "Epoch 152/800\n",
      "17/17 [==============================] - 0s 831us/step - loss: 0.6141 - accuracy: 0.7654\n",
      "Epoch 153/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.6055 - accuracy: 0.7731\n",
      "Epoch 154/800\n",
      "17/17 [==============================] - 0s 831us/step - loss: 0.6206 - accuracy: 0.7731\n",
      "Epoch 155/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.6352 - accuracy: 0.7654\n",
      "Epoch 156/800\n",
      "17/17 [==============================] - 0s 838us/step - loss: 0.6132 - accuracy: 0.7731\n",
      "Epoch 157/800\n",
      "17/17 [==============================] - 0s 844us/step - loss: 0.6039 - accuracy: 0.7692\n",
      "Epoch 158/800\n",
      "17/17 [==============================] - 0s 834us/step - loss: 0.5973 - accuracy: 0.7731\n",
      "Epoch 159/800\n",
      "17/17 [==============================] - 0s 845us/step - loss: 0.5916 - accuracy: 0.7731\n",
      "Epoch 160/800\n",
      "17/17 [==============================] - 0s 838us/step - loss: 0.6042 - accuracy: 0.7731\n",
      "Epoch 161/800\n",
      "17/17 [==============================] - 0s 827us/step - loss: 0.5977 - accuracy: 0.7769\n",
      "Epoch 162/800\n",
      "17/17 [==============================] - 0s 836us/step - loss: 0.5922 - accuracy: 0.7731\n",
      "Epoch 163/800\n",
      "17/17 [==============================] - 0s 831us/step - loss: 0.5930 - accuracy: 0.7769\n",
      "Epoch 164/800\n",
      "17/17 [==============================] - 0s 822us/step - loss: 0.5929 - accuracy: 0.7808\n",
      "Epoch 165/800\n",
      "17/17 [==============================] - 0s 837us/step - loss: 0.5862 - accuracy: 0.7731\n",
      "Epoch 166/800\n",
      "17/17 [==============================] - 0s 834us/step - loss: 0.5905 - accuracy: 0.7808\n",
      "Epoch 167/800\n",
      "17/17 [==============================] - 0s 829us/step - loss: 0.5832 - accuracy: 0.7808\n",
      "Epoch 168/800\n",
      "17/17 [==============================] - 0s 827us/step - loss: 0.5796 - accuracy: 0.7808\n",
      "Epoch 169/800\n",
      "17/17 [==============================] - 0s 817us/step - loss: 0.5834 - accuracy: 0.7731\n",
      "Epoch 170/800\n",
      "17/17 [==============================] - 0s 837us/step - loss: 0.5802 - accuracy: 0.7846\n",
      "Epoch 171/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 0.5796 - accuracy: 0.7731\n",
      "Epoch 172/800\n",
      "17/17 [==============================] - 0s 835us/step - loss: 0.5768 - accuracy: 0.7808\n",
      "Epoch 173/800\n",
      "17/17 [==============================] - 0s 836us/step - loss: 0.5745 - accuracy: 0.7769\n",
      "Epoch 174/800\n",
      "17/17 [==============================] - 0s 838us/step - loss: 0.5894 - accuracy: 0.7769\n",
      "Epoch 175/800\n",
      "17/17 [==============================] - 0s 842us/step - loss: 0.5767 - accuracy: 0.7885\n",
      "Epoch 176/800\n",
      "17/17 [==============================] - 0s 848us/step - loss: 0.5820 - accuracy: 0.7808\n",
      "Epoch 177/800\n",
      "17/17 [==============================] - 0s 839us/step - loss: 0.5707 - accuracy: 0.7808\n",
      "Epoch 178/800\n",
      "17/17 [==============================] - 0s 822us/step - loss: 0.5711 - accuracy: 0.7846\n",
      "Epoch 179/800\n",
      "17/17 [==============================] - 0s 836us/step - loss: 0.5632 - accuracy: 0.7808\n",
      "Epoch 180/800\n",
      "17/17 [==============================] - 0s 833us/step - loss: 0.5676 - accuracy: 0.7885\n",
      "Epoch 181/800\n",
      "17/17 [==============================] - 0s 847us/step - loss: 0.5632 - accuracy: 0.7808\n",
      "Epoch 182/800\n",
      "17/17 [==============================] - 0s 848us/step - loss: 0.5675 - accuracy: 0.7808\n",
      "Epoch 183/800\n",
      "17/17 [==============================] - 0s 851us/step - loss: 0.5566 - accuracy: 0.7885\n",
      "Epoch 184/800\n",
      "17/17 [==============================] - 0s 834us/step - loss: 0.5658 - accuracy: 0.7885\n",
      "Epoch 185/800\n",
      "17/17 [==============================] - 0s 841us/step - loss: 0.5602 - accuracy: 0.7885\n",
      "Epoch 186/800\n",
      "17/17 [==============================] - 0s 847us/step - loss: 0.5595 - accuracy: 0.7808\n",
      "Epoch 187/800\n",
      "17/17 [==============================] - 0s 840us/step - loss: 0.5661 - accuracy: 0.7846\n",
      "Epoch 188/800\n",
      "17/17 [==============================] - 0s 830us/step - loss: 0.5622 - accuracy: 0.7846\n",
      "Epoch 189/800\n",
      "17/17 [==============================] - 0s 822us/step - loss: 0.5609 - accuracy: 0.7846\n",
      "Epoch 190/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 0.5752 - accuracy: 0.7769\n",
      "Epoch 191/800\n",
      "17/17 [==============================] - 0s 833us/step - loss: 0.5471 - accuracy: 0.7923\n",
      "Epoch 192/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 0.5474 - accuracy: 0.7808\n",
      "Epoch 193/800\n",
      "17/17 [==============================] - 0s 826us/step - loss: 0.5562 - accuracy: 0.7769\n",
      "Epoch 194/800\n",
      "17/17 [==============================] - 0s 841us/step - loss: 0.5533 - accuracy: 0.7885\n",
      "Epoch 195/800\n",
      "17/17 [==============================] - 0s 840us/step - loss: 0.5443 - accuracy: 0.7846\n",
      "Epoch 196/800\n",
      "17/17 [==============================] - 0s 822us/step - loss: 0.5593 - accuracy: 0.7923\n",
      "Epoch 197/800\n",
      "17/17 [==============================] - 0s 844us/step - loss: 0.5575 - accuracy: 0.7885\n",
      "Epoch 198/800\n",
      "17/17 [==============================] - 0s 848us/step - loss: 0.5572 - accuracy: 0.7731\n",
      "Epoch 199/800\n",
      "17/17 [==============================] - 0s 841us/step - loss: 0.5558 - accuracy: 0.7769\n",
      "Epoch 200/800\n",
      "17/17 [==============================] - 0s 841us/step - loss: 0.5438 - accuracy: 0.7923\n",
      "Epoch 201/800\n",
      "17/17 [==============================] - 0s 840us/step - loss: 0.5443 - accuracy: 0.7962\n",
      "Epoch 202/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.5299 - accuracy: 0.7769\n",
      "Epoch 203/800\n",
      "17/17 [==============================] - 0s 827us/step - loss: 0.5327 - accuracy: 0.7885\n",
      "Epoch 204/800\n",
      "17/17 [==============================] - 0s 840us/step - loss: 0.5349 - accuracy: 0.7808\n",
      "Epoch 205/800\n",
      "17/17 [==============================] - 0s 833us/step - loss: 0.5325 - accuracy: 0.7923\n",
      "Epoch 206/800\n",
      "17/17 [==============================] - 0s 831us/step - loss: 0.5283 - accuracy: 0.7923\n",
      "Epoch 207/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.5321 - accuracy: 0.7962\n",
      "Epoch 208/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.5272 - accuracy: 0.7923\n",
      "Epoch 209/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.5246 - accuracy: 0.8038\n",
      "Epoch 210/800\n",
      "17/17 [==============================] - 0s 837us/step - loss: 0.5370 - accuracy: 0.7846\n",
      "Epoch 211/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.5281 - accuracy: 0.7923\n",
      "Epoch 212/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.5220 - accuracy: 0.7923\n",
      "Epoch 213/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 0.5227 - accuracy: 0.7923\n",
      "Epoch 214/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.5199 - accuracy: 0.7923\n",
      "Epoch 215/800\n",
      "17/17 [==============================] - 0s 839us/step - loss: 0.5226 - accuracy: 0.7885\n",
      "Epoch 216/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.5213 - accuracy: 0.8000\n",
      "Epoch 217/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.5154 - accuracy: 0.7923\n",
      "Epoch 218/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.5249 - accuracy: 0.7923\n",
      "Epoch 219/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.5219 - accuracy: 0.7923\n",
      "Epoch 220/800\n",
      "17/17 [==============================] - 0s 795us/step - loss: 0.5154 - accuracy: 0.7962\n",
      "Epoch 221/800\n",
      "17/17 [==============================] - 0s 852us/step - loss: 0.5178 - accuracy: 0.7923\n",
      "Epoch 222/800\n",
      "17/17 [==============================] - 0s 829us/step - loss: 0.5140 - accuracy: 0.7923\n",
      "Epoch 223/800\n",
      "17/17 [==============================] - 0s 838us/step - loss: 0.5071 - accuracy: 0.8038\n",
      "Epoch 224/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.5222 - accuracy: 0.7846\n",
      "Epoch 225/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.5159 - accuracy: 0.7923\n",
      "Epoch 226/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.5190 - accuracy: 0.7962\n",
      "Epoch 227/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.5043 - accuracy: 0.8115\n",
      "Epoch 228/800\n",
      "17/17 [==============================] - 0s 822us/step - loss: 0.5068 - accuracy: 0.8115\n",
      "Epoch 229/800\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.5000 - accuracy: 0.7923\n",
      "Epoch 230/800\n",
      "17/17 [==============================] - 0s 829us/step - loss: 0.5054 - accuracy: 0.7923\n",
      "Epoch 231/800\n",
      "17/17 [==============================] - 0s 834us/step - loss: 0.5037 - accuracy: 0.8000\n",
      "Epoch 232/800\n",
      "17/17 [==============================] - 0s 827us/step - loss: 0.5164 - accuracy: 0.8000\n",
      "Epoch 233/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.4998 - accuracy: 0.8000\n",
      "Epoch 234/800\n",
      "17/17 [==============================] - 0s 804us/step - loss: 0.5135 - accuracy: 0.8000\n",
      "Epoch 235/800\n",
      "17/17 [==============================] - 0s 827us/step - loss: 0.5037 - accuracy: 0.7962\n",
      "Epoch 236/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.4992 - accuracy: 0.8038\n",
      "Epoch 237/800\n",
      "17/17 [==============================] - 0s 829us/step - loss: 0.4949 - accuracy: 0.8038\n",
      "Epoch 238/800\n",
      "17/17 [==============================] - 0s 838us/step - loss: 0.4926 - accuracy: 0.8115\n",
      "Epoch 239/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.4923 - accuracy: 0.8038\n",
      "Epoch 240/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.4893 - accuracy: 0.8231\n",
      "Epoch 241/800\n",
      "17/17 [==============================] - 0s 837us/step - loss: 0.4880 - accuracy: 0.8077\n",
      "Epoch 242/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.5146 - accuracy: 0.8038\n",
      "Epoch 243/800\n",
      "17/17 [==============================] - 0s 840us/step - loss: 0.4979 - accuracy: 0.8038\n",
      "Epoch 244/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.4898 - accuracy: 0.8192\n",
      "Epoch 245/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.4858 - accuracy: 0.8115\n",
      "Epoch 246/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 0.4871 - accuracy: 0.8115\n",
      "Epoch 247/800\n",
      "17/17 [==============================] - 0s 834us/step - loss: 0.4821 - accuracy: 0.8154\n",
      "Epoch 248/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.4813 - accuracy: 0.8154\n",
      "Epoch 249/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 0.4802 - accuracy: 0.8115\n",
      "Epoch 250/800\n",
      "17/17 [==============================] - 0s 841us/step - loss: 0.4845 - accuracy: 0.8154\n",
      "Epoch 251/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.4874 - accuracy: 0.8154\n",
      "Epoch 252/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.4974 - accuracy: 0.8192\n",
      "Epoch 253/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.4914 - accuracy: 0.8077\n",
      "Epoch 254/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.4773 - accuracy: 0.8154\n",
      "Epoch 255/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.4780 - accuracy: 0.8269\n",
      "Epoch 256/800\n",
      "17/17 [==============================] - 0s 817us/step - loss: 0.4749 - accuracy: 0.8269\n",
      "Epoch 257/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.4729 - accuracy: 0.8192\n",
      "Epoch 258/800\n",
      "17/17 [==============================] - 0s 831us/step - loss: 0.4793 - accuracy: 0.8231\n",
      "Epoch 259/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.4787 - accuracy: 0.8192\n",
      "Epoch 260/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.4810 - accuracy: 0.8154\n",
      "Epoch 261/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.4801 - accuracy: 0.8192\n",
      "Epoch 262/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.4699 - accuracy: 0.8231\n",
      "Epoch 263/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.4790 - accuracy: 0.8154\n",
      "Epoch 264/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.4694 - accuracy: 0.8154\n",
      "Epoch 265/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 0.4637 - accuracy: 0.8308\n",
      "Epoch 266/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.4606 - accuracy: 0.8269\n",
      "Epoch 267/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.4616 - accuracy: 0.8154\n",
      "Epoch 268/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.4715 - accuracy: 0.8269\n",
      "Epoch 269/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.4967 - accuracy: 0.8038\n",
      "Epoch 270/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.4606 - accuracy: 0.8192\n",
      "Epoch 271/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 0.4562 - accuracy: 0.8269\n",
      "Epoch 272/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.4652 - accuracy: 0.8269\n",
      "Epoch 273/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.5303 - accuracy: 0.8038\n",
      "Epoch 274/800\n",
      "17/17 [==============================] - 0s 817us/step - loss: 0.4720 - accuracy: 0.8192\n",
      "Epoch 275/800\n",
      "17/17 [==============================] - 0s 838us/step - loss: 0.4553 - accuracy: 0.8346\n",
      "Epoch 276/800\n",
      "17/17 [==============================] - 0s 837us/step - loss: 0.4552 - accuracy: 0.8269\n",
      "Epoch 277/800\n",
      "17/17 [==============================] - 0s 826us/step - loss: 0.4533 - accuracy: 0.8231\n",
      "Epoch 278/800\n",
      "17/17 [==============================] - 0s 833us/step - loss: 0.4536 - accuracy: 0.8308\n",
      "Epoch 279/800\n",
      "17/17 [==============================] - 0s 830us/step - loss: 0.4843 - accuracy: 0.8231\n",
      "Epoch 280/800\n",
      "17/17 [==============================] - 0s 826us/step - loss: 0.4838 - accuracy: 0.8115\n",
      "Epoch 281/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.4652 - accuracy: 0.8346\n",
      "Epoch 282/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.4546 - accuracy: 0.8423\n",
      "Epoch 283/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.4581 - accuracy: 0.8269\n",
      "Epoch 284/800\n",
      "17/17 [==============================] - 0s 834us/step - loss: 0.4880 - accuracy: 0.8115\n",
      "Epoch 285/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 0.4638 - accuracy: 0.8192\n",
      "Epoch 286/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 0.4451 - accuracy: 0.8385\n",
      "Epoch 287/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 0.4429 - accuracy: 0.8269\n",
      "Epoch 288/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 0.4498 - accuracy: 0.8308\n",
      "Epoch 289/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.4419 - accuracy: 0.8346\n",
      "Epoch 290/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.4418 - accuracy: 0.8346\n",
      "Epoch 291/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.4379 - accuracy: 0.8538\n",
      "Epoch 292/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.4394 - accuracy: 0.8346\n",
      "Epoch 293/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.4453 - accuracy: 0.8308\n",
      "Epoch 294/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.4355 - accuracy: 0.8423\n",
      "Epoch 295/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.4329 - accuracy: 0.8385\n",
      "Epoch 296/800\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.4363 - accuracy: 0.8385\n",
      "Epoch 297/800\n",
      "17/17 [==============================] - 0s 772us/step - loss: 0.4319 - accuracy: 0.8346\n",
      "Epoch 298/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.4352 - accuracy: 0.8308\n",
      "Epoch 299/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.4414 - accuracy: 0.8308\n",
      "Epoch 300/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.4375 - accuracy: 0.8462\n",
      "Epoch 301/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.4259 - accuracy: 0.8577\n",
      "Epoch 302/800\n",
      "17/17 [==============================] - 0s 835us/step - loss: 0.4359 - accuracy: 0.8385\n",
      "Epoch 303/800\n",
      "17/17 [==============================] - 0s 836us/step - loss: 0.4321 - accuracy: 0.8423\n",
      "Epoch 304/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.4247 - accuracy: 0.8385\n",
      "Epoch 305/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.4331 - accuracy: 0.8577\n",
      "Epoch 306/800\n",
      "17/17 [==============================] - 0s 817us/step - loss: 0.4255 - accuracy: 0.8500\n",
      "Epoch 307/800\n",
      "17/17 [==============================] - 0s 831us/step - loss: 0.4448 - accuracy: 0.8308\n",
      "Epoch 308/800\n",
      "17/17 [==============================] - 0s 830us/step - loss: 0.4815 - accuracy: 0.8192\n",
      "Epoch 309/800\n",
      "17/17 [==============================] - 0s 837us/step - loss: 0.4284 - accuracy: 0.8423\n",
      "Epoch 310/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 0.4229 - accuracy: 0.8538\n",
      "Epoch 311/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 0.4214 - accuracy: 0.8423\n",
      "Epoch 312/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 0.4233 - accuracy: 0.8346\n",
      "Epoch 313/800\n",
      "17/17 [==============================] - 0s 840us/step - loss: 0.4220 - accuracy: 0.8462\n",
      "Epoch 314/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.4146 - accuracy: 0.8462\n",
      "Epoch 315/800\n",
      "17/17 [==============================] - 0s 822us/step - loss: 0.4203 - accuracy: 0.8462\n",
      "Epoch 316/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.4258 - accuracy: 0.8538\n",
      "Epoch 317/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.4178 - accuracy: 0.8423\n",
      "Epoch 318/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.4106 - accuracy: 0.8500\n",
      "Epoch 319/800\n",
      "17/17 [==============================] - 0s 829us/step - loss: 0.4178 - accuracy: 0.8577\n",
      "Epoch 320/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.4114 - accuracy: 0.8346\n",
      "Epoch 321/800\n",
      "17/17 [==============================] - 0s 822us/step - loss: 0.4119 - accuracy: 0.8462\n",
      "Epoch 322/800\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.4110 - accuracy: 0.8577\n",
      "Epoch 323/800\n",
      "17/17 [==============================] - 0s 834us/step - loss: 0.4096 - accuracy: 0.8423\n",
      "Epoch 324/800\n",
      "17/17 [==============================] - 0s 834us/step - loss: 0.4064 - accuracy: 0.8577\n",
      "Epoch 325/800\n",
      "17/17 [==============================] - 0s 840us/step - loss: 0.4057 - accuracy: 0.8577\n",
      "Epoch 326/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.4069 - accuracy: 0.8500\n",
      "Epoch 327/800\n",
      "17/17 [==============================] - 0s 822us/step - loss: 0.4054 - accuracy: 0.8500\n",
      "Epoch 328/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.4055 - accuracy: 0.8577\n",
      "Epoch 329/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.4051 - accuracy: 0.8500\n",
      "Epoch 330/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.4027 - accuracy: 0.8577\n",
      "Epoch 331/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 0.4017 - accuracy: 0.8577\n",
      "Epoch 332/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.4051 - accuracy: 0.8423\n",
      "Epoch 333/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.4003 - accuracy: 0.8538\n",
      "Epoch 334/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.4055 - accuracy: 0.8500\n",
      "Epoch 335/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.3991 - accuracy: 0.8500\n",
      "Epoch 336/800\n",
      "17/17 [==============================] - 0s 804us/step - loss: 0.3988 - accuracy: 0.8577\n",
      "Epoch 337/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.3971 - accuracy: 0.8538\n",
      "Epoch 338/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.4074 - accuracy: 0.8538\n",
      "Epoch 339/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.3939 - accuracy: 0.8500\n",
      "Epoch 340/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.3966 - accuracy: 0.8462\n",
      "Epoch 341/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.4364 - accuracy: 0.8385\n",
      "Epoch 342/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.4141 - accuracy: 0.8500\n",
      "Epoch 343/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.3968 - accuracy: 0.8500\n",
      "Epoch 344/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.3956 - accuracy: 0.8577\n",
      "Epoch 345/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 0.3994 - accuracy: 0.8423\n",
      "Epoch 346/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.3909 - accuracy: 0.8692\n",
      "Epoch 347/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.3902 - accuracy: 0.8692\n",
      "Epoch 348/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 0.3929 - accuracy: 0.8654\n",
      "Epoch 349/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.3869 - accuracy: 0.8615\n",
      "Epoch 350/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.3868 - accuracy: 0.8577\n",
      "Epoch 351/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.3881 - accuracy: 0.8692\n",
      "Epoch 352/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.3847 - accuracy: 0.8615\n",
      "Epoch 353/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.3881 - accuracy: 0.8654\n",
      "Epoch 354/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.3900 - accuracy: 0.8615\n",
      "Epoch 355/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.3852 - accuracy: 0.8769\n",
      "Epoch 356/800\n",
      "17/17 [==============================] - 0s 804us/step - loss: 0.3959 - accuracy: 0.8538\n",
      "Epoch 357/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.4044 - accuracy: 0.8577\n",
      "Epoch 358/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.3960 - accuracy: 0.8538\n",
      "Epoch 359/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.3841 - accuracy: 0.8692\n",
      "Epoch 360/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 0.3811 - accuracy: 0.8538\n",
      "Epoch 361/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.3812 - accuracy: 0.8692\n",
      "Epoch 362/800\n",
      "17/17 [==============================] - 0s 800us/step - loss: 0.3806 - accuracy: 0.8731\n",
      "Epoch 363/800\n",
      "17/17 [==============================] - 0s 804us/step - loss: 0.3755 - accuracy: 0.8692\n",
      "Epoch 364/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.3794 - accuracy: 0.8577\n",
      "Epoch 365/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.3846 - accuracy: 0.8500\n",
      "Epoch 366/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.3840 - accuracy: 0.8500\n",
      "Epoch 367/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.3748 - accuracy: 0.8577\n",
      "Epoch 368/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.3769 - accuracy: 0.8731\n",
      "Epoch 369/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 0.3890 - accuracy: 0.8577\n",
      "Epoch 370/800\n",
      "17/17 [==============================] - 0s 796us/step - loss: 0.3676 - accuracy: 0.8808\n",
      "Epoch 371/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.3764 - accuracy: 0.8731\n",
      "Epoch 372/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.3668 - accuracy: 0.8692\n",
      "Epoch 373/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.3658 - accuracy: 0.8731\n",
      "Epoch 374/800\n",
      "17/17 [==============================] - 0s 831us/step - loss: 0.3799 - accuracy: 0.8538\n",
      "Epoch 375/800\n",
      "17/17 [==============================] - 0s 834us/step - loss: 0.3684 - accuracy: 0.8654\n",
      "Epoch 376/800\n",
      "17/17 [==============================] - 0s 833us/step - loss: 0.3674 - accuracy: 0.8538\n",
      "Epoch 377/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.3712 - accuracy: 0.8654\n",
      "Epoch 378/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.3694 - accuracy: 0.8769\n",
      "Epoch 379/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.3645 - accuracy: 0.8500\n",
      "Epoch 380/800\n",
      "17/17 [==============================] - 0s 831us/step - loss: 0.3614 - accuracy: 0.8692\n",
      "Epoch 381/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.3639 - accuracy: 0.8769\n",
      "Epoch 382/800\n",
      "17/17 [==============================] - 0s 834us/step - loss: 0.3708 - accuracy: 0.8654\n",
      "Epoch 383/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.3702 - accuracy: 0.8731\n",
      "Epoch 384/800\n",
      "17/17 [==============================] - 0s 830us/step - loss: 0.3601 - accuracy: 0.8769\n",
      "Epoch 385/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.3545 - accuracy: 0.8808\n",
      "Epoch 386/800\n",
      "17/17 [==============================] - 0s 817us/step - loss: 0.3543 - accuracy: 0.8885\n",
      "Epoch 387/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 0.3579 - accuracy: 0.8808\n",
      "Epoch 388/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.3539 - accuracy: 0.8808\n",
      "Epoch 389/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 0.3632 - accuracy: 0.8692\n",
      "Epoch 390/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.3629 - accuracy: 0.8577\n",
      "Epoch 391/800\n",
      "17/17 [==============================] - 0s 840us/step - loss: 0.3487 - accuracy: 0.8769\n",
      "Epoch 392/800\n",
      "17/17 [==============================] - 0s 835us/step - loss: 0.3529 - accuracy: 0.8731\n",
      "Epoch 393/800\n",
      "17/17 [==============================] - 0s 832us/step - loss: 0.3505 - accuracy: 0.8692\n",
      "Epoch 394/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.3508 - accuracy: 0.8692\n",
      "Epoch 395/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.3518 - accuracy: 0.8692\n",
      "Epoch 396/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.3521 - accuracy: 0.8808\n",
      "Epoch 397/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.3563 - accuracy: 0.8654\n",
      "Epoch 398/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.3491 - accuracy: 0.8846\n",
      "Epoch 399/800\n",
      "17/17 [==============================] - 0s 806us/step - loss: 0.3482 - accuracy: 0.8769\n",
      "Epoch 400/800\n",
      "17/17 [==============================] - 0s 796us/step - loss: 0.3447 - accuracy: 0.8692\n",
      "Epoch 401/800\n",
      "17/17 [==============================] - 0s 826us/step - loss: 0.3445 - accuracy: 0.8808\n",
      "Epoch 402/800\n",
      "17/17 [==============================] - 0s 822us/step - loss: 0.3477 - accuracy: 0.8769\n",
      "Epoch 403/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.3464 - accuracy: 0.8769\n",
      "Epoch 404/800\n",
      "17/17 [==============================] - 0s 835us/step - loss: 0.3467 - accuracy: 0.8808\n",
      "Epoch 405/800\n",
      "17/17 [==============================] - 0s 829us/step - loss: 0.3509 - accuracy: 0.8769\n",
      "Epoch 406/800\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.3448 - accuracy: 0.8846\n",
      "Epoch 407/800\n",
      "17/17 [==============================] - 0s 829us/step - loss: 0.3422 - accuracy: 0.8692\n",
      "Epoch 408/800\n",
      "17/17 [==============================] - 0s 831us/step - loss: 0.3396 - accuracy: 0.8769\n",
      "Epoch 409/800\n",
      "17/17 [==============================] - 0s 827us/step - loss: 0.3393 - accuracy: 0.8808\n",
      "Epoch 410/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 0.3443 - accuracy: 0.8846\n",
      "Epoch 411/800\n",
      "17/17 [==============================] - 0s 834us/step - loss: 0.3551 - accuracy: 0.8654\n",
      "Epoch 412/800\n",
      "17/17 [==============================] - 0s 833us/step - loss: 0.3429 - accuracy: 0.8692\n",
      "Epoch 413/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.3552 - accuracy: 0.8692\n",
      "Epoch 414/800\n",
      "17/17 [==============================] - 0s 835us/step - loss: 0.3466 - accuracy: 0.8654\n",
      "Epoch 415/800\n",
      "17/17 [==============================] - 0s 822us/step - loss: 0.3393 - accuracy: 0.8808\n",
      "Epoch 416/800\n",
      "17/17 [==============================] - 0s 829us/step - loss: 0.3379 - accuracy: 0.8808\n",
      "Epoch 417/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.3406 - accuracy: 0.8731\n",
      "Epoch 418/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.3350 - accuracy: 0.8808\n",
      "Epoch 419/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.3333 - accuracy: 0.8769\n",
      "Epoch 420/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.3374 - accuracy: 0.8885\n",
      "Epoch 421/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.3382 - accuracy: 0.8769\n",
      "Epoch 422/800\n",
      "17/17 [==============================] - 0s 804us/step - loss: 0.3346 - accuracy: 0.8846\n",
      "Epoch 423/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.3542 - accuracy: 0.8615\n",
      "Epoch 424/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.3516 - accuracy: 0.8731\n",
      "Epoch 425/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 0.3523 - accuracy: 0.8500\n",
      "Epoch 426/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.3422 - accuracy: 0.8692\n",
      "Epoch 427/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.3358 - accuracy: 0.8731\n",
      "Epoch 428/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.3285 - accuracy: 0.8769\n",
      "Epoch 429/800\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.3438 - accuracy: 0.8615\n",
      "Epoch 430/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.3395 - accuracy: 0.8692\n",
      "Epoch 431/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.3308 - accuracy: 0.8731\n",
      "Epoch 432/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.3258 - accuracy: 0.8731\n",
      "Epoch 433/800\n",
      "17/17 [==============================] - 0s 804us/step - loss: 0.3259 - accuracy: 0.8885\n",
      "Epoch 434/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.3332 - accuracy: 0.8692\n",
      "Epoch 435/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.3360 - accuracy: 0.8731\n",
      "Epoch 436/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.3295 - accuracy: 0.8846\n",
      "Epoch 437/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.3321 - accuracy: 0.8808\n",
      "Epoch 438/800\n",
      "17/17 [==============================] - 0s 795us/step - loss: 0.3219 - accuracy: 0.8846\n",
      "Epoch 439/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.3476 - accuracy: 0.8500\n",
      "Epoch 440/800\n",
      "17/17 [==============================] - 0s 819us/step - loss: 0.3305 - accuracy: 0.8808\n",
      "Epoch 441/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 0.3209 - accuracy: 0.8846\n",
      "Epoch 442/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.3180 - accuracy: 0.8769\n",
      "Epoch 443/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.3190 - accuracy: 0.8885\n",
      "Epoch 444/800\n",
      "17/17 [==============================] - 0s 828us/step - loss: 0.3210 - accuracy: 0.8885\n",
      "Epoch 445/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.3240 - accuracy: 0.8731\n",
      "Epoch 446/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 0.3180 - accuracy: 0.8846\n",
      "Epoch 447/800\n",
      "17/17 [==============================] - 0s 821us/step - loss: 0.3159 - accuracy: 0.8846\n",
      "Epoch 448/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.3146 - accuracy: 0.8885\n",
      "Epoch 449/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.3147 - accuracy: 0.8846\n",
      "Epoch 450/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.3133 - accuracy: 0.8808\n",
      "Epoch 451/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.3248 - accuracy: 0.8769\n",
      "Epoch 452/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.3164 - accuracy: 0.8885\n",
      "Epoch 453/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.3291 - accuracy: 0.8769\n",
      "Epoch 454/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.3137 - accuracy: 0.8923\n",
      "Epoch 455/800\n",
      "17/17 [==============================] - 0s 814us/step - loss: 0.3177 - accuracy: 0.8769\n",
      "Epoch 456/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.3134 - accuracy: 0.8846\n",
      "Epoch 457/800\n",
      "17/17 [==============================] - 0s 795us/step - loss: 0.3191 - accuracy: 0.8846\n",
      "Epoch 458/800\n",
      "17/17 [==============================] - 0s 778us/step - loss: 0.3162 - accuracy: 0.8615\n",
      "Epoch 459/800\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.3164 - accuracy: 0.8808\n",
      "Epoch 460/800\n",
      "17/17 [==============================] - 0s 797us/step - loss: 0.3072 - accuracy: 0.8885\n",
      "Epoch 461/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.3106 - accuracy: 0.8769\n",
      "Epoch 462/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.3059 - accuracy: 0.8846\n",
      "Epoch 463/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.3107 - accuracy: 0.8654\n",
      "Epoch 464/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.3104 - accuracy: 0.8846\n",
      "Epoch 465/800\n",
      "17/17 [==============================] - 0s 816us/step - loss: 0.3051 - accuracy: 0.8692\n",
      "Epoch 466/800\n",
      "17/17 [==============================] - 0s 793us/step - loss: 0.3078 - accuracy: 0.8769\n",
      "Epoch 467/800\n",
      "17/17 [==============================] - 0s 806us/step - loss: 0.3096 - accuracy: 0.8808\n",
      "Epoch 468/800\n",
      "17/17 [==============================] - 0s 804us/step - loss: 0.3046 - accuracy: 0.8846\n",
      "Epoch 469/800\n",
      "17/17 [==============================] - 0s 782us/step - loss: 0.3041 - accuracy: 0.8846\n",
      "Epoch 470/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.3458 - accuracy: 0.8654\n",
      "Epoch 471/800\n",
      "17/17 [==============================] - 0s 800us/step - loss: 0.3047 - accuracy: 0.8808\n",
      "Epoch 472/800\n",
      "17/17 [==============================] - 0s 817us/step - loss: 0.3028 - accuracy: 0.8846\n",
      "Epoch 473/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.3034 - accuracy: 0.8885\n",
      "Epoch 474/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.3002 - accuracy: 0.8923\n",
      "Epoch 475/800\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.2988 - accuracy: 0.8885\n",
      "Epoch 476/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 0.3134 - accuracy: 0.8692\n",
      "Epoch 477/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.3063 - accuracy: 0.8769\n",
      "Epoch 478/800\n",
      "17/17 [==============================] - 0s 815us/step - loss: 0.3147 - accuracy: 0.8615\n",
      "Epoch 479/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.3166 - accuracy: 0.8654\n",
      "Epoch 480/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.3087 - accuracy: 0.8885\n",
      "Epoch 481/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.2951 - accuracy: 0.8885\n",
      "Epoch 482/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.3021 - accuracy: 0.8731\n",
      "Epoch 483/800\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.2983 - accuracy: 0.8808\n",
      "Epoch 484/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.3077 - accuracy: 0.8808\n",
      "Epoch 485/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.3028 - accuracy: 0.8769\n",
      "Epoch 486/800\n",
      "17/17 [==============================] - 0s 796us/step - loss: 0.2921 - accuracy: 0.8885\n",
      "Epoch 487/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.2986 - accuracy: 0.8962\n",
      "Epoch 488/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.3056 - accuracy: 0.8654\n",
      "Epoch 489/800\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.3083 - accuracy: 0.8615\n",
      "Epoch 490/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.3724 - accuracy: 0.8731\n",
      "Epoch 491/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.3126 - accuracy: 0.8769\n",
      "Epoch 492/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.2964 - accuracy: 0.8808\n",
      "Epoch 493/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.3099 - accuracy: 0.8654\n",
      "Epoch 494/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.2951 - accuracy: 0.8846\n",
      "Epoch 495/800\n",
      "17/17 [==============================] - 0s 780us/step - loss: 0.2972 - accuracy: 0.8885\n",
      "Epoch 496/800\n",
      "17/17 [==============================] - 0s 803us/step - loss: 0.2931 - accuracy: 0.8885\n",
      "Epoch 497/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.2889 - accuracy: 0.8846\n",
      "Epoch 498/800\n",
      "17/17 [==============================] - 0s 824us/step - loss: 0.2938 - accuracy: 0.8808\n",
      "Epoch 499/800\n",
      "17/17 [==============================] - 0s 818us/step - loss: 0.2885 - accuracy: 0.8923\n",
      "Epoch 500/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.2889 - accuracy: 0.8885\n",
      "Epoch 501/800\n",
      "17/17 [==============================] - 0s 823us/step - loss: 0.2842 - accuracy: 0.8923\n",
      "Epoch 502/800\n",
      "17/17 [==============================] - 0s 813us/step - loss: 0.2829 - accuracy: 0.8962\n",
      "Epoch 503/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.2855 - accuracy: 0.8923\n",
      "Epoch 504/800\n",
      "17/17 [==============================] - 0s 783us/step - loss: 0.2901 - accuracy: 0.8885\n",
      "Epoch 505/800\n",
      "17/17 [==============================] - 0s 784us/step - loss: 0.2970 - accuracy: 0.8885\n",
      "Epoch 506/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.2966 - accuracy: 0.8769\n",
      "Epoch 507/800\n",
      "17/17 [==============================] - 0s 792us/step - loss: 0.2915 - accuracy: 0.8769\n",
      "Epoch 508/800\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.2851 - accuracy: 0.8885\n",
      "Epoch 509/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.2834 - accuracy: 0.8962\n",
      "Epoch 510/800\n",
      "17/17 [==============================] - 0s 798us/step - loss: 0.2885 - accuracy: 0.8885\n",
      "Epoch 511/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.2819 - accuracy: 0.9000\n",
      "Epoch 512/800\n",
      "17/17 [==============================] - 0s 790us/step - loss: 0.2827 - accuracy: 0.8885\n",
      "Epoch 513/800\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.2833 - accuracy: 0.8923\n",
      "Epoch 514/800\n",
      "17/17 [==============================] - 0s 805us/step - loss: 0.2800 - accuracy: 0.8923\n",
      "Epoch 515/800\n",
      "17/17 [==============================] - 0s 794us/step - loss: 0.2809 - accuracy: 0.8962\n",
      "Epoch 516/800\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.2758 - accuracy: 0.8808\n",
      "Epoch 517/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.2810 - accuracy: 0.8962\n",
      "Epoch 518/800\n",
      "17/17 [==============================] - 0s 791us/step - loss: 0.2765 - accuracy: 0.8885\n",
      "Epoch 519/800\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.2807 - accuracy: 0.8923\n",
      "Epoch 520/800\n",
      "17/17 [==============================] - 0s 807us/step - loss: 0.2805 - accuracy: 0.8885\n",
      "Epoch 521/800\n",
      "17/17 [==============================] - 0s 786us/step - loss: 0.2851 - accuracy: 0.8731\n",
      "Epoch 522/800\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.2756 - accuracy: 0.8923\n",
      "Epoch 523/800\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.2742 - accuracy: 0.8923\n",
      "Epoch 524/800\n",
      "17/17 [==============================] - 0s 817us/step - loss: 0.2758 - accuracy: 0.9038\n",
      "Epoch 525/800\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.2725 - accuracy: 0.8962\n",
      "Epoch 526/800\n",
      "17/17 [==============================] - 0s 778us/step - loss: 0.2726 - accuracy: 0.9000\n",
      "Epoch 527/800\n",
      "17/17 [==============================] - 0s 775us/step - loss: 0.2746 - accuracy: 0.9000\n",
      "Epoch 528/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.2784 - accuracy: 0.8962\n",
      "Epoch 529/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.2732 - accuracy: 0.8962\n",
      "Epoch 530/800\n",
      "17/17 [==============================] - 0s 761us/step - loss: 0.2702 - accuracy: 0.8923\n",
      "Epoch 531/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.2707 - accuracy: 0.9000\n",
      "Epoch 532/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.2690 - accuracy: 0.8923\n",
      "Epoch 533/800\n",
      "17/17 [==============================] - 0s 773us/step - loss: 0.2722 - accuracy: 0.8923\n",
      "Epoch 534/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.2685 - accuracy: 0.8923\n",
      "Epoch 535/800\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.2933 - accuracy: 0.8808\n",
      "Epoch 536/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.2837 - accuracy: 0.8846\n",
      "Epoch 537/800\n",
      "17/17 [==============================] - 0s 765us/step - loss: 0.2865 - accuracy: 0.9000\n",
      "Epoch 538/800\n",
      "17/17 [==============================] - 0s 729us/step - loss: 0.2949 - accuracy: 0.8731\n",
      "Epoch 539/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.2669 - accuracy: 0.9038\n",
      "Epoch 540/800\n",
      "17/17 [==============================] - 0s 722us/step - loss: 0.2716 - accuracy: 0.9077\n",
      "Epoch 541/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.2631 - accuracy: 0.9000\n",
      "Epoch 542/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.2649 - accuracy: 0.9038\n",
      "Epoch 543/800\n",
      "17/17 [==============================] - 0s 760us/step - loss: 0.2714 - accuracy: 0.9000\n",
      "Epoch 544/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.2614 - accuracy: 0.9077\n",
      "Epoch 545/800\n",
      "17/17 [==============================] - 0s 757us/step - loss: 0.2666 - accuracy: 0.9038\n",
      "Epoch 546/800\n",
      "17/17 [==============================] - 0s 758us/step - loss: 0.2665 - accuracy: 0.8962\n",
      "Epoch 547/800\n",
      "17/17 [==============================] - 0s 776us/step - loss: 0.2859 - accuracy: 0.8923\n",
      "Epoch 548/800\n",
      "17/17 [==============================] - 0s 734us/step - loss: 0.2700 - accuracy: 0.8923\n",
      "Epoch 549/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.2602 - accuracy: 0.9038\n",
      "Epoch 550/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 0.2648 - accuracy: 0.8846\n",
      "Epoch 551/800\n",
      "17/17 [==============================] - 0s 733us/step - loss: 0.2584 - accuracy: 0.8923\n",
      "Epoch 552/800\n",
      "17/17 [==============================] - 0s 767us/step - loss: 0.2602 - accuracy: 0.9000\n",
      "Epoch 553/800\n",
      "17/17 [==============================] - 0s 745us/step - loss: 0.2651 - accuracy: 0.8923\n",
      "Epoch 554/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.2591 - accuracy: 0.8923\n",
      "Epoch 555/800\n",
      "17/17 [==============================] - 0s 736us/step - loss: 0.2537 - accuracy: 0.9038\n",
      "Epoch 556/800\n",
      "17/17 [==============================] - 0s 727us/step - loss: 0.2563 - accuracy: 0.9115\n",
      "Epoch 557/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.2551 - accuracy: 0.9077\n",
      "Epoch 558/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.2567 - accuracy: 0.9115\n",
      "Epoch 559/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 0.2583 - accuracy: 0.9077\n",
      "Epoch 560/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.2878 - accuracy: 0.8885\n",
      "Epoch 561/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.2617 - accuracy: 0.9077\n",
      "Epoch 562/800\n",
      "17/17 [==============================] - 0s 730us/step - loss: 0.2512 - accuracy: 0.9077\n",
      "Epoch 563/800\n",
      "17/17 [==============================] - 0s 729us/step - loss: 0.2534 - accuracy: 0.9077\n",
      "Epoch 564/800\n",
      "17/17 [==============================] - 0s 731us/step - loss: 0.2536 - accuracy: 0.9077\n",
      "Epoch 565/800\n",
      "17/17 [==============================] - 0s 738us/step - loss: 0.2558 - accuracy: 0.9077\n",
      "Epoch 566/800\n",
      "17/17 [==============================] - 0s 732us/step - loss: 0.2540 - accuracy: 0.9000\n",
      "Epoch 567/800\n",
      "17/17 [==============================] - 0s 735us/step - loss: 0.2573 - accuracy: 0.9154\n",
      "Epoch 568/800\n",
      "17/17 [==============================] - 0s 732us/step - loss: 0.2570 - accuracy: 0.9115\n",
      "Epoch 569/800\n",
      "17/17 [==============================] - 0s 737us/step - loss: 0.2495 - accuracy: 0.9192\n",
      "Epoch 570/800\n",
      "17/17 [==============================] - 0s 752us/step - loss: 0.2490 - accuracy: 0.9115\n",
      "Epoch 571/800\n",
      "17/17 [==============================] - 0s 769us/step - loss: 0.2526 - accuracy: 0.9154\n",
      "Epoch 572/800\n",
      "17/17 [==============================] - 0s 771us/step - loss: 0.2520 - accuracy: 0.9077\n",
      "Epoch 573/800\n",
      "17/17 [==============================] - 0s 763us/step - loss: 0.2507 - accuracy: 0.9154\n",
      "Epoch 574/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.2449 - accuracy: 0.9115\n",
      "Epoch 575/800\n",
      "17/17 [==============================] - 0s 756us/step - loss: 0.2600 - accuracy: 0.9115\n",
      "Epoch 576/800\n",
      "17/17 [==============================] - 0s 777us/step - loss: 0.2455 - accuracy: 0.9269\n",
      "Epoch 577/800\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.2440 - accuracy: 0.9192\n",
      "Epoch 578/800\n",
      "17/17 [==============================] - 0s 753us/step - loss: 0.2382 - accuracy: 0.9115\n",
      "Epoch 579/800\n",
      "17/17 [==============================] - 0s 781us/step - loss: 0.2588 - accuracy: 0.9077\n",
      "Epoch 580/800\n",
      "17/17 [==============================] - 0s 766us/step - loss: 0.3245 - accuracy: 0.8885\n",
      "Epoch 581/800\n",
      "Epoch 581/800\n"
     ]
    }
   ],
   "source": [
    "# Tuning the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "def build_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = 10))\n",
    "    classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier)\n",
    "parameters = {'batch_size': [16, 32],\n",
    "              'epochs': [800, 1000],\n",
    "              'optimizer': ['adam', 'rmsprop']}\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10)\n",
    "grid_search = grid_search.fit(X_train, y_train,verbose = 1)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
