{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Experiment 1</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbLj-OUKojSL"
   },
   "source": [
    "#### Aim: Build an Artificial Neural Network to implement Binary Classification task using the Back-propagation algorithm and test the same using appropriate data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAd5BOpNn1yb"
   },
   "source": [
    "#### Description\n",
    "\n",
    "The data used here is : '**Pima Indians Diabetes Dataset**'. It is downloaded from : https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\n",
    "\n",
    "It is a binary (2-class) classification problem. There are 768 observations with 8 input variables and 1 output variable.\n",
    "\n",
    "The variable names are as follows:\n",
    "\n",
    "**1. Number of times pregnant.**\n",
    "\n",
    "**2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test.**\n",
    "\n",
    "**3. Diastolic blood pressure (mm Hg).**\n",
    "\n",
    "**4. Triceps skinfold thickness (mm).**\n",
    "\n",
    "**5. 2-Hour serum insulin (mu U/ml).**\n",
    "\n",
    "**6. Body mass index (weight in kg/(height in m)^2).**\n",
    "\n",
    "**7. Diabetes pedigree function.**\n",
    "\n",
    "**8. Age (years).**\n",
    "\n",
    "**9. Class variable (0 or 1).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3pOyaANmimQ"
   },
   "source": [
    " #### Data Import and Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mwGyz6EwSRk5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-n1H04B-dX7O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       768 non-null    int64  \n",
      " 1   1       768 non-null    int64  \n",
      " 2   2       768 non-null    int64  \n",
      " 3   3       768 non-null    int64  \n",
      " 4   4       768 non-null    int64  \n",
      " 5   5       768 non-null    float64\n",
      " 6   6       768 non-null    float64\n",
      " 7   7       768 non-null    int64  \n",
      " 8   8       768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n",
      "None\n",
      "   0    1   2   3    4     5      6   7  8\n",
      "0  6  148  72  35    0  33.6  0.627  50  1\n",
      "1  1   85  66  29    0  26.6  0.351  31  0\n",
      "2  8  183  64   0    0  23.3  0.672  32  1\n",
      "3  1   89  66  23   94  28.1  0.167  21  0\n",
      "4  0  137  40  35  168  43.1  2.288  33  1\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv'\n",
    "data_pd = pd.read_csv(url,header = None)\n",
    "print(data_pd.info())\n",
    "print(data_pd.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsRaWD3y5CgE"
   },
   "source": [
    "StandardScaler: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qyy2Qp8uHNkQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.639947</td>\n",
       "      <td>0.848324</td>\n",
       "      <td>0.149641</td>\n",
       "      <td>0.907270</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>0.204013</td>\n",
       "      <td>0.468492</td>\n",
       "      <td>1.425995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-1.123396</td>\n",
       "      <td>-0.160546</td>\n",
       "      <td>0.530902</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-0.684422</td>\n",
       "      <td>-0.365061</td>\n",
       "      <td>-0.190672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.233880</td>\n",
       "      <td>1.943724</td>\n",
       "      <td>-0.263941</td>\n",
       "      <td>-1.288212</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-1.103255</td>\n",
       "      <td>0.604397</td>\n",
       "      <td>-0.105584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-0.998208</td>\n",
       "      <td>-0.160546</td>\n",
       "      <td>0.154533</td>\n",
       "      <td>0.123302</td>\n",
       "      <td>-0.494043</td>\n",
       "      <td>-0.920763</td>\n",
       "      <td>-1.041549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.141852</td>\n",
       "      <td>0.504055</td>\n",
       "      <td>-1.504687</td>\n",
       "      <td>0.907270</td>\n",
       "      <td>0.765836</td>\n",
       "      <td>1.409746</td>\n",
       "      <td>5.484909</td>\n",
       "      <td>-0.020496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.639947  0.848324  0.149641  0.907270 -0.692891  0.204013  0.468492   \n",
       "1 -0.844885 -1.123396 -0.160546  0.530902 -0.692891 -0.684422 -0.365061   \n",
       "2  1.233880  1.943724 -0.263941 -1.288212 -0.692891 -1.103255  0.604397   \n",
       "3 -0.844885 -0.998208 -0.160546  0.154533  0.123302 -0.494043 -0.920763   \n",
       "4 -1.141852  0.504055 -1.504687  0.907270  0.765836  1.409746  5.484909   \n",
       "\n",
       "          7  \n",
       "0  1.425995  \n",
       "1 -0.190672  \n",
       "2 -0.105584  \n",
       "3 -1.041549  \n",
       "4 -0.020496  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling Numerical columns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "scaled = std.fit_transform(data_pd.iloc[:,0:8])\n",
    "scaled = pd.DataFrame(scaled)\n",
    "scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "aSvqBd1jC0GW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data: (768, 8)\n",
      "Y_data: (768,)\n"
     ]
    }
   ],
   "source": [
    "X_data =scaled.to_numpy()\n",
    "print('X_data:',np.shape(X_data))\n",
    "Y_data = data_pd.iloc[:,8]\n",
    "print('Y_data:',np.shape(Y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "re5mYzfAdX2R"
   },
   "outputs": [],
   "source": [
    "# Split data into X_train, X_test, y_train, y_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.25, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6XY9nsL8dXzm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (576, 8)\n",
      "y_train: (576,)\n",
      "X_test: (192, 8)\n",
      "y_test: (192,)\n"
     ]
    }
   ],
   "source": [
    "# Check the dimension of the sets\n",
    "print('X_train:',np.shape(X_train))\n",
    "print('y_train:',np.shape(y_train))\n",
    "print('X_test:',np.shape(X_test))\n",
    "print('y_test:',np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hDbfl4qm5Iq"
   },
   "source": [
    "#### Design the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lTOChYlGdXmu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential   # importing Sequential model\n",
    "from keras.layers import Dense        # importing Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BRvrz_MLSfMd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# declaring model\n",
    "basic_model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1u-JSWmXnAqf"
   },
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GvTzUK7OasqW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/120\n",
      "WARNING:tensorflow:From C:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "18/18 [==============================] - 2s 52ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 2/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 3/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 4/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 5/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 6/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 7/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 8/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 9/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 10/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 11/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 12/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 13/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 14/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 15/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 16/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 17/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 18/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 19/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 20/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 21/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 22/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 23/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 24/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 25/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 26/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 27/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 28/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 29/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 30/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 31/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 32/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 33/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 34/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 35/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 36/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 37/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 38/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 39/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 40/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 41/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 42/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 43/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 44/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 45/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 46/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 47/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 48/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 49/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 50/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 51/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 52/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 53/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 54/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 55/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 56/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 57/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 58/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 59/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 60/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 61/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 62/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 63/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 64/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 65/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 66/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 67/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 68/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 69/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 70/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 71/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 72/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 73/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 74/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 75/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 76/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 77/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 78/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 79/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 80/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 81/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 82/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 83/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 84/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 85/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 86/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 87/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 88/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 89/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 90/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 91/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 92/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 93/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 94/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 95/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 96/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 97/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 98/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 99/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 100/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 101/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 102/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 103/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 104/120\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 105/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 106/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 107/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 108/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 109/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 110/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 111/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 112/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 113/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 114/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 115/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 116/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 117/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 118/120\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 119/120\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.4540 - val_loss: 3.3674\n",
      "Epoch 120/120\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3.4540 - val_loss: 3.3674\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "basic_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "epochs=120\n",
    "history = basic_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sb996_yGu6cl"
   },
   "source": [
    "#### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "SUS1fZ5nvF3U"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss vs epochs\n",
    "epochRange = range(1,epochs+1)\n",
    "plt.plot(epochRange,history.history['loss'])\n",
    "plt.plot(epochRange,history.history['val_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.xlim((1,epochs))\n",
    "plt.legend(['Train','Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Z08lfMC5v0wk"
   },
   "outputs": [],
   "source": [
    "# Plot accuracy vs epochs (DIY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FlT5Vst5h16C",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3674\n",
      "Loss =  3.3673744201660156\n"
     ]
    }
   ],
   "source": [
    "# Test, Loss, and Accuracy\n",
    "evaluation = basic_model.evaluate(X_test, y_test)\n",
    "if isinstance(evaluation, float):\n",
    "    # If only one metric (usually loss) is returned\n",
    "    loss = evaluation\n",
    "    print('Loss = ', loss)\n",
    "else:\n",
    "    # If multiple metrics are returned\n",
    "    loss = evaluation[0]\n",
    "    accuracy = evaluation[1]\n",
    "    print('Loss = ', loss)\n",
    "    print('Accuracy = ', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rs-Eo3bFwsl_"
   },
   "source": [
    "#### Classification Model Performance measures\n",
    "\n",
    "<img src='https://editor.analyticsvidhya.com/uploads/99666confusion%20matrix.JPG' width=40%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "G8j6D_uvwu1p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step\n",
      "661    1\n",
      "122    0\n",
      "113    0\n",
      "14     1\n",
      "529    0\n",
      "Name: 8, dtype: int64\n",
      "[[-0.84488505  2.4444783   0.35643175  1.4090945  -0.6928906   1.3843617\n",
      "   2.784923   -0.95646167]\n",
      " [-0.5479186  -0.43485916  0.25303626  0.5936296   0.17539902  0.20401277\n",
      "  -0.20499448 -0.87137395]\n",
      " [ 0.04601434 -1.4050707  -0.36733675 -1.2882122  -0.6928906   0.25478047\n",
      "  -0.24425603 -0.7011984 ]\n",
      " [ 0.3429808   1.4116724   0.14964075 -0.09637905  0.8266162  -0.78595734\n",
      "   0.34768724  1.5110831 ]\n",
      " [-1.1418515  -0.3096706  -0.2122435  -1.2882122  -0.6928906  -0.93826044\n",
      "   0.5681559  -0.1906719 ]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = basic_model.predict(X_test)\n",
    "print(y_test[:5])\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion: The loss was found out to be 3.36."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/Kaustubh-Atey/Keras-Codes-/blob/master/Keras%20-%20Binary%20Classification.ipynb",
     "timestamp": 1690785277040
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
