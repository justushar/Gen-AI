{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LSRciOWJ7jV"
      },
      "source": [
        "# AIM: Design a CNN architecture to implement the image classification task over an image dataset. Perform the Hyper-parameter tuning and record the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbzVJDovJ7jX"
      },
      "source": [
        "## Database\n",
        "* The data that will be incorporated is the **MNIST database** which contains 60,000 images for training and 10,000 test images.\n",
        "* The dataset consists of small square 28Ã—28 pixel grayscale images of handwritten single digits between 0 and 9\n",
        "* The MNIST dataset is conveniently bundled within Keras, and we can easily analyze some of its features in Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V012gbodpic3"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.datasets import mnist     # MNIST dataset is included in Keras\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(\"X_train shape\", X_train.shape)\n",
        "print(\"y_train shape\", y_train.shape)\n",
        "print(\"X_test shape\", X_test.shape)\n",
        "print(\"y_test shape\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAgWtMJopoI4"
      },
      "source": [
        "# Visualize any random image\n",
        "import matplotlib.pyplot as plt\n",
        "i=50;\n",
        "plt.imshow(X_train[i], cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTLr3I6qp7tX"
      },
      "source": [
        "### Formatting the Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH6WP7EhJ7kK"
      },
      "source": [
        "# Single-channel input data (grey-scale)\n",
        "# First apply convolutions then flatten\n",
        "\n",
        "X_train = X_train.reshape(60000, 28, 28, 1) # single-channel input\n",
        "X_test = X_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "X_train = X_train.astype('float32')         # change integers to 32-bit floating point numbers\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255                              # min-max normalization\n",
        "X_test /= 255\n",
        "\n",
        "print(\"Training matrix shape\", X_train.shape)\n",
        "print(\"Testing matrix shape\", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuGGo-BhJ7kG"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXPdGa2zJ7kG"
      },
      "source": [
        "* Convolution applies **kernels** (filters) that traverse through each image and generate **feature maps**\n",
        "* keras Conv2D:  https://keras.io/api/layers/convolution_layers/convolution2d/\n",
        "* Each kernel in a CNN learns a different characteristic of an image.\n",
        "* **max pooling** helps in reducing the number of learnable parameters, and decreasing the computational cost (e.g. system memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzUmjgpcJ7kJ"
      },
      "source": [
        "## Building a Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAz2NiBysMk-"
      },
      "source": [
        "from keras import backend as K\n",
        "from keras import __version__\n",
        "\n",
        "print('Using Keras version:', __version__, 'backend:', K.backend())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "qullHJQyJ7kJ"
      },
      "source": [
        "# import cnn layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()                                 # Linear stacking of layers\n",
        "\n",
        "# Convolution Layer 1: 8 filters, kernel size 3x3, relu activation, valid padding, stride 1\n",
        "\n",
        "# MaxPooling: pool size 2, stride 2\n",
        "\n",
        "# Convolution Layer 2: 16 filters, kernel size 3x3, relu activation, valid padding, stride 1\n",
        "\n",
        "# MaxPooling: pool size 2, stride 2\n",
        "\n",
        "# Flatten final feature matrix into a 1d array\n",
        "\n",
        "# Fully Connected Layer: 64 units and relu activation\n",
        "\n",
        "# Dropout layer, 0.2 rate\n",
        "\n",
        "# Final output dense Layer\n",
        "\n",
        "#Compile the model with sparse_categorical_crossentropy loss\n"
      ],
      "metadata": {
        "id": "vnyTdNLt-NMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPtz-hkNJ7kL"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conv1: 3x3 kernels, one for each the single channel, 8 such filters and 8 biases\n",
        "print('Conv1: ',3*3*1*8 + 8)\n",
        "# Conv2: 3x3 kernels, one for each of the 8 channels, 16 such filters and 16 biases\n",
        "print('Conv2: ',3*3*8*16 + 16)\n",
        "# input to dense layer\n",
        "print('Flatten:', 5*5*16)\n",
        "# 400 inputs, 1 bias connected to each of 64 units in dense layer\n",
        "print('Dense1: ',400*64+64)\n",
        "# 64 inputs, 1 bias connected to each of 10 units in output layer\n",
        "print('Dense2: ',64*10+10)"
      ],
      "metadata": {
        "id": "kAbfseDLAfDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y60-vSdJvwrZ"
      },
      "source": [
        "# Visualize the model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, show_shapes=True, show_layer_names=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSfLW0QDwhwZ"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_9c9v-nj9Li"
      },
      "source": [
        "* Validation data =0.2*60,000 = 12,000\n",
        "* Batch size = 128\n",
        "* Number of batches during training are (60000-12000)/128 = 48000/128 = 375\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stleMOVewiLS"
      },
      "source": [
        "# Train the model\n",
        "batch_size=128\n",
        "epochs=10\n",
        "hist = model.fit(X_train, y_train,epochs=epochs,batch_size=batch_size,verbose=1,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a7xQqDE0l71"
      },
      "source": [
        "### Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNtLvw7R0mcA"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose = 0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqXjnsGilvB2"
      },
      "source": [
        "# make one prediction\n",
        "print('Actual class:',y_test[0])\n",
        "print('Class Probabilities:')\n",
        "model.predict(X_test[0].reshape(1,28,28,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuJKW9-i1fCw"
      },
      "source": [
        "import numpy as np\n",
        "yhat_test = np.argmax(model.predict(X_test),axis=-1);\n",
        "print(yhat_test[0:10]);\n",
        "print(y_test[0:10]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOx0Jxzl19Ij"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print('Accuracy:')\n",
        "print(float(accuracy_score(y_test, yhat_test))*100,'%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRWO59sO2Qns"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, yhat_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Learning curves"
      ],
      "metadata": {
        "id": "EDGErUSxBtmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist.history.keys()"
      ],
      "metadata": {
        "id": "2dws9ppRBVPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Accuracy vs epochs (DIY)\n"
      ],
      "metadata": {
        "id": "fDWmI4noB3XB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Loss vs epochs (DIY)\n"
      ],
      "metadata": {
        "id": "OYfmgD93CCpz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}